{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from helium import *\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "url = 'https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub'  # open access paper with a lot of information\n",
    "url2 = 'https://www.sciencedirect.com/science/article/abs/pii/S0306437918300838?via%3Dihub'  # pay per paper view with less information (available at least)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A: Selenium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_HTML_selenium(url, os):\n",
    "    \"\"\"\n",
    "    Get HTML from a website using Selenium and ChromeDriver. Methods runs headless per default and has JS activated.\n",
    "    Be aware that this method is quite slow and schould only be used if classic requests method cannot access information thus only use that for dynamic data.\n",
    "    :param url: URL of a website\n",
    "    :param os: Operating system of the user (Windows, Linux, Mac)\n",
    "    :return: HTML with all loaded content\n",
    "    \"\"\"\n",
    "    # print current path\n",
    "    if os == 'mac':\n",
    "        PATH_MAC = 'Research_Scraper_Code/driver/chromedriverMAC'\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=chrome\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\", \"enable-logging\"])\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    driver = webdriver.Chrome(PATH_MAC, options=options)\n",
    "    driver.get(url)\n",
    "    break_time = 5\n",
    "    time.sleep(break_time)\n",
    "\n",
    "    # todo if content owned by WWU add sleep to load more content\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\n",
    "        f'Browser closed in {end - start} seconds, including {break_time} seconds of waiting, thus {end - start - break_time} seconds of loading.')\n",
    "    return html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriverMAC' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:72\u001B[0m, in \u001B[0;36mService.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     71\u001B[0m     cmd\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_line_args())\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplatform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msystem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWindows\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstdin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/subprocess.py:951\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001B[0m\n\u001B[1;32m    948\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    949\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/subprocess.py:1821\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001B[0m\n\u001B[1;32m   1820\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1822\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'Research_Scraper_Code/driver/chromedriverMAC'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mWebDriverException\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m html1 \u001B[38;5;241m=\u001B[39m \u001B[43mget_HTML_selenium\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmac\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [15]\u001B[0m, in \u001B[0;36mget_HTML_selenium\u001B[0;34m(url, os)\u001B[0m\n\u001B[1;32m     15\u001B[0m options\u001B[38;5;241m.\u001B[39madd_experimental_option(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexcludeSwitches\u001B[39m\u001B[38;5;124m\"\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menable-automation\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menable-logging\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     17\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 19\u001B[0m driver \u001B[38;5;241m=\u001B[39m \u001B[43mwebdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPATH_MAC\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m driver\u001B[38;5;241m.\u001B[39mget(url)\n\u001B[1;32m     21\u001B[0m break_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:73\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001B[0m\n\u001B[1;32m     66\u001B[0m         desired_capabilities\u001B[38;5;241m.\u001B[39mupdate(options\u001B[38;5;241m.\u001B[39mto_capabilities())\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice \u001B[38;5;241m=\u001B[39m Service(\n\u001B[1;32m     69\u001B[0m     executable_path,\n\u001B[1;32m     70\u001B[0m     port\u001B[38;5;241m=\u001B[39mport,\n\u001B[1;32m     71\u001B[0m     service_args\u001B[38;5;241m=\u001B[39mservice_args,\n\u001B[1;32m     72\u001B[0m     log_path\u001B[38;5;241m=\u001B[39mservice_log_path)\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     RemoteWebDriver\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     77\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     78\u001B[0m         command_executor\u001B[38;5;241m=\u001B[39mChromeRemoteConnection(\n\u001B[1;32m     79\u001B[0m             remote_server_addr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice\u001B[38;5;241m.\u001B[39mservice_url,\n\u001B[1;32m     80\u001B[0m             keep_alive\u001B[38;5;241m=\u001B[39mkeep_alive),\n\u001B[1;32m     81\u001B[0m         desired_capabilities\u001B[38;5;241m=\u001B[39mdesired_capabilities)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:81\u001B[0m, in \u001B[0;36mService.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m err\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[0;32m---> 81\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m WebDriverException(\n\u001B[1;32m     82\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m executable needs to be in PATH. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m     83\u001B[0m                 os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_error_message)\n\u001B[1;32m     84\u001B[0m         )\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m err\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mEACCES:\n\u001B[1;32m     86\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m WebDriverException(\n\u001B[1;32m     87\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m executable may have wrong permissions. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m     88\u001B[0m                 os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_error_message)\n\u001B[1;32m     89\u001B[0m         )\n",
      "\u001B[0;31mWebDriverException\u001B[0m: Message: 'chromedriverMAC' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n"
     ]
    }
   ],
   "source": [
    "html1 = get_HTML_selenium(url, 'mac')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Nearest neighbor density ratio estimation for large-scale applications in astronomy - ScienceDirect\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing math: 12%\n",
      "\n",
      "      JavaScript is disabled on your browser.\n",
      "      Please enable JavaScript to use all the features on this page.\n",
      "      \n",
      "\n",
      "Skip to main content\n",
      "Skip to article\n",
      "\n",
      "ScienceDirectJournals & BooksHelpSearchInstitutionRegisterSign in PDFView PDFDownload Full IssueView Open ManuscriptOther access optionsNavigate DownSearchOutlineAbstractKeywords1. Introduction2. Kernel-based density ratio estimation3. Nearest neighbor density ratio estimation revisited4. Experiments5. ConclusionAcknowledgmentsReferencesShow full outlineNavigate DownCited By (20)Figures (5)Astronomy and ComputingVolume 12, September 2015, Pages 67-72Full length articleNearest neighbor density ratio estimation for large-scale applications in astronomyAuthor links open overlay panelJ.KremeraPersonEnvelopeF.GiesekebK.Steenstrup PedersenacC.IgelacShow moreNavigate DownListOutlinePlusAdd to MendeleyShareShareCited ByCitehttps://doi.org/10.1016/j.ascom.2015.06.005Get rights and contentAbstractIn astronomical applications of machine learning, the distribution of objects used for building a model is often different from the distribution of the objects the model is later applied to. This is known as sample selection bias, which is a major challenge for statistical inference as one can no longer assume that the labeled training data are representative. To address this issue, one can re-weight the labeled training patterns to match the distribution of unlabeled data that are available already in the training phase. There are many examples in practice where this strategy yielded good results, but estimating the weights reliably from a finite sample is challenging. We consider an efficient nearest neighbor density ratio estimator that can exploit large samples to increase the accuracy of the weight estimates. To solve the problem of choosing the right neighborhood size, we propose to use cross-validation on a model selection criterion that is unbiased under covariate shift. The resulting algorithm is our method of choice for density ratio estimation when the feature space dimensionality is small and sample sizes are large. The approach is simple and, because of the model selection, robust. We empirically find that it is on a par with established kernel-based methods on relatively small regression benchmark datasets. However, when applied to large-scale photometric redshift estimation, our approach outperforms the state-of-the-art.Navigate LeftPrevious article in issueNext article in issueNavigate RightKeywordsMethods: data analysisMethods: statisticalGalaxies: distances and redshiftsSample selection biasNearest neighborsLarge-scale learning1. IntroductionIn many machine learning applications labeled (training) and unlabeled (test) data do not follow the same distribution. One reason can be that the labeled patterns have not been sampled randomly. In astronomy such a sample selection bias arises because objects that are expected to show more interesting properties are preferred when it comes to costly high-quality spectroscopic follow-up observations; other objects whose scientific value may not be that obvious (e.g., seemingly star-like objects) may be overlooked (Mortlock et al., 2011). One way to address this bias is to weight the labeled training sample according to the ratio between the two probability distributions (Huang et al., 2007). As this true ratio is usually not available, one has to estimate it from a finite sample. The crucial point is to control the variance of the estimator. Empirically, it seems promising to reduce the variance of the estimator by accepting a slightly higher bias (Sugiyama et al., 2008). This gives rise to ratio estimators that, in practice, perform better than the naïve approach of estimating the two densities separately.In this work, we improve a simple nearest neighbor density ratio estimator (Lima et al., 2008) by combining it with a principled way of performing model selection (Sugiyama and Müller, 2005). The approach compares well to established kernel-based estimators on a variety of standard, small-sized regression datasets. Furthermore, by selecting proper hyperparameters and by taking huge amounts of patterns into account, we experimentally show that the estimator yields better results compared to the state-of-the-art on a large-scale astronomical dataset.Let each data point be represented by a feature vector x from a domain X with a corresponding label y from a domain Y. We consider scenarios in which the learner has access to some labeled (source) data S sampled from ps(x,y) and a large sample of unlabeled (target) data T sampled from pt(x,y). While ps(x,y) and pt(x,y) may not coincide, we assume that ps(y|x)=pt(y|x) for all x and that the support of pt is a subset of the support of ps. This is usually referred to as covariate shift, a particular type of sample selection bias. In this case the probability density ratio between target and source distribution at a given point reduces to β(x)=pt(x)ps(x).Different strategies have been proposed to address covariate shift, such as finding a common feature space or re-weighting the source patterns. The latter is conceptually simple, and there are several approaches to estimate appropriate weights via density ratio estimation (Huang et al., 2007, Lima et al., 2008, Sugiyama and Müller, 2005, Bickel et al., 2007, Cortes et al., 2008, Loog, 2012, Quionero-Candela et al., 2009, Izbicki et al., 2014, Kanamori et al., 2009). These methods are, for example, based on reducing the problem to probabilistic classification between the target and source dataset (Bickel et al., 2007), on using kernel-based methods to match means in an induced Hilbert space (Huang et al., 2007), or on using nearest neighbor queries to estimate the mismatch between the densities by counting patterns in local regions (Lima et al., 2008, Loog, 2012). It is crucial to control the variance of such an estimator via regularization. Depending on the algorithm at hand, the regularization can take the form of, for example, a kernel bandwidth (Huang et al., 2007), the rank of a low-rank kernel matrix approximation (Izbicki et al., 2014), or a weight norm (Kanamori et al., 2009). The involved parameters are often set by heuristics such as the median of pairwise distances for the kernel bandwidth (Schölkopf and Smola, 2002). As an alternative,  Sugiyama and Müller (2005) suggest a model selection criterion that is unbiased under covariate shift. In the following, we employ this criterion for selecting the neighborhood size of the nearest neighbor estimator via cross-validation. Then, we empirically show that the resulting algorithm can outperform the computationally more expensive state-of-the-art kernel-based estimator due to its ability to consider larger samples in less time.This article is structured as follows: in Section  2 we briefly discuss two state-of-the-art kernel-based estimators that serve as a baseline in our experimental evaluation. In Section  3 we present a nearest neighbor-based density ratio estimator and show how it can be extended to perform automatic model selection. In Section  4 we evaluate the proposed nearest neighbor density ratio estimator with integrated model selection in comparison to other methods on a medium-sized regression benchmark and on a large-scale astronomical dataset for photometric redshift estimation. In Section  5 we conclude and give possible directions for future work.2. Kernel-based density ratio estimationIn density ratio estimation, kernel-based estimators are considered the state-of-the-art (Sugiyama et al., 2010). Among these, kernel mean matching (KMM) (Huang et al., 2007) and the spectral series estimator (Izbicki et al., 2014) have shown to perform particularly well.Given some input space X, a kernel is a positive semi-definite function k:X×X→R for which ∀x,z∈X:k(x,z)=〈Φ(x),Φ(z)〉H, where Φ:X→H maps elements of the input space to a kernel-induced Hilbert space H  (Aronszajn, 1950). Kernel mean matching aims at matching the means of two distributions in H by solving the problem(1)minimizeβ‖1Ns∑i=1NsβiΦ(xi(s))−1Nt∑i=1NtΦ(xi(t))‖H2(2)subject toβi∈[0,B]and|∑i=1Nsβi−Ns|≤Nsϵ, where Ns is the number of source domain patterns and Nt is the number of target domain patterns. The parameter B restricts the maximum possible weight and ϵ bounds the deviation of the mean weight from 1.  Cortes et al. (2008) show that the solution to Eq.  (1) converges with high probability to the true density ratio if the kernel induced by Φ(x) is universal (Steinwart and Christmann, 2008). The kernel function, which implicitly defines Φ and H, is typically chosen from a parameterized family of functions, and the kernel parameters are parameters of KMM-based approaches.The spectral series estimator (Izbicki et al., 2014), although motivated differently, minimizes an unconstrained version of Eq.  (1) for computing training weights. Instead of bounding the weights via B and their mean via ϵ, the solution is regularized by the rank J of a low-rank approximation of the kernel Gram matrix between training points—which results when expanding Eq.  (1). Unlike KMM, the spectral series estimator can compute weights not only for the source sample, but also for arbitrary patterns. This allows for selecting the kernel parameters and J via cross-validation, as we shall see later.Negative theoretical results in the analysis of weighting methods (Ben-David et al., 2010, Ben-David and Urner, 2012) suggest that sample sizes have to be prohibitively large to guarantee reliable weights. However, empirically it has been found that re-weighting often does improve results. Our method is motivated by typical tasks in astronomy, where we deal with large labeled samples and huge unlabeled samples in feature spaces of relatively low dimensionality (e.g., up to R10). For such rather benign scenarios, we aim at estimating weights with high accuracy by taking into account hundreds of thousands of labeled and unlabeled patterns. However, both KMM as well as the spectral series estimator involve |S|×|T| kernel matrices in their general form. Thus, they are not directly applicable to scenarios with hundreds of thousands of patterns. Special cases might be addressed in a more efficient way. Still, the general cases with non-linear kernel functions involve the computation of such kernel matrices and, depending on the method, quadratic programming, matrix inversion, or eigenvalue decomposition, which exhibit at least a quadratic running time (Bern and Eppstein, 2001, Golub and Van Loan, 1989, Kojima et al., 1989). Therefore, we are considering nearest neighbor-based density ratio estimation, which can be implemented more efficiently.For the matrix decompositions in the spectral series estimator we used an efficient O(n2)-algorithm (Dhillon, 1998). Both, decomposition as well as the nearest neighbor search, could be sped up by using approximation schemes (e.g., see  Arya et al., 1994, Halko et al., 2011), but we decided not to introduce such approximations with corresponding hyperparameters in our study.3. Nearest neighbor density ratio estimation revisitedWe consider the algorithm proposed by  Lima et al. (2008) to estimate appropriate ratios via nearest neighbor queries, see Algorithm 1. The efficiency of the approach is ensured via the use of k–d  trees. For the sake of completeness, we briefly sketch how these spatial data structures can be used to speed up nearest neighbor search before outlining the details of the density ratio estimator.3.1. Nearest neighbor search in low dimensionsA classical k – d   tree  (Bentley, 1975) is a binary tree constructed from a d-dimensional point set S⊂Rd. The inner nodes correspond to hyperplanes splitting the data in Rd and the leaf nodes define a partitioning of S. The tree can be built recursively in O(|S|log|S|) time. Starting from the root node numbered by 0 and S0=S, each inner node v with children u and w partitions the data Sv into two almost equal-sized subsets Su and Sw. If Sv contains only a single point (or a predefined number of points), v becomes a leaf node. At tree level j, the datasets are split according to the median in dimension jmodd+1.To efficiently search for the nearest neighbor of a given query point q∈Rd, one can make use of the hierarchical subdivision induced by a k–d  tree: The tree is traversed in two phases. During the first phase, the tree is processed from top to bottom to find the d-dimensional leaf (box) that contains the query point (the search is guided by the median values). The query point is then compared with all points that are stored in the corresponding leaf, which yields the first nearest neighbor candidate. Afterwards, in the second phase, the tree is processed from bottom to top and on the way back to the root, neighboring boxes are checked for points that are potentially closer to q than the current candidate. In case the distance of q to the splitting hyperplane is larger than the distance between q and its current nearest neighbor candidate, one can safely ignore the whole subtree that has not yet been visited. These distance checks can be performed efficiently by resorting to the associated median values. The generalization to k>1 neighbors is straightforward (see, e.g.,  Bentley, 1975, or  Gieseke et al., 2014, for details).In the best case, all nearest neighbors are contained in the leaf that stems from the first phase and no further subtrees need to be processed on the way back to the root. For such queries, the runtime is logarithmic in the number |S| of points. This also holds for the expected case as shown by  Friedman et al. (1977) (given constant d). In the worst case, however, the complete k–d  tree needs to be processed, which leads to a linear instead of a logarithmic runtime per query. From a practical perspective, the running time depends on the dimensionality of the feature space: for moderate dimensions (e.g., up to d=30), a logarithmic running time behavior can be expected, while for larger d the performance often decreases significantly due to the curse of dimensionality  (Hastie et al., 2009).3.2. Nearest neighbor density ratio estimatorWe are now ready to outline the details of Algorithm 1: In Step 1, k–d  trees for the source and target patterns are built. In Steps 2 to 8, all query patterns xj(q) are processed. For each query pattern, the K nearest neighbors w.r.t. the source patterns in S are computed. This is followed by the computation of the number lj of nearest neighbors in T whose distance to xj(q) is less than or equal to the previously computed Kth nearest neighbor. Finally, this result is re-weighted according to the number Ns of source patterns, the number Nt of target patterns and the number K of nearest neighbors. Hence, the true density ratio β(xj(q)) of target and source distribution at a point xj(q) in the feature space Rd is approximated via(3)β̂(xj(q))=lj⋅NsK⋅Nt.Download : Download high-res image (432KB)Download : Download full-size imageAs k–d  trees speed up nearest neighbor computation for low-dimensional feature spaces, we get good running time results in this scenario: the construction of the trees for the source and target patterns takes O(NslogNs) and O(NtlogNt) time, respectively. For each query pattern, nearest neighbors are computed via these trees. The number K of neighbors is crucial for the accuracy of the algorithm, and the question of how to choose it is not discussed by  Lima et al. (2008). We propose to select K via cross-validation by minimizing the model selection criterion proposed in  Sugiyama and Müller (2005). It seeks to minimize the least-squares error between true and estimated density ratio, as in regression. However, we usually do not have access to the true density ratio. Therefore, we use a substitution to estimate the minimizer of the least-squares error up to a constant. The expected least-squares loss between true and estimated density ratio over the source probability density ps(x) is given by (4)L(β,β̂)=∫(β(x)−β̂(x))2ps(x)dx=∫β̂(x)2ps(x)dx−2∫β̂(x)β(x)ps(x)dx+∫β(x)2ps(x)dx=∫β̂(x)2ps(x)dx−2∫β̂(x)pt(x)dx+∫β(x)2ps(x)dx, where we substituted the true density ratio β(x)=pt(x)ps(x). As the third term does not depend on the estimated ratio β̂(x), we can estimate L(β,β̂) up to a constant by (5)L̂(β,β̂)=1|S|∑x∈Sβ̂(x)2−2|T|∑x∈Tβ̂(x). Here, we have replaced the expectations in the first two terms by their empirical estimates. As long as ps(x) and pt(x) do not change, the constant term in Eq.  (5) will not change and thus, we can safely ignore it when comparing different weight estimates β̂.It is important to note that we evaluate Eq.  (5)   post hoc on trained density ratio estimators. Direct unconstrained minimization of Eq.  (5) with respect to β̂(x) for x∈S (i.e., the values needed for re-weighted training) would lead to the trivial solution β̂(x)=0 for x∈S. An open-source Python package of the nearest neighbor estimator with integrated model selection is available on Github.14. ExperimentsWe consider two experiments: re-weighted regression on standard domain adaptation benchmarks and weight computation for photometric redshift estimation.4.1. Regression benchmarksWe compared our approach to kernel mean matching (KMM) (Huang et al., 2007) and the spectral series estimator (Izbicki et al., 2014) following the protocol of the experiments in  Cortes et al. (2008). For each of the eight regression datasets, which are rather small (the largest having 16 512 labeled and 9511 unlabeled patterns), we created a biased subset S of the original dataset T. As defined in  Cortes et al. (2008), each point is moved from T to S with probability (6)p(s=1|x)=ev1+ev, where v is defined as (7)v=4w⋅(x−x¯)Var(w⋅(x−x¯)), for a pattern x∈Rd, and w∈Rd chosen uniformly at random from [−1,1]d. Thus, the bias is only determined by the covariate x. The ideal method, which we consider as a baseline, weights the points in S with 1p(s=1|x). For each dataset, we selected the w that maximized the difference in regression loss between ideal and unweighted method among 10 trials.After having estimated the weights, we use them to re-weight the loss function of a linear regularized least-squares estimator. Here, we select the regularization parameter λ∈{2n:n∈{−3,…,4}} via leave-one-out cross-validation. Since KMM has no mechanism for automatically choosing its hyperparameter, we chose the bandwidth σ=d/2 for x∈Rd  (Cortes et al., 2008). For the spectral series estimator and the nearest neighbor method, we chose their parameters by performing 5-fold cross-validation using Eq.  (5). We selected the bandwidth parameter ϵ of the spectral series estimator from {ϵ0−1,ϵ00,ϵ01,ϵ02}, with ϵ0=median({‖x−y‖22:x,y∈S})/8  (Schölkopf and Smola, 2002), and the rank J from {1,…,⌊Ns×4/5⌋}. For the nearest neighbor estimator we selected a K∈{2,3,4,5,8,16,32} and also considered a variant with fixed K=2 to demonstrate the influence of model selection (the value K=2 corresponds to the most frequent choice for K in the model selection algorithm).Fig. 1 shows the relative normalized mean squared error (NMSE) and the standard deviation over 10 different trials for each method on a test set not used for training or estimation of weights. For each dataset we scaled the results linearly so that the unweighted NMSE yielded 1.0. The weighted methods almost always perform better than unweighted regression. Although the sample sizes are small, the nearest neighbor estimator performs on a par with the kernel methods among which the spectral series estimator performs best. Because of the sample sizes, our method cannot tap its full potential and using a fixed K=2 seems to be a viable approach. However, the picture changes when moving to our real-world large-scale application.Download : Download high-res image (248KB)Download : Download full-size imageFig. 1. The relative normalized mean squared errors (NMSE) for kernel- and nearest neighbor-based ratio estimators on different regression datasets. The error bars indicate the standard deviations over 10 different samplings using the selection probability p(s=1|x) for a fixed w.4.2. Redshift estimationWe evaluated our method on a large-scale astronomical dataset (Izbicki et al., 2014). The problem we consider is photometric redshift estimation of galaxies. The redshift phenomenon is caused by the Doppler effect which shifts the spectrum of an object towards longer wavelengths if it is moving away from the observer. Because the universe is expanding uniformly, we can infer a galaxy’s velocity by its redshift and, thus, its distance to Earth. Hence, redshift estimation is a useful tool for determining the geometry of the universe. A photometric observation contains the intensities of an object (in our case, galaxies) in 5 different bands (u, g, r, i, z), ranging from ultraviolet to infrared. Spectroscopy, in contrast, measures the photon count at certain wavelengths. The resulting spectrum allows for identifying the chemical components of the observed object and thus, enables determining many interesting properties, including the redshift. Spectroscopy, however, is much more time-consuming than photometric observation and therefore, costs could be greatly reduced if we could predict suitable candidates for follow-up spectroscopy from low-quality low-cost photometry. Fig. 2 shows examples of corresponding photometric and spectroscopic observations.Download : Download high-res image (351KB)Download : Download full-size imageFig. 2. An example from the Sloan Digital Sky Survey (SDSS) (Aihara et al., 2011). (a) An image of the spiral galaxy NGC 5750. (b) Its associated spectrum overlapping the five photometric intensity band filters u, g, r, i, z.For each of the 5 bands a point spread function (model) and a composite model (cmodel) are fit to the photometric observation. We take the 4 magnitude differences between adjacent bands and the magnitude in the red band for model and cmodel. Thus, we arrive at 2×(4+1)=10 covariates for each galaxy. The dataset contains a sample of 467 710 galaxies whose redshift has been confirmed by spectroscopy and an unconfirmed sample of 540 237 galaxies. The task is to estimate the redshift of the unconfirmed (target) sample by training on the spectroscopically confirmed (source) sample. As we do not have ground-truth labels for the target sample, we simply recorded the estimated loss given by Eq.  (5) as in  Izbicki et al. (2014), see Fig. 3. Interestingly, the absolute estimates are more accurate when we consider the dataset as-is. In Fig. 3(b) we consider a preprocessed dataset where we standardized the covariates to have zero mean and unit variance, as is common for methods that rely on pattern distances. Here, we see that the nearest neighbor estimator with model selection outperforms the other methods even clearer, although the absolute estimated loss is higher than the one for the original data, see Fig. 3(a). If the task can benefit from re-weighting, then the performance is likely to improve with more accurate weights.Download : Download high-res image (264KB)Download : Download full-size imageFig. 3. The estimated loss for the nearest neighbor and spectral series estimator on an astronomical dataset typically used in the context of photometric redshift estimation. (a) The original dataset. (b) Results with covariates transformed to have zero mean and unit variance.In our experiment, we trained the ratio estimators with increasing sample sizes from 5000 to 400 000 patterns (each from source and target sample) and estimated the weights on hold-out test samples of size 50 000 (source and target) not used for training. As KMM cannot produce out-of-sample weights, we only compared the nearest neighbor estimator (with K either being fixed or chosen by model selection) and the spectral series estimator using the same parameters as in the first experiment. As running times become prohibitively large for the spectral series estimator, we only recorded it up to sample sizes of 20 000 patterns. Fig. 4 shows the running time per sample size on an AMD Opteron 6380. The time measured includes the time used for cross-validation on a single-core machine. It should be noted that the cross-validation procedure is parallelizable to the point that its additional costs for the gained accuracy are minimal. For comparable running times the nearest neighbor estimator is able to use more samples than the spectral series estimator and thus, estimate weights more accurately. Furthermore, selecting the parameter K via cross-validation performs better than our default choice K=2 (which was the most frequently selected value in the model selection experiments on the benchmark datasets).Download : Download high-res image (162KB)Download : Download full-size imageFig. 4. The running times per sample size for the different estimators, including the time used for cross-validation. The nearest neighbor estimators can utilize considerably larger samples than the spectral series estimator given the same time constraints.5. ConclusionSample selection bias is a common problem in astronomy (Richards et al., 2012), where datasets are typically large and the feature space dimensionality is often low. For this scenario, we suggest to use a nearest neighbor density ratio estimator combined with a model selection criterion, which is unbiased under covariate shift, for choosing the neighborhood size. The resulting algorithm is simple, robust due to the systematic hyperparameter choice, and–as we experimentally demonstrate–highly efficient and accurate. Future work will consider the theoretical properties of the estimator and an implementation on GPUs (Gieseke et al., 2014) for handling datasets with billions of patterns efficiently and at low cost.AcknowledgmentsThe authors gratefully acknowledge support from The Danish Council for Independent Research through the project SkyML (FNU 12-125149). The authors also would like to thank R. Izbicki for providing the astronomical dataset. Funding for SDSS-III has been provided by the Alfred P. Sloan Foundation, the Participating Institutions, the National Science Foundation, and the US Department of Energy Office of Science. The SDSS-III web site is http://www.sdss3.org/.SDSS-III is managed by the Astrophysical Research Consortium for the Participating Institutions of the SDSS-III Collaboration including the University of Arizona, the Brazilian Participation Group, Brookhaven National Laboratory, Carnegie Mellon University, University of Florida, the French Participation Group, the German Participation Group, Harvard University, the Instituto de Astrofisica de Canarias, the Michigan State/Notre Dame/JINA Participation Group, Johns Hopkins University, Lawrence Berkeley National Laboratory, Max Planck Institute for Astrophysics, Max Planck Institute for Extraterrestrial Physics, New Mexico State University, New York University, Ohio State University, Pennsylvania State University, University of Portsmouth, Princeton University, the Spanish Participation Group, University of Tokyo, University of Utah, Vanderbilt University, University of Virginia, University of Washington, and Yale University.Recommended articlesReferencesAihara et al., 2011H. Aihara, C.A. Prieto, D. An, S.F. Anderson, É. Aubourg, E. Balbinot, T.C. Beers, A.A. Berlind, S.J. Bickerton, D.e.a. BizyaevThe eighth data release of the sloan digital sky survey: first data from sdss-iiiAstrophys. J. Suppl. Ser., 193 (2011), p. 29CrossRefGoogle ScholarAronszajn, 1950N. AronszajnTheory of reproducing kernelsTrans. Amer. Math. Soc., 68 (1950), pp. 337-404Google ScholarArya et al., 1994S. Arya, D.M. Mount, N. Netanyahu, R. Silverman, A.Y. WuAn optimal algorithm for approximate nearest neighbor searching in fixed dimensionsJ. ACM, 45 (1994), pp. 891-923Google ScholarBen-David et al., 2010S. Ben-David, T. Lu, T. Luu, D. PálImpossibility theorems for domain adaptationProceedings of the International Conference on Artificial Intelligence and Statistics, AISTATS, JMLR W&CP (2010), pp. 129-136Google ScholarBen-David and Urner, 2012S. Ben-David, R. UrnerOn the hardness of domain adaptation and the utility of unlabeled target samplesAlgorithmic Learning Theory, Springer (2012), pp. 139-153CrossRefView Record in ScopusGoogle ScholarBentley, 1975J. BentleyMultidimensional binary search trees used for associative searchingCommun. ACM, 18 (1975), pp. 509-517Google ScholarBern and Eppstein, 2001M.W. Bern, D. EppsteinOptimization over zonotopes and training support vector machinesProceedings of the Workshop on Algorithms and Data Structures, Springer (2001), pp. 111-121CrossRefView Record in ScopusGoogle ScholarBickel et al., 2007S. Bickel, M. Brückner, T. SchefferDiscriminative learning for differing training and test distributionsProceedings of the International Conference on Machine Learning, ICML, ACM (2007), pp. 81-88CrossRefGoogle ScholarCortes et al., 2008C. Cortes, M. Mohri, M. Riley, A. RostamizadehSample selection bias correction theoryAlgorithmic Learning Theory, Springer (2008), pp. 38-53CrossRefGoogle ScholarDhillon, 1998I.S. DhillonA New O(n2) Algorithm for the Symmetric Tridiagonal Eigenvalue Eigenvector Problem(Ph.D. thesis)University of California at Berkeley, Berkeley, CA, USA (1998)UMI Order No. GAX98-03176Google ScholarFriedman et al., 1977J.H. Friedman, J.L. Bentley, R.A. FinkelAn algorithm for finding best matches in logarithmic expected timeACM Trans. Math. Software, 3 (1977), pp. 209-226Google ScholarGieseke et al., 2014F. Gieseke, J. Heinermann, C. Oancea, C. IgelBuffer k–d trees: Processing massive nearest neighbor queries on GPUsProceedings of the International Conference on Machine Learning, ICML, JMLR W&CP (2014), pp. 172-180View Record in ScopusGoogle ScholarGolub and Van Loan, 1989G.H. Golub, C. Van LoanMatrix Computations (second ed), Johns Hopkins University Press (1989)Google ScholarHalko et al., 2011N. Halko, P.G. Martinsson, J.A. TroppFinding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositionsSIAM Rev., 53 (2011), pp. 217-288CrossRefView Record in ScopusGoogle ScholarHastie et al., 2009T. Hastie, R. Tibshirani, J. FriedmanThe Elements of Statistical LearningSpringer (2009)Google ScholarHuang et al., 2007J. Huang, A.J. Smola, A. Gretton, K. Borgwardt, B. SchölkopfCorrecting sample selection bias by unlabeled dataAdvances in Neural Information Processing Systems, NIPS, MIT Press (2007), pp. 601-608Google ScholarIzbicki et al., 2014R. Izbicki, A.B. Lee, C.M. SchaferHigh-dimensional density ratio estimation with extensions to approximate likelihood computationProceedings of the International Conference on Artificial Intelligence and Statistics, AISTATS, JMLR W&CP (2014), pp. 420-429Google ScholarKanamori et al., 2009T. Kanamori, S. Hido, M. SugiyamaA least-squares approach to direct importance estimationJ. Mach. Learn. Res., 10 (2009), pp. 1391-1445View Record in ScopusGoogle ScholarKojima et al., 1989M. Kojima, S. Mizuno, A. YoshiseA polynomial-time algorithm for a class of linear complementarity problemsMath. Program., 44 (1989), pp. 1-26View Record in ScopusGoogle ScholarLima et al., 2008M. Lima, C.E. Cunha, H. Oyaizu, J. Frieman, H. Lin, E.S. SheldonEstimating the redshift distribution of photometric galaxy samplesMon. Not. R. Astron. Soc., 390 (2008), pp. 118-130CrossRefView Record in ScopusGoogle ScholarLoog, 2012M. LoogNearest neighbor-based importance weightingProceedings of the International Workshop on Machine Learning for Signal Processing, MLSP, IEEE Press (2012), pp. 1-6CrossRefGoogle ScholarMortlock et al., 2011D.J. Mortlock, S.J. Warren, B.P. Venemans, M. Patel, P.C. Hewett, R.G. McMahon, C. Simpson, T. Theuns, E.A. Gonzales-Solares, A. Adamson, S. Dye, N.C. Hambly, P. Hirst, M.J. Irwin, E. Kuiper, A. Lawrence, H.J.A. RottgeringA luminous quasar at a redshift of z=7.085Nature, 474 (2011), pp. 616-619CrossRefView Record in ScopusGoogle ScholarQuionero-Candela et al., 2009J. Quionero-Candela, M. Sugiyama, A. Schwaighofer, N. LawrenceDataset Shift in Machine LearningMIT Press (2009)Google ScholarRichards et al., 2012J.W. Richards, D.L. Starr, H. Brink, A.A. Miller, J.S. Bloom, N.R. Butler, J.B. James, J.P. Long, J. RiceActive learning to overcome sample selection bias: Application to photometric variable star classificationAstrophys. J., 744 (2012)Google ScholarSchölkopf and Smola, 2002B. Schölkopf, A. SmolaLearning with Kernels: Support Vector Machines, Regularization, Optimization, and BeyondMIT Press (2002)Google ScholarSteinwart and Christmann, 2008I. Steinwart, A. ChristmannSupport Vector Machines Information Science and StatisticsSpringer-Verlag (2008)Google ScholarSugiyama and Müller, 2005M. Sugiyama, K.R. MüllerModel selection under covariate shiftProceedings of the International Conference on Artificial Neural Networks, ICANN, Springer (2005), pp. 235-240CrossRefView Record in ScopusGoogle ScholarSugiyama et al., 2008M. Sugiyama, S. Nakajima, H. Kashima, P.V. Bünau, M. KawanabeDirect importance estimation with model selection and its application to covariate shift adaptationAdvances in Neural Information Processing Systems, NIPS, MIT Press (2008), pp. 1433-1440Google ScholarSugiyama et al., 2010M. Sugiyama, T. Suzuki, T. KanamoriDensity ratio estimation: A comprehensive reviewStatistical Experiment and its Related Topics (2010), pp. 10-31View Record in ScopusGoogle ScholarCited by (20)Estimation based on nearest neighbor matching: From density ratio to average treatment effect2021, arXivStratified learning: A general-purpose statistical method for improved learning under covariate shift2021, arXivA Review of Domain Adaptation without Target Labels2021, IEEE Transactions on Pattern Analysis and Machine IntelligenceUnsupervised calibration under covariate shift2020, arXivGaussian mixture models for blended photometric redshifts2019, Monthly Notices of the Royal Astronomical SocietyUse of GIS tools in sustainable heritage management-the importance of data generalization in spatial modeling2019, Sustainability (Switzerland)Arrow Up and RightView all citing articles on Scopus1https://github.com/kremerj/nnratio.View AbstractCopyright © 2015 Elsevier B.V. All rights reserved.Recommended articlesNavigate DownField emission property of ZnO nanowires prepared by ultrasonic spray pyrolysisSuperlattices and Microstructures, Volume 84, 2015, pp. 144-153PDFDownload PDFView detailsNavigate DownRole of Methadone in Induction and/or Exacerbation of Cluster Headache in Patients Treated for Opioid AddictionTherapies, Volume 70, Issue 3, 2015, pp. 305-307PDFPurchase PDFView detailsNavigate DownAn Innovative Tool for Technical, Environmental and Economic Design of Building Energy Plants: A Case Study in UmbriaEnergy Procedia, Volume 82, 2015, pp. 652-658PDFDownload PDFView detailsNavigate Down12NextNavigate RightArticle MetricsNavigate DownView article metricsAbout ScienceDirectRemote accessShopping cartAdvertiseContact and supportTerms and conditionsPrivacy policyWe use cookies to help provide and enhance our service and tailor content and ads. By continuing you agree to the use of cookies.Copyright © 2022 Elsevier B.V. or its licensors or contributors. ScienceDirect® is a registered trademark of Elsevier B.V.ScienceDirect® is a registered trademark of Elsevier B.V.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup1 = BeautifulSoup(html1, 'html.parser')\n",
    "print(soup1.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser closed in 22.284823179244995 seconds, including 5 seconds of waiting, thus 17.284823179244995 seconds of loading.\n",
      "Testing accessing title:\n",
      "Nearest neighbor density ratio estimation for large-scale applications in astronomy\n"
     ]
    }
   ],
   "source": [
    "def quick_Selenium_Test():\n",
    "    html = get_HTML_selenium('https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub', 'mac')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title_test = soup.find('span', class_='title-text').text.strip()\n",
    "    print('Testing accessing title:')\n",
    "    print(title_test)\n",
    "\n",
    "    assert title_test == 'Nearest neighbor density ratio estimation for large-scale applications in astronomy', f'Expted title not matched'\n",
    "\n",
    "\n",
    "quick_Selenium_Test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B: Trying helium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_HTML_helium(url):\n",
    "    \"\"\"\n",
    "    Get HTML from a website using helium and ChromeDriver. Helium is a lightweight Selenium adapter. It comes with simple wait and click functions.\n",
    "    Method runs headless per default and has JS activated. By adding arguments the method mimics a user so that Elesevier returns the full HTML and allows loading.\n",
    "    Be aware that this method is quite slow and schould only be used if classic requests method cannot access information thus only use that for dynamic data.\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ## helium does not work for science direct, so we use selenium instead => works!\n",
    "    url = 'https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub'\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Tricking Elsevier\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=chrome\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    #options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    browser = start_chrome(url, options=options)\n",
    "\n",
    "    wait_until_start = time.time()\n",
    "    wait_until(lambda: not Text(\"Loading...\").exists(), timeout_secs=10, interval_secs=0.5)\n",
    "    wait_until_end = time.time()\n",
    "\n",
    "    html = browser.page_source\n",
    "    kill_browser()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Waited {wait_until_end - wait_until_start} seconds for the wait_until method')\n",
    "    print(f'and Total waiting time: {end - start} seconds')\n",
    "    return html\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: Service /Users/leoncena/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/webdrivers/mac/chromedriver unexpectedly exited. Status code was: -9\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:72\u001B[0m, in \u001B[0;36mService.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     71\u001B[0m     cmd\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_line_args())\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess \u001B[38;5;241m=\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcmd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplatform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msystem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWindows\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstdout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstderr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mstdin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mPIPE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/subprocess.py:951\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001B[0m\n\u001B[1;32m    948\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mTextIOWrapper(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstderr,\n\u001B[1;32m    949\u001B[0m                     encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[0;32m--> 951\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    952\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    953\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    954\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    955\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    956\u001B[0m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    957\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    958\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    959\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    960\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m    961\u001B[0m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/subprocess.py:1821\u001B[0m, in \u001B[0;36mPopen._execute_child\u001B[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001B[0m\n\u001B[1;32m   1820\u001B[0m         err_msg \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mstrerror(errno_num)\n\u001B[0;32m-> 1821\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001B[1;32m   1822\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m child_exception_type(err_msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'chromedriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mWebDriverException\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/__init__.py:106\u001B[0m, in \u001B[0;36mAPIImpl._start_chrome_driver\u001B[0;34m(self, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 106\u001B[0m \tresult \u001B[38;5;241m=\u001B[39m \u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchrome_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesired_capabilities\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapabilities\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m WebDriverException:\n\u001B[1;32m    108\u001B[0m \t\u001B[38;5;66;03m# This usually happens when chromedriver is not on the PATH.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:73\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice \u001B[38;5;241m=\u001B[39m Service(\n\u001B[1;32m     69\u001B[0m     executable_path,\n\u001B[1;32m     70\u001B[0m     port\u001B[38;5;241m=\u001B[39mport,\n\u001B[1;32m     71\u001B[0m     service_args\u001B[38;5;241m=\u001B[39mservice_args,\n\u001B[1;32m     72\u001B[0m     log_path\u001B[38;5;241m=\u001B[39mservice_log_path)\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:81\u001B[0m, in \u001B[0;36mService.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m err\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mENOENT:\n\u001B[0;32m---> 81\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m WebDriverException(\n\u001B[1;32m     82\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m executable needs to be in PATH. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\n\u001B[1;32m     83\u001B[0m             os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mbasename(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstart_error_message)\n\u001B[1;32m     84\u001B[0m     )\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m err\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m==\u001B[39m errno\u001B[38;5;241m.\u001B[39mEACCES:\n",
      "\u001B[0;31mWebDriverException\u001B[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mWebDriverException\u001B[0m                        Traceback (most recent call last)",
      "Input \u001B[0;32mIn [20]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m html \u001B[38;5;241m=\u001B[39m \u001B[43mget_HTML_helium\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [19]\u001B[0m, in \u001B[0;36mget_HTML_helium\u001B[0;34m(url)\u001B[0m\n\u001B[1;32m     20\u001B[0m options\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--start-maximized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m options\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwindow-size=1920,1080\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m browser \u001B[38;5;241m=\u001B[39m \u001B[43mstart_chrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m wait_until_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     25\u001B[0m wait_until(\u001B[38;5;28;01mlambda\u001B[39;00m: \u001B[38;5;129;01mnot\u001B[39;00m Text(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mexists(), timeout_secs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, interval_secs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/__init__.py:76\u001B[0m, in \u001B[0;36mstart_chrome\u001B[0;34m(url, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_chrome\u001B[39m(\n\u001B[1;32m     22\u001B[0m \turl\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, headless\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, capabilities\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     23\u001B[0m ):\n\u001B[1;32m     24\u001B[0m \t\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03m\t:param url: URL to open.\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m\t:type url: str\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m\t\tkill_browser()\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m\t\"\"\"\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_api_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_chrome_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheadless\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapabilities\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/__init__.py:101\u001B[0m, in \u001B[0;36mAPIImpl.start_chrome_impl\u001B[0;34m(self, url, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_chrome_impl\u001B[39m(\n\u001B[1;32m     97\u001B[0m \t\u001B[38;5;28mself\u001B[39m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, headless\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     98\u001B[0m \tcapabilities\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     99\u001B[0m ):\n\u001B[1;32m    100\u001B[0m \tchrome_driver \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m--> 101\u001B[0m \t\t\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_start_chrome_driver\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheadless\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapabilities\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start(chrome_driver, url)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/__init__.py:110\u001B[0m, in \u001B[0;36mAPIImpl._start_chrome_driver\u001B[0;34m(self, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m WebDriverException:\n\u001B[1;32m    108\u001B[0m \t\u001B[38;5;66;03m# This usually happens when chromedriver is not on the PATH.\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \tdriver_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_included_web_driver(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchromedriver\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 110\u001B[0m \tresult \u001B[38;5;241m=\u001B[39m \u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchrome_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesired_capabilities\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapabilities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mexecutable_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdriver_path\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m atexit\u001B[38;5;241m.\u001B[39mregister(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kill_service, result\u001B[38;5;241m.\u001B[39mservice)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:73\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001B[0m\n\u001B[1;32m     66\u001B[0m         desired_capabilities\u001B[38;5;241m.\u001B[39mupdate(options\u001B[38;5;241m.\u001B[39mto_capabilities())\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice \u001B[38;5;241m=\u001B[39m Service(\n\u001B[1;32m     69\u001B[0m     executable_path,\n\u001B[1;32m     70\u001B[0m     port\u001B[38;5;241m=\u001B[39mport,\n\u001B[1;32m     71\u001B[0m     service_args\u001B[38;5;241m=\u001B[39mservice_args,\n\u001B[1;32m     72\u001B[0m     log_path\u001B[38;5;241m=\u001B[39mservice_log_path)\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     76\u001B[0m     RemoteWebDriver\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     77\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     78\u001B[0m         command_executor\u001B[38;5;241m=\u001B[39mChromeRemoteConnection(\n\u001B[1;32m     79\u001B[0m             remote_server_addr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice\u001B[38;5;241m.\u001B[39mservice_url,\n\u001B[1;32m     80\u001B[0m             keep_alive\u001B[38;5;241m=\u001B[39mkeep_alive),\n\u001B[1;32m     81\u001B[0m         desired_capabilities\u001B[38;5;241m=\u001B[39mdesired_capabilities)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:98\u001B[0m, in \u001B[0;36mService.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     96\u001B[0m count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43massert_process_still_running\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_connectable():\n\u001B[1;32m    100\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/common/service.py:109\u001B[0m, in \u001B[0;36mService.assert_process_still_running\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    107\u001B[0m return_code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess\u001B[38;5;241m.\u001B[39mpoll()\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_code \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 109\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m WebDriverException(\n\u001B[1;32m    110\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mService \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m unexpectedly exited. Status code was: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath, return_code)\n\u001B[1;32m    112\u001B[0m     )\n",
      "\u001B[0;31mWebDriverException\u001B[0m: Message: Service /Users/leoncena/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/webdrivers/mac/chromedriver unexpectedly exited. Status code was: -9\n"
     ]
    }
   ],
   "source": [
    "html = get_HTML_helium(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waited 15.016202926635742 seconds for the wait_until method\n",
      "and Total waiting time: 26.3247127532959 seconds\n",
      "Testing accessing title:\n",
      "Nearest neighbor density ratio estimation for large-scale applications in astronomy\n"
     ]
    }
   ],
   "source": [
    "def quick_Helium_Test():\n",
    "    html = get_HTML_helium('https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title_test = soup.find('span', class_='title-text').text.strip()\n",
    "    print('Testing accessing title:')\n",
    "    print(title_test)\n",
    "\n",
    "    assert title_test == 'Nearest neighbor density ratio estimation for large-scale applications in astronomy', f'Expted title not matched'\n",
    "\n",
    "\n",
    "quick_Helium_Test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# small test if the last reference is recognized (hard-copied!)\n",
    "\n",
    "print(\"ref test\")\n",
    "print(soup.find('div', {'id': 'ref-id-sbref29'}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# misc\n",
    "Kill Helium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kill_browser()  # kills Helium browser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kill Selenium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}