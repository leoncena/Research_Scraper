{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import requests\n",
    "from scholarly import scholarly, ProxyGenerator\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Init proxy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def handle_proxy(proxy=None):\n",
    "    \"\"\"\n",
    "    Handle the procxy, by default no proxy thus None\n",
    "    :param proxy: choose whether to use proxy, we can add premium proxied if needed later\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "\n",
    "    if proxy is None:\n",
    "        scholarly.use_proxy(None)\n",
    "    elif proxy == 'free':\n",
    "        pg = ProxyGenerator()\n",
    "        success = pg.FreeProxies()\n",
    "        print(f'Free proxy success: {success}')\n",
    "        scholarly.use_proxy(pg)\n",
    "    elif proxy == 'scraper_api':\n",
    "        pg = ProxyGenerator()\n",
    "        success = pg.ScraperAPI('XXX Token XXX')\n",
    "        scholarly.use_proxy(pg)\n",
    "    else:\n",
    "        print('No proxy recognized')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Methods\n",
    "## Search author (with fill parameter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "search_query = scholarly.search_author('Fabian Gieseke, Münster')\n",
    "author = next(search_query)\n",
    "# res = scholarly.fill(author, sections=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Method: author details"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['scholar_id', 'url_picture', 'name', 'affiliation', 'email_domain', 'interests', 'citedby', 'citedby5y', 'hindex', 'hindex5y', 'i10index', 'i10index5y', 'cites_per_year', 'organization', 'homepage'])\n"
     ]
    }
   ],
   "source": [
    "def search_author_information_from_google_scholar(details, sections=['basics', 'indices', 'counts']):\n",
    "    result = scholarly.search_author(details)\n",
    "    # get first result\n",
    "    found_author = next(result)\n",
    "    filled_author = scholarly.fill(found_author, sections=sections)\n",
    "    # remove unwanted values from filled_author\n",
    "    del filled_author['container_type']\n",
    "    del filled_author['filled']\n",
    "    del filled_author['source']\n",
    "\n",
    "    return filled_author\n",
    "\n",
    "\n",
    "#handle_proxy()\n",
    "prof_gieseke = search_author_information_from_google_scholar('Fabian Gieseke, University of Munster')\n",
    "# print prof_gieseke keys\n",
    "print(prof_gieseke.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search by author id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'container_type': 'Author',\n 'filled': ['basics'],\n 'scholar_id': 'g3ZiieoAAAAJ',\n 'source': <AuthorSource.AUTHOR_PROFILE_PAGE: 'AUTHOR_PROFILE_PAGE'>,\n 'name': 'Fabian Gieseke',\n 'url_picture': 'https://scholar.googleusercontent.com/citations?view_op=view_photo&user=g3ZiieoAAAAJ&citpid=2',\n 'affiliation': 'Department of Information Systems, University of Münster',\n 'organization': 12991841939693602029,\n 'interests': ['Data Engineering', 'Maschine Learning'],\n 'email_domain': '@uni-muenster.de',\n 'homepage': 'https://www.wi.uni-muenster.de/de/institut/dasc',\n 'citedby': 1361}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author = scholarly.search_author_id('g3ZiieoAAAAJ')  # now in the short form without fill\n",
    "author"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search orga and authors by orga id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Searching for WWU as orga"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WWU Orga ID: 12991841939693602029\n"
     ]
    }
   ],
   "source": [
    "orga = scholarly.search_org('Münster')[0]  # taking first result\n",
    "wwu_orga_id = orga.get('id')\n",
    "print(f'WWU Orga ID: {wwu_orga_id}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using WWU orga id to search for authors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'container_type': 'Author',\n 'filled': [],\n 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n 'scholar_id': 'U5xmC3IAAAAJ',\n 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=U5xmC3IAAAAJ',\n 'name': 'Frank Glorius',\n 'affiliation': 'WWU Muenster',\n 'email_domain': '@uni-muenster.de',\n 'interests': ['Organic Chemistry',\n  'Photocatalysis',\n  'CH Activation',\n  'Organometallic Chemistry',\n  'Asymmetric Catalysis'],\n 'citedby': 58871}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query_author_by_orga_wwu = scholarly.search_author_by_organization(\n",
    "    wwu_orga_id)  # an iterator, you need to loop through\n",
    "author = next(search_query_author_by_orga_wwu)  # first result of iterator\n",
    "author"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search by keyword"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'container_type': 'Author',\n 'filled': [],\n 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n 'scholar_id': 'ui0P8NYAAAAJ',\n 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=ui0P8NYAAAAJ',\n 'name': 'David Rio Deiros',\n 'affiliation': 'Scientific Software Engineer, Baylor College Of Medicine',\n 'email_domain': '@bcm.edu',\n 'interests': ['bioinformatics',\n  'genomics',\n  'nextgen sequencing',\n  'visualization',\n  'data'],\n 'citedby': 10039}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query_keywords = scholarly.search_keyword('Data Engineering')\n",
    "next(search_query_keywords)  # returns first result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Search for publications (and their links, dois)\n",
    "Scholarly is a good way to find the link of a publication when we have some information. This can be used with the incomplete cris data. Unfortunately google is very fast with blocking the bot ( probably the IP?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'container_type': 'Publication',\n 'source': <PublicationSource.PUBLICATION_SEARCH_SNIPPET: 'PUBLICATION_SEARCH_SNIPPET'>,\n 'bib': {'title': 'How regular are conjugate exponential families?',\n  'author': ['U Müller-Funk', 'F Pukelsheim'],\n  'pub_year': '1989',\n  'venue': 'Statistics & probability letters',\n  'abstract': \"Given an exponential family of sampling distributions of order k, one may construct in a natural way an exponential family of conjugate (that is, prior) distributions depending on a k-dimensional parameter c and an additional weight w> 0. We compute the bias term by which the expectation of the sampling mean-value parameter under the conjugate distribution deviates from the conjugate parameter c. This bias term vanishes for regular exponential families, providing an appealing interpretation of the conjugate parameter c as a 'prior\"},\n 'filled': False,\n 'gsrank': 1,\n 'pub_url': 'https://www.sciencedirect.com/science/article/pii/016771528990117X',\n 'author_id': ['', ''],\n 'url_scholarbib': '/scholar?hl=en&q=info:MlF1C63ga7wJ:scholar.google.com/&output=cite&scirp=0&hl=en',\n 'url_add_sclib': '/citations?hl=en&xsrf=&continue=/scholar%3Fq%3DHow%2BRegular%2BAre%2BConjugate%2BExponential%2BFamilies%253F%26hl%3Den%26as_sdt%3D0,33&citilm=1&update_op=library_add&info=MlF1C63ga7wJ&ei=9LFNY4OZGo30mgHekrT4BA&json=',\n 'num_citations': 3,\n 'citedby_url': '/scholar?cites=13577192535464694066&as_sdt=5,33&sciodt=0,33&hl=en',\n 'url_related_articles': '/scholar?q=related:MlF1C63ga7wJ:scholar.google.com/&scioq=How+Regular+Are+Conjugate+Exponential+Families%3F&hl=en&as_sdt=0,33',\n 'eprint_url': 'http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.434.4946&rep=rep1&type=pdf'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query_publication = scholarly.search_pubs(\n",
    "    query='How Regular Are Conjugate Exponential Families?')\n",
    "next(search_query_publication)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the url of publication by search query"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 46.76773524284363\n"
     ]
    }
   ],
   "source": [
    "from scholarly import MaxTriesExceededException\n",
    "\n",
    "\n",
    "def get_url_from_publication_with_scholarly(search_query):\n",
    "    scholarly_search = scholarly.search_pubs(search_query)\n",
    "    publication = next(scholarly_search)\n",
    "    url = publication.get('pub_url')\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "#handle_proxy('scraper_api')\n",
    "test_url = get_url_from_publication_with_scholarly(\n",
    "    'Exploring customers’ likeliness to use e-service touchpoints in brick and mortar retail, Benjamin Barann')\n",
    "end = time.time()\n",
    "print(f'Time: {end - start}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "handle_proxy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Citedby search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [67]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m publication \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[43mscholarly\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_pubs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mMassively-Parallel Change Detection for Satellite Time Series Data with Missing Values\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      2\u001B[0m query_cited_by \u001B[38;5;241m=\u001B[39m scholarly\u001B[38;5;241m.\u001B[39mcitedby(publication)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# print all citations\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_scholarly.py:156\u001B[0m, in \u001B[0;36m_Scholarly.search_pubs\u001B[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param query: terms to be searched\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    151\u001B[0m \n\u001B[1;32m    152\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    153\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_url(_PUBSEARCH\u001B[38;5;241m.\u001B[39mformat(requests\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mquote(query)), patents\u001B[38;5;241m=\u001B[39mpatents,\n\u001B[1;32m    154\u001B[0m                           citations\u001B[38;5;241m=\u001B[39mcitations, year_low\u001B[38;5;241m=\u001B[39myear_low, year_high\u001B[38;5;241m=\u001B[39myear_high,\n\u001B[1;32m    155\u001B[0m                           sort_by\u001B[38;5;241m=\u001B[39msort_by, include_last_year\u001B[38;5;241m=\u001B[39minclude_last_year, start_index\u001B[38;5;241m=\u001B[39mstart_index)\n\u001B[0;32m--> 156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__nav\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_publications\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:283\u001B[0m, in \u001B[0;36mNavigator.search_publications\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_publications\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _SearchScholarIterator:\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    :param url: the url where publications can be found.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_SearchScholarIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/publication_parser.py:53\u001B[0m, in \u001B[0;36m_SearchScholarIterator.__init__\u001B[0;34m(self, nav, url)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pubtype \u001B[38;5;241m=\u001B[39m PublicationSource\u001B[38;5;241m.\u001B[39mPUBLICATION_SEARCH_SNIPPET \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/scholar?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m url \u001B[38;5;28;01melse\u001B[39;00m PublicationSource\u001B[38;5;241m.\u001B[39mJOURNAL_CITATION_LIST\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nav \u001B[38;5;241m=\u001B[39m nav\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_total_results()\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_parser \u001B[38;5;241m=\u001B[39m PublicationParser(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nav)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/publication_parser.py:59\u001B[0m, in \u001B[0;36m_SearchScholarIterator._load_url\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_url\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;66;03m# this is temporary until setup json file\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nav\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_soup\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup\u001B[38;5;241m.\u001B[39mfind_all(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgs_r gs_or gs_scl\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup\u001B[38;5;241m.\u001B[39mfind_all(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgsc_mpat_ttl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:226\u001B[0m, in \u001B[0;36mNavigator._get_soup\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_soup\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BeautifulSoup:\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001B[39;00m\n\u001B[0;32m--> 226\u001B[0m     html \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_page\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttps://scholar.google.com\u001B[39;49m\u001B[38;5;132;43;01m{0}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     html \u001B[38;5;241m=\u001B[39m html\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\xa0\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    228\u001B[0m     res \u001B[38;5;241m=\u001B[39m BeautifulSoup(html, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhtml.parser\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:113\u001B[0m, in \u001B[0;36mNavigator._get_page\u001B[0;34m(self, pagerequest, premium)\u001B[0m\n\u001B[1;32m    111\u001B[0m w \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39muniform(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    112\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(w)\n\u001B[0;32m--> 113\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpagerequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlogger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSession proxy config is \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(session\u001B[38;5;241m.\u001B[39mproxies))\n\u001B[1;32m    116\u001B[0m has_captcha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_requests_has_captcha(resp\u001B[38;5;241m.\u001B[39mtext)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/requests/sessions.py:600\u001B[0m, in \u001B[0;36mSession.get\u001B[0;34m(self, url, **kwargs)\u001B[0m\n\u001B[1;32m    592\u001B[0m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001B[39;00m\n\u001B[1;32m    593\u001B[0m \n\u001B[1;32m    594\u001B[0m \u001B[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001B[39;00m\n\u001B[1;32m    596\u001B[0m \u001B[38;5;124;03m:rtype: requests.Response\u001B[39;00m\n\u001B[1;32m    597\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    599\u001B[0m kwargs\u001B[38;5;241m.\u001B[39msetdefault(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 600\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGET\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m         resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m            \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m            \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproxy_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:700\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    696\u001B[0m is_new_proxy_conn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproxy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\n\u001B[1;32m    697\u001B[0m     conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msock\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    698\u001B[0m )\n\u001B[1;32m    699\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_new_proxy_conn \u001B[38;5;129;01mand\u001B[39;00m http_tunnel_required:\n\u001B[0;32m--> 700\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_proxy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[1;32m    703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[1;32m    704\u001B[0m     conn,\n\u001B[1;32m    705\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    710\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    711\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:996\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._prepare_proxy\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m    993\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproxy\u001B[38;5;241m.\u001B[39mscheme \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    994\u001B[0m     conn\u001B[38;5;241m.\u001B[39mtls_in_tls_required \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 996\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connection.py:369\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    365\u001B[0m     tls_in_tls \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    367\u001B[0m \u001B[38;5;66;03m# Calls self._set_hostport(), so self.host is\u001B[39;00m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;66;03m# self._tunnel_host below.\u001B[39;00m\n\u001B[0;32m--> 369\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tunnel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;66;03m# Mark this connection as not reusable\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_open \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:926\u001B[0m, in \u001B[0;36mHTTPConnection._tunnel\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    923\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m headers\n\u001B[1;32m    925\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_class(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_method)\n\u001B[0;32m--> 926\u001B[0m (version, code, message) \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m code \u001B[38;5;241m!=\u001B[39m http\u001B[38;5;241m.\u001B[39mHTTPStatus\u001B[38;5;241m.\u001B[39mOK:\n\u001B[1;32m    929\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# this function triggers ban\n",
    "#  publication = next(\n",
    "#scholarly.search_pubs('Massively-Parallel Change Detection for Satellite Time Series Data with Missing Values'))\n",
    "#query_cited_by = scholarly.citedby(publication)\n",
    "# print all citations\n",
    "#next(query_cited_by)\n",
    "\n",
    "# Error: MaxTriesExceededException: Cannot Fetch from Google Scholar -> prob IP ban"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using proxies to bypass google scholar security\n",
    "Not very good working, google is blocking our requests pretty fast"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "pg = ProxyGenerator()  # init proxy generator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We use a free proxy, could use a more powerfula (and not free) proxy if neeeded during the course of the project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success = pg.FreeProxies()  # active free proxy and check if it is working\n",
    "success  # Returns true if working"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Activate proxy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "scholarly.use_proxy(pg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'container_type': 'Author',\n 'filled': [],\n 'source': <AuthorSource.SEARCH_AUTHOR_SNIPPETS: 'SEARCH_AUTHOR_SNIPPETS'>,\n 'scholar_id': 'g3ZiieoAAAAJ',\n 'url_picture': 'https://scholar.google.com/citations?view_op=medium_photo&user=g3ZiieoAAAAJ',\n 'name': 'Fabian Gieseke',\n 'affiliation': 'Department of Information Systems, University of Münster',\n 'email_domain': '@uni-muenster.de',\n 'interests': ['Data Engineering', 'Maschine Learning'],\n 'citedby': 1361}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query as before\n",
    "search_query = scholarly.search_author('Fabian Gieseke, Münster')\n",
    "next(search_query)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "MaxTriesExceededException",
     "evalue": "Cannot Fetch from Google Scholar.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMaxTriesExceededException\u001B[0m                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m publication \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[43mscholarly\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_pubs\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBig Universe, Big Data: Machine Learning and Image Analysis for Astronomy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_scholarly.py:156\u001B[0m, in \u001B[0;36m_Scholarly.search_pubs\u001B[0;34m(self, query, patents, citations, year_low, year_high, sort_by, include_last_year, start_index)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;124;03m\"\"\"Searches by query and returns a generator of Publication objects\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param query: terms to be searched\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    151\u001B[0m \n\u001B[1;32m    152\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    153\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_construct_url(_PUBSEARCH\u001B[38;5;241m.\u001B[39mformat(requests\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mquote(query)), patents\u001B[38;5;241m=\u001B[39mpatents,\n\u001B[1;32m    154\u001B[0m                           citations\u001B[38;5;241m=\u001B[39mcitations, year_low\u001B[38;5;241m=\u001B[39myear_low, year_high\u001B[38;5;241m=\u001B[39myear_high,\n\u001B[1;32m    155\u001B[0m                           sort_by\u001B[38;5;241m=\u001B[39msort_by, include_last_year\u001B[38;5;241m=\u001B[39minclude_last_year, start_index\u001B[38;5;241m=\u001B[39mstart_index)\n\u001B[0;32m--> 156\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__nav\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch_publications\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:283\u001B[0m, in \u001B[0;36mNavigator.search_publications\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msearch_publications\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m _SearchScholarIterator:\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;124;03m\"\"\"Returns a Publication Generator given a url\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    :param url: the url where publications can be found.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;124;03m    :rtype: {_SearchScholarIterator}\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 283\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_SearchScholarIterator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/publication_parser.py:53\u001B[0m, in \u001B[0;36m_SearchScholarIterator.__init__\u001B[0;34m(self, nav, url)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pubtype \u001B[38;5;241m=\u001B[39m PublicationSource\u001B[38;5;241m.\u001B[39mPUBLICATION_SEARCH_SNIPPET \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/scholar?\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m url \u001B[38;5;28;01melse\u001B[39;00m PublicationSource\u001B[38;5;241m.\u001B[39mJOURNAL_CITATION_LIST\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nav \u001B[38;5;241m=\u001B[39m nav\n\u001B[0;32m---> 53\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal_results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_total_results()\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpub_parser \u001B[38;5;241m=\u001B[39m PublicationParser(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_nav)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/publication_parser.py:59\u001B[0m, in \u001B[0;36m_SearchScholarIterator._load_url\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_load_url\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;66;03m# this is temporary until setup json file\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nav\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_soup\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rows \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup\u001B[38;5;241m.\u001B[39mfind_all(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgs_r gs_or gs_scl\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_soup\u001B[38;5;241m.\u001B[39mfind_all(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdiv\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgsc_mpat_ttl\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:226\u001B[0m, in \u001B[0;36mNavigator._get_soup\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_soup\u001B[39m(\u001B[38;5;28mself\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BeautifulSoup:\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the BeautifulSoup for a page on scholar.google.com\"\"\"\u001B[39;00m\n\u001B[0;32m--> 226\u001B[0m     html \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_page\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhttps://scholar.google.com\u001B[39;49m\u001B[38;5;132;43;01m{0}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     html \u001B[38;5;241m=\u001B[39m html\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\xa0\u001B[39;00m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mu\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    228\u001B[0m     res \u001B[38;5;241m=\u001B[39m BeautifulSoup(html, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhtml.parser\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/scholarly/_navigator.py:177\u001B[0m, in \u001B[0;36mNavigator._get_page\u001B[0;34m(self, pagerequest, premium)\u001B[0m\n\u001B[1;32m    175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_page(pagerequest, \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 177\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxTriesExceededException(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot Fetch from Google Scholar.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mMaxTriesExceededException\u001B[0m: Cannot Fetch from Google Scholar."
     ]
    }
   ],
   "source": [
    "publication = next(\n",
    "    scholarly.search_pubs('Big Universe, Big Data: Machine Learning and Image Analysis for Astronomy, Fabian Gieseke'))\n",
    "#query_cited_by = scholarly.citedby(publication)\n",
    "# print all citations\n",
    "#next(query_cited_by)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "publication.get_journal_categories()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}