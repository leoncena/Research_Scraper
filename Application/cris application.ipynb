{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Research_Scraper_Code.Research_Scraper import ResearchScraper\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Notebook for application of scraping\n",
    "Demo Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test urls\n",
    "url_ieee = 'https://ieeexplore.ieee.org/document/7887648'\n",
    "url_springer = 'https://link.springer.com/article/10.1007/s12525-020-00445-0'\n",
    "url_doi = 'https://doi.org/10.1007/978-0-387-73947-2_8'\n",
    "url_elsevier = 'https://www.sciencedirect.com/science/article/pii/S2451929420300851?via%3Dihub'\n",
    "url_springer2 = 'https://doi.org/10.1007/s00450-009-0054-z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Init scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scraper = ResearchScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_publications_from_csv():\n",
    "    data = 'data/publications_without_abstract.csv'\n",
    "\n",
    "    with open(data) as f:\n",
    "        df = pd.read_csv(f, sep=';')\n",
    "    return df\n",
    "\n",
    "\n",
    "df_publications = load_publications_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get entries with DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_dois(df):\n",
    "    dois = df['doi']\n",
    "    # remove NaNs\n",
    "    dois = dois.dropna()\n",
    "    dois.tolist()\n",
    "    return dois\n",
    "\n",
    "\n",
    "publication_dois = get_all_dois(df_publications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Method for creating JSON file as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_results(results, name):\n",
    "    if results is not None:\n",
    "        with open(f'exports/scrapings/{name}.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a sample of cris data and scrape them al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_sample_of_dois(dois, n):\n",
    "    # get a sample of 10 from dois\n",
    "    sample = dois.sample(n)\n",
    "    #print(sample)\n",
    "    results = []\n",
    "\n",
    "    for doi in sample:\n",
    "        print(f'Scraping {doi}')\n",
    "        start = time.time()\n",
    "        result = scraper.scrape_publication_by_doi(doi, params=['full'])\n",
    "        end = time.time()\n",
    "        print(f'Total time : {end - start}')\n",
    "        old_len = len(results)\n",
    "        results.append(result)\n",
    "        print(f'\\n \\t  >>>>>> added new result, n went from {old_len} to n={len(results)}')\n",
    "        # print(f'\\t -> Results: {results}')\n",
    "\n",
    "    #write_results(results, f'sample_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022_10_15__17_49'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamp with date and time\n",
    "timestamp = time.strftime(\"%Y_%m_%d__%H_%M\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping doi.org/10.1016/j.jbusres.2021.11.035\n",
      "Total time : 0.00045990943908691406\n",
      "\n",
      " \t  >>>>>> added new result, n went from 0 to n=1\n",
      "Scraping 10.1016/S0167-9473(02)00170-6\n",
      "URL ('https://doi.org/10.1016/S0167-9473(02)00170-6') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://linkinghub.elsevier.com/retrieve/pii/S0167947302001706\n",
      "[DEBUG - ResearchScraper] - Found scraper for https://linkinghub.elsevier.com/retrieve/pii/S0167947302001706 -> ScraperScienceDirect\n",
      "200\n",
      "scrolling took 0.1083669662475586 seconds\n",
      "Browser closed in 22.265285968780518 seconds, including 13.053704977035522 seconds of waiting, thus 9.211580991744995 seconds of loading.\n",
      "Total time : 24.63638401031494\n",
      "\n",
      " \t  >>>>>> added new result, n went from 1 to n=2\n",
      "Scraping 10.3390/su14159407\n",
      "URL ('https://doi.org/10.3390/su14159407') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://www.mdpi.com/2071-1050/14/15/9407\n",
      "[DEBUG - ResearchScraper] - No scraper found for https://www.mdpi.com/2071-1050/14/15/9407\n",
      "Total time : 0.48225998878479004\n",
      "\n",
      " \t  >>>>>> added new result, n went from 2 to n=3\n"
     ]
    }
   ],
   "source": [
    "# scrape sample of 10\n",
    "res = None\n",
    "res = scrape_sample_of_dois(publication_dois, 3)\n",
    "write_results(res, f'sample_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scraping a list of DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_publication_by_doi_list(doi_list, params=['full']):\n",
    "    print(f'Time of scrape start: {time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    results = []\n",
    "    for doi in doi_list:\n",
    "        print(f'>>> Scraping {doi}')\n",
    "        result = scraper.scrape_publication_by_doi(doi, params)\n",
    "        print(f'>>>> Scraping {doi} done')\n",
    "        results.append(result)\n",
    "        print(f'>>>> Scraping {doi} added to results')\n",
    "    print(f'>>>> Scraping {len(doi_list)} publications done')\n",
    "    write_results(results, f'scrapings_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    print(f'Time of scrape end: {time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Scraping 10.1509/jmkg.72.2.1\n",
      "URL ('https://doi.org/10.1509/jmkg.72.2.1') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://journals.sagepub.com/doi/10.1509/jmkg.72.2.1\n",
      "[DEBUG - ResearchScraper] - No scraper found for https://journals.sagepub.com/doi/10.1509/jmkg.72.2.1\n",
      ">>>> Scraping 10.1509/jmkg.72.2.1 done\n",
      ">>>> Scraping 10.1509/jmkg.72.2.1 added to results\n",
      ">>>> Scraping 1 publications done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw a sample list and scrape them\n",
    "doi_list_sample = publication_dois.sample(10)\n",
    "scraping_results = scrape_publication_by_doi_list(doi_list_sample)\n",
    "len(scraping_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scrape all dois\n",
    "scraping_results_all_dois = scrape_publication_by_doi_list(publication_dois)\n",
    "print(len(scraping_results_all_dois))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing results of scraping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read json file 'Application/exports/scrapings/scrapings_2022_10_15__21_22.json'\n",
    "with open('exports/scrapings/scrapings_2022_10_16__07_09.json') as f:\n",
    "    scraping_results_imported = json.load(f)\n",
    "# old file 582 after clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# drop Nones from dict\n",
    "scraping_results_imported_cleaned = [x for x in scraping_results_imported if x is not None]\n",
    "# old file 582 after clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# get the rows from the dict with the key 'error'\n",
    "error_rows = [x for x in scraping_results_imported_cleaned if x.get('error') is not None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2022_10_16__00_48\n"
     ]
    }
   ],
   "source": [
    "# print time\n",
    "print(f'Time: {time.strftime(\"%Y_%m_%d__%H_%M\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}