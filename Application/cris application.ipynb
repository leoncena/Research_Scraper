{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Research_Scraper_Code.Research_Scraper import ResearchScraper\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Test Notebook for application of scraping\n",
    "Demo Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test urls\n",
    "url_ieee = 'https://ieeexplore.ieee.org/document/7887648'\n",
    "url_springer = 'https://link.springer.com/article/10.1007/s12525-020-00445-0'\n",
    "url_doi = 'https://doi.org/10.1007/978-0-387-73947-2_8'\n",
    "url_elsevier = 'https://www.sciencedirect.com/science/article/pii/S2451929420300851?via%3Dihub'\n",
    "url_springer2 = 'https://doi.org/10.1007/s00450-009-0054-z'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Init scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scraper = ResearchScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_publications_from_csv():\n",
    "    data = 'data/publications_without_abstract.csv'\n",
    "\n",
    "    with open(data) as f:\n",
    "        df = pd.read_csv(f, sep=';')\n",
    "    return df\n",
    "\n",
    "\n",
    "df_publications = load_publications_from_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Get entries with DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_dois(df):\n",
    "    dois = df['doi']\n",
    "    # remove NaNs\n",
    "    dois = dois.dropna()\n",
    "    dois.tolist()\n",
    "    return dois\n",
    "\n",
    "\n",
    "publication_dois = get_all_dois(df_publications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Method for creating JSON file as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def write_results(results, name):\n",
    "    if results is not None:\n",
    "        with open(f'exports/scrapings/{name}.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a sample of cris data and scrape them al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_sample_of_dois(dois, n):\n",
    "    # get a sample of 10 from dois\n",
    "    sample = dois.sample(n)\n",
    "    #print(sample)\n",
    "    results = []\n",
    "\n",
    "    for doi in sample:\n",
    "        print(f'Scraping {doi}')\n",
    "        start = time.time()\n",
    "        result = scraper.scrape_publication_by_doi(doi, params=['full'])\n",
    "        end = time.time()\n",
    "        print(f'Total time : {end - start}')\n",
    "        old_len = len(results)\n",
    "        results.append(result)\n",
    "        print(f'\\n \\t  >>>>>> added new result, n went from {old_len} to n={len(results)}')\n",
    "        # print(f'\\t -> Results: {results}')\n",
    "\n",
    "    #write_results(results, f'sample_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2022_10_16__13_23'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamp with date and time\n",
    "timestamp = time.strftime(\"%Y_%m_%d__%H_%M\")\n",
    "timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping 10.1111/1467-8551.12350\n",
      "URL ('https://doi.org/10.1111/1467-8551.12350') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://onlinelibrary.wiley.com/doi/10.1111/1467-8551.12350\n",
      "[DEBUG - ResearchScraper] - No scraper found for https://onlinelibrary.wiley.com/doi/10.1111/1467-8551.12350\n",
      "Total time : 0.6439321041107178\n",
      "\n",
      " \t  >>>>>> added new result, n went from 0 to n=1\n",
      "Scraping 10.1016/j.eneco.2016.03.008\n",
      "URL ('https://doi.org/10.1016/j.eneco.2016.03.008') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://linkinghub.elsevier.com/retrieve/pii/S0140988316300469\n",
      "[DEBUG - ResearchScraper] - Found scraper for https://linkinghub.elsevier.com/retrieve/pii/S0140988316300469 -> ScraperScienceDirect\n",
      "200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# scrape sample of 10\u001B[39;00m\n\u001B[1;32m      2\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[43mscrape_sample_of_dois\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpublication_dois\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m write_results(res, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msample_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtime\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY_\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm_\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH_\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mscrape_sample_of_dois\u001B[0;34m(dois, n)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mScraping \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdoi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      9\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 10\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mscraper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscrape_publication_by_doi\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfull\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTotal time : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend \u001B[38;5;241m-\u001B[39m start\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Repos/GitHub/Research_Scraper/Research_Scraper_Code/Research_Scraper.py:58\u001B[0m, in \u001B[0;36mResearchScraper.scrape_publication_by_doi\u001B[0;34m(self, doi, params)\u001B[0m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     57\u001B[0m url \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mcreate_doi_link(doi)\n\u001B[0;32m---> 58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscrape_publication_by_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Repos/GitHub/Research_Scraper/Research_Scraper_Code/Research_Scraper.py:40\u001B[0m, in \u001B[0;36mResearchScraper.scrape_publication_by_url\u001B[0;34m(self, url, params)\u001B[0m\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[DEBUG - ResearchScraper] - Found scraper for \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m -> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(scraper)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     39\u001B[0m         scraper_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 40\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mscraper\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscrape_by_url\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;66;03m# if no scraper was found return None\u001B[39;00m\n",
      "File \u001B[0;32m~/Repos/GitHub/Research_Scraper/Research_Scraper_Code/scraper_types/scraper_sciencedirect.py:87\u001B[0m, in \u001B[0;36mScraperScienceDirect.scrape_by_url\u001B[0;34m(self, url, params)\u001B[0m\n\u001B[1;32m     84\u001B[0m bs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_bs(url, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcloud\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     86\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_text\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreferences\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mamount_citations\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m params:\n\u001B[0;32m---> 87\u001B[0m     bs_full \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_bs\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mhelium\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# only example, springer does not need cloudscraper\u001B[39;00m\n\u001B[1;32m     88\u001B[0m     bs_full_is_created \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m# get title\u001B[39;00m\n",
      "File \u001B[0;32m~/Repos/GitHub/Research_Scraper/Research_Scraper_Code/scraper_types/scraper_abstract.py:176\u001B[0m, in \u001B[0;36mScraperAbstract.get_bs\u001B[0;34m(self, url, method)\u001B[0m\n\u001B[1;32m    174\u001B[0m     bs \u001B[38;5;241m=\u001B[39m BeautifulSoup(request, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhtml.parser\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# selenium already returns html\u001B[39;00m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhelium\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 176\u001B[0m     request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_HTML_helium\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    177\u001B[0m     bs \u001B[38;5;241m=\u001B[39m BeautifulSoup(request, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhtml.parser\u001B[39m\u001B[38;5;124m'\u001B[39m)  \u001B[38;5;66;03m# helium already returns html\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Repos/GitHub/Research_Scraper/Research_Scraper_Code/scraper_types/scraper_abstract.py:95\u001B[0m, in \u001B[0;36mScraperAbstract.get_HTML_helium\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m     93\u001B[0m options\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--start-maximized\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     94\u001B[0m options\u001B[38;5;241m.\u001B[39madd_argument(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwindow-size=1920,1080\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 95\u001B[0m browser \u001B[38;5;241m=\u001B[39m \u001B[43mstart_chrome\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;66;03m# todo maybe move helium to ieer scraper\u001B[39;00m\n\u001B[1;32m     98\u001B[0m wait_until_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/__init__.py:76\u001B[0m, in \u001B[0;36mstart_chrome\u001B[0;34m(url, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_chrome\u001B[39m(\n\u001B[1;32m     22\u001B[0m \turl\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, headless\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, capabilities\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     23\u001B[0m ):\n\u001B[1;32m     24\u001B[0m \t\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03m\t:param url: URL to open.\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m\t:type url: str\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;124;03m\t\tkill_browser()\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;124;03m\t\"\"\"\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_api_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_chrome_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheadless\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapabilities\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/__init__.py:101\u001B[0m, in \u001B[0;36mAPIImpl.start_chrome_impl\u001B[0;34m(self, url, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstart_chrome_impl\u001B[39m(\n\u001B[1;32m     97\u001B[0m \t\u001B[38;5;28mself\u001B[39m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, headless\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, maximize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     98\u001B[0m \tcapabilities\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     99\u001B[0m ):\n\u001B[1;32m    100\u001B[0m \tchrome_driver \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m--> 101\u001B[0m \t\t\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_start_chrome_driver\u001B[49m\u001B[43m(\u001B[49m\u001B[43mheadless\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcapabilities\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start(chrome_driver, url)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/helium/_impl/__init__.py:110\u001B[0m, in \u001B[0;36mAPIImpl._start_chrome_driver\u001B[0;34m(self, headless, maximize, options, capabilities)\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m WebDriverException:\n\u001B[1;32m    108\u001B[0m \t\u001B[38;5;66;03m# This usually happens when chromedriver is not on the PATH.\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \tdriver_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_included_web_driver(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchromedriver\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 110\u001B[0m \tresult \u001B[38;5;241m=\u001B[39m \u001B[43mChrome\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchrome_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesired_capabilities\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapabilities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m\t\t\u001B[49m\u001B[43mexecutable_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdriver_path\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[43m\t\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m atexit\u001B[38;5;241m.\u001B[39mregister(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kill_service, result\u001B[38;5;241m.\u001B[39mservice)\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/chrome/webdriver.py:76\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, keep_alive)\u001B[0m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mservice\u001B[38;5;241m.\u001B[39mstart()\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 76\u001B[0m     \u001B[43mRemoteWebDriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcommand_executor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mChromeRemoteConnection\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremote_server_addr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mservice_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_alive\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdesired_capabilities\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesired_capabilities\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquit()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:157\u001B[0m, in \u001B[0;36mWebDriver.__init__\u001B[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m browser_profile \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    155\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease use FirefoxOptions to set browser profile\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    156\u001B[0m                   \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m--> 157\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_session\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcapabilities\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbrowser_profile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to \u001B[38;5;241m=\u001B[39m SwitchTo(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mobile \u001B[38;5;241m=\u001B[39m Mobile(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:252\u001B[0m, in \u001B[0;36mWebDriver.start_session\u001B[0;34m(self, capabilities, browser_profile)\u001B[0m\n\u001B[1;32m    249\u001B[0m w3c_caps \u001B[38;5;241m=\u001B[39m _make_w3c_caps(capabilities)\n\u001B[1;32m    250\u001B[0m parameters \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcapabilities\u001B[39m\u001B[38;5;124m\"\u001B[39m: w3c_caps,\n\u001B[1;32m    251\u001B[0m               \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdesiredCapabilities\u001B[39m\u001B[38;5;124m\"\u001B[39m: capabilities}\n\u001B[0;32m--> 252\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCommand\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNEW_SESSION\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msessionId\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m response:\n\u001B[1;32m    254\u001B[0m     response \u001B[38;5;241m=\u001B[39m response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:319\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[0;34m(self, driver_command, params)\u001B[0m\n\u001B[1;32m    316\u001B[0m         params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msessionId\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession_id\n\u001B[1;32m    318\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_value(params)\n\u001B[0;32m--> 319\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommand_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver_command\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_handler\u001B[38;5;241m.\u001B[39mcheck_response(response)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:374\u001B[0m, in \u001B[0;36mRemoteConnection.execute\u001B[0;34m(self, command, params)\u001B[0m\n\u001B[1;32m    372\u001B[0m data \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mdump_json(params)\n\u001B[1;32m    373\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_url, path)\n\u001B[0;32m--> 374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand_info\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:397\u001B[0m, in \u001B[0;36mRemoteConnection._request\u001B[0;34m(self, method, url, body)\u001B[0m\n\u001B[1;32m    394\u001B[0m     body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkeep_alive:\n\u001B[0;32m--> 397\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m     statuscode \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mstatus\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/request.py:78\u001B[0m, in \u001B[0;36mRequestMethods.request\u001B[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_encode_url(\n\u001B[1;32m     75\u001B[0m         method, url, fields\u001B[38;5;241m=\u001B[39mfields, headers\u001B[38;5;241m=\u001B[39mheaders, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39murlopen_kw\n\u001B[1;32m     76\u001B[0m     )\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_encode_body\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfields\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43murlopen_kw\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/request.py:170\u001B[0m, in \u001B[0;36mRequestMethods.request_encode_body\u001B[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001B[0m\n\u001B[1;32m    167\u001B[0m extra_kw[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mupdate(headers)\n\u001B[1;32m    168\u001B[0m extra_kw\u001B[38;5;241m.\u001B[39mupdate(urlopen_kw)\n\u001B[0;32m--> 170\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/poolmanager.py:376\u001B[0m, in \u001B[0;36mPoolManager.urlopen\u001B[0;34m(self, method, url, redirect, **kw)\u001B[0m\n\u001B[1;32m    374\u001B[0m     response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    378\u001B[0m redirect_location \u001B[38;5;241m=\u001B[39m redirect \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mget_redirect_location()\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m redirect_location:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    444\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:1377\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1377\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:320\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# scrape sample of 10\n",
    "res = None\n",
    "res = scrape_sample_of_dois(publication_dois, 3)\n",
    "write_results(res, f'sample_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Scraping a list of DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_publication_by_doi_list(doi_list, params=['full']):\n",
    "    print(f'Time of scrape start: {time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    results = []\n",
    "    for doi in doi_list:\n",
    "        print(f'>>> Scraping {doi}')\n",
    "        result = scraper.scrape_publication_by_doi(doi, params)\n",
    "        print(f'>>>> Scraping {doi} done')\n",
    "        results.append(result)\n",
    "        print(f'>>>> Scraping {doi} added to results')\n",
    "    print(f'>>>> Scraping {len(doi_list)} publications done')\n",
    "    write_results(results, f'scrapings_{time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    print(f'Time of scrape end: {time.strftime(\"%Y_%m_%d__%H_%M\")}')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Scraping 10.1509/jmkg.72.2.1\n",
      "URL ('https://doi.org/10.1509/jmkg.72.2.1') is a DOI link, Links is now resolved properly\n",
      "Resolved DOI link to: https://journals.sagepub.com/doi/10.1509/jmkg.72.2.1\n",
      "[DEBUG - ResearchScraper] - No scraper found for https://journals.sagepub.com/doi/10.1509/jmkg.72.2.1\n",
      ">>>> Scraping 10.1509/jmkg.72.2.1 done\n",
      ">>>> Scraping 10.1509/jmkg.72.2.1 added to results\n",
      ">>>> Scraping 1 publications done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw a sample list and scrape them\n",
    "doi_list_sample = publication_dois.sample(10)\n",
    "scraping_results = scrape_publication_by_doi_list(doi_list_sample)\n",
    "len(scraping_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scrape all dois\n",
    "scraping_results_all_dois = scrape_publication_by_doi_list(publication_dois)\n",
    "print(len(scraping_results_all_dois))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing results of scraping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read json file with scraping results (all cris doi numbers)\n",
    "with open('exports/scrapings/scrapings_2022_10_16__07_09.json') as f:\n",
    "    scraping_results_imported = json.load(f)\n",
    "# old file 582 after clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# drop Nones from dict\n",
    "scraping_results_imported_cleaned = [x for x in scraping_results_imported if x is not None]\n",
    "# old file 582 after clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# get the rows from the dict with the key 'error'\n",
    "error_rows = [x for x in scraping_results_imported_cleaned if x.get('error') is not None]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2022_10_16__00_48\n"
     ]
    }
   ],
   "source": [
    "# print time\n",
    "print(f'Time: {time.strftime(\"%Y_%m_%d__%H_%M\")}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}