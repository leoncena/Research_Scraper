{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from helium import *\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "url = 'https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub'  # open access paper with a lot of information\n",
    "url2 = 'https://www.sciencedirect.com/science/article/abs/pii/S0306437918300838?via%3Dihub'  # pay per paper view with less information (available at least)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A: Selenium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "def get_HTML_selenium(url, os):\n",
    "    \"\"\"\n",
    "    Get HTML from a website using Selenium and ChromeDriver. Methods runs headless per default and has JS activated.\n",
    "    Be aware that this method is quite slow and schould only be used if classic requests method cannot access information thus only use that for dynamic data.\n",
    "    :param url: URL of a website\n",
    "    :param os: Operating system of the user (Windows, Linux, Mac)\n",
    "    :return: HTML with all loaded content\n",
    "    \"\"\"\n",
    "    if os == 'mac':\n",
    "        PATH_MAC = '../driver/chromedriverMAC'\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=chrome\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    driver = webdriver.Chrome(PATH_MAC, options=options)\n",
    "    driver.get(url)\n",
    "    break_time = 5\n",
    "    time.sleep(break_time)\n",
    "\n",
    "    # todo if content owned by WWU add sleep to load more content\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(\n",
    "        f'Browser closed in {end - start} seconds, including {break_time} seconds of waiting, thus {end - start - break_time} seconds of loading.')\n",
    "    return html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [281]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m html1 \u001B[38;5;241m=\u001B[39m \u001B[43mget_HTML_selenium\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmac\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [278]\u001B[0m, in \u001B[0;36mget_HTML_selenium\u001B[0;34m(url, os)\u001B[0m\n\u001B[1;32m     14\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     15\u001B[0m driver \u001B[38;5;241m=\u001B[39m webdriver\u001B[38;5;241m.\u001B[39mChrome(PATH_MAC, options\u001B[38;5;241m=\u001B[39moptions)\n\u001B[0;32m---> 16\u001B[0m \u001B[43mdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m break_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[1;32m     18\u001B[0m time\u001B[38;5;241m.\u001B[39msleep(break_time)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:333\u001B[0m, in \u001B[0;36mWebDriver.get\u001B[0;34m(self, url)\u001B[0m\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, url):\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;124;03m    Loads a web page in the current browser session.\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 333\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCommand\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mGET\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43murl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/webdriver.py:319\u001B[0m, in \u001B[0;36mWebDriver.execute\u001B[0;34m(self, driver_command, params)\u001B[0m\n\u001B[1;32m    316\u001B[0m         params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msessionId\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession_id\n\u001B[1;32m    318\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_wrap_value(params)\n\u001B[0;32m--> 319\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommand_executor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdriver_command\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response:\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39merror_handler\u001B[38;5;241m.\u001B[39mcheck_response(response)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:374\u001B[0m, in \u001B[0;36mRemoteConnection.execute\u001B[0;34m(self, command, params)\u001B[0m\n\u001B[1;32m    372\u001B[0m data \u001B[38;5;241m=\u001B[39m utils\u001B[38;5;241m.\u001B[39mdump_json(params)\n\u001B[1;32m    373\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_url, path)\n\u001B[0;32m--> 374\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand_info\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/selenium/webdriver/remote/remote_connection.py:397\u001B[0m, in \u001B[0;36mRemoteConnection._request\u001B[0;34m(self, method, url, body)\u001B[0m\n\u001B[1;32m    394\u001B[0m     body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkeep_alive:\n\u001B[0;32m--> 397\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m     statuscode \u001B[38;5;241m=\u001B[39m resp\u001B[38;5;241m.\u001B[39mstatus\n\u001B[1;32m    400\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/request.py:78\u001B[0m, in \u001B[0;36mRequestMethods.request\u001B[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001B[0m\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_encode_url(\n\u001B[1;32m     75\u001B[0m         method, url, fields\u001B[38;5;241m=\u001B[39mfields, headers\u001B[38;5;241m=\u001B[39mheaders, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39murlopen_kw\n\u001B[1;32m     76\u001B[0m     )\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_encode_body\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfields\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43murlopen_kw\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/request.py:170\u001B[0m, in \u001B[0;36mRequestMethods.request_encode_body\u001B[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001B[0m\n\u001B[1;32m    167\u001B[0m extra_kw[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mheaders\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mupdate(headers)\n\u001B[1;32m    168\u001B[0m extra_kw\u001B[38;5;241m.\u001B[39mupdate(urlopen_kw)\n\u001B[0;32m--> 170\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mextra_kw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/poolmanager.py:376\u001B[0m, in \u001B[0;36mPoolManager.urlopen\u001B[0;34m(self, method, url, redirect, **kw)\u001B[0m\n\u001B[1;32m    374\u001B[0m     response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 376\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mu\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    378\u001B[0m redirect_location \u001B[38;5;241m=\u001B[39m redirect \u001B[38;5;129;01mand\u001B[39;00m response\u001B[38;5;241m.\u001B[39mget_redirect_location()\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m redirect_location:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    444\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:1377\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1377\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1378\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1379\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:320\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    322\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/http/client.py:281\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 281\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    282\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    283\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/Research_Scraper/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "html1 = get_HTML_selenium(url, 'mac')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "soup1 = BeautifulSoup(html1, 'html.parser')\n",
    "print(soup1.text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser closed in 22.284823179244995 seconds, including 5 seconds of waiting, thus 17.284823179244995 seconds of loading.\n",
      "Testing accessing title:\n",
      "Nearest neighbor density ratio estimation for large-scale applications in astronomy\n"
     ]
    }
   ],
   "source": [
    "def quick_Selenium_Test():\n",
    "    html = get_HTML_selenium('https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub', 'mac')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title_test = soup.find('span', class_='title-text').text.strip()\n",
    "    print('Testing accessing title:')\n",
    "    print(title_test)\n",
    "\n",
    "    assert title_test == 'Nearest neighbor density ratio estimation for large-scale applications in astronomy', f'Expted title not matched'\n",
    "\n",
    "\n",
    "quick_Selenium_Test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B: Trying helium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [],
   "source": [
    "def get_HTML_helium(url):\n",
    "    \"\"\"\n",
    "    Get HTML from a website using helium and ChromeDriver. Helium is a lightweight Selenium adapter. It comes with simple wait and click functions.\n",
    "    Method runs headless per default and has JS activated. By adding arguments the method mimics a user so that Elesevier returns the full HTML and allows loading.\n",
    "    Be aware that this method is quite slow and schould only be used if classic requests method cannot access information thus only use that for dynamic data.\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ## helium does not work for science direct, so we use selenium instead => works!\n",
    "    url = 'https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub'\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Tricking Elsevier\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless=chrome\")\n",
    "    options.add_argument(\"--enable-javascript\")\n",
    "    #options.add_argument('--no-sandbox')\n",
    "    options.add_argument(\"--disable-extensions\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"window-size=1920,1080\")\n",
    "    browser = start_chrome(url, options=options)\n",
    "\n",
    "    wait_until_start = time.time()\n",
    "    wait_until(lambda: not Text(\"Loading...\").exists(), timeout_secs=10, interval_secs=0.5)\n",
    "    wait_until_end = time.time()\n",
    "\n",
    "    html = browser.page_source\n",
    "    kill_browser()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f'Waited {wait_until_end - wait_until_start} seconds for the wait_until method')\n",
    "    print(f'and Total waiting time: {end - start} seconds')\n",
    "    return html\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "html = get_HTML_helium(url)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waited 21.20144271850586 seconds for the wait_until method\n",
      "and Total waiting time: 28.12459969520569 seconds\n",
      "Testing accessing title:\n",
      "Nearest neighbor density ratio estimation for large-scale applications in astronomy\n"
     ]
    }
   ],
   "source": [
    "def quick_Helium_Test():\n",
    "    html = get_HTML_helium('https://www.sciencedirect.com/science/article/pii/S2213133715000657?via%3Dihub')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    title_test = soup.find('span', class_='title-text').text.strip()\n",
    "    print('Testing accessing title:')\n",
    "    print(title_test)\n",
    "\n",
    "    assert title_test == 'Nearest neighbor density ratio estimation for large-scale applications in astronomy', f'Expted title not matched'\n",
    "\n",
    "\n",
    "quick_Helium_Test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# small test if the last reference is recognized (hard-copied!)\n",
    "\n",
    "print(\"ref test\")\n",
    "print(soup.find('div', {'id': 'ref-id-sbref29'}))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# misc\n",
    "Kill Helium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kill_browser()  # kills Helium browser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kill Selenium"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "driver.close()  # Kills Selenium browser"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}