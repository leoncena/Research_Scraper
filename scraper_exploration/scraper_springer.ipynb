{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scraper commands for publications on springer\n",
    "## Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here it is only about the steps, to parse are necessary so that it can be included in the end.\n",
    "\n",
    "There are different website types for publications on springer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "journal_doi = 'https://doi.org/10.1007/s12525-020-00445-0'\n",
    "journal_full_link = 'https://link.springer.com/article/10.1007/s12525-020-00445-0'\n",
    "\n",
    "conference_chapter_link = 'https://link.springer.com/chapter/10.1007/978-3-030-49570-1_14'\n",
    "conference_book_link = 'https://link.springer.com/book/10.1007/978-3-642-22531-4'\n",
    "\n",
    "volume_contribution_link = 'https://link.springer.com/chapter/10.1007/978-3-030-06234-7_27'\n",
    "#volume_link = 'https://link.springer.com/book/10.1007/978-3-030-06234-7'\n",
    "\n",
    "springer_links = [journal_full_link, conference_chapter_link, conference_book_link, volume_contribution_link]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# identify the type of the link\n",
    "def get_springer_link_type(url):\n",
    "    if '/chapter/' in url:\n",
    "        return 'chapter'\n",
    "    elif '/book/' in url:\n",
    "        return 'book'\n",
    "    elif '/article/' in url:\n",
    "        return 'article'\n",
    "    else:\n",
    "        return 'unknown'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "for link in springer_links:\n",
    "    get_springer_link_type(link)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_bs(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.5 Safari/605.1.15'}\n",
    "        r = requests.get(url, headers=headers)\n",
    "        print(r.status_code)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "    except:\n",
    "        print('Error: ', url)\n",
    "        return None\n",
    "    return bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "journal_soup = get_bs(journal_full_link)\n",
    "conference_chapter_soup = get_bs(conference_chapter_link)\n",
    "conference_book_soup = get_bs(conference_book_link)\n",
    "volume_contribution_soup = get_bs(volume_contribution_link)\n",
    "springer_soups = [journal_soup, conference_chapter_soup, conference_book_soup, volume_contribution_soup]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# get whole data from json and loads to dict\n",
    "# articles need to be prefiltered because they are nested differently\n",
    "def get_json_data(bs):\n",
    "    json_string = bs.find('script', {'type': 'application/ld+json'}).text\n",
    "    json_data = json.loads(json_string)\n",
    "\n",
    "    if '{\"mainEntity\":' in json_string:\n",
    "        return json_data['mainEntity']\n",
    "    else:\n",
    "        return json_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating json files for the three different types of publications for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "journal_json = get_json_data(journal_soup)\n",
    "conference_chapter_json = get_json_data(conference_chapter_soup)\n",
    "conference_book_json = get_json_data(conference_book_soup)\n",
    "volume_contribution_json = get_json_data(volume_contribution_soup)\n",
    "json_data_list = [journal_json, conference_chapter_json, conference_book_json, volume_contribution_json]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# get names of json fields\n",
    "def get_json_fields(json_data):\n",
    "    return list(json_data.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['headline',\n 'description',\n 'datePublished',\n 'dateModified',\n 'pageStart',\n 'pageEnd',\n 'license',\n 'sameAs',\n 'keywords',\n 'image',\n 'isPartOf',\n 'publisher',\n 'author',\n 'isAccessibleForFree',\n '@type']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_fields(journal_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Fields\n",
    "Title #TODO get title also for book (if instruction or with json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_title(bs):\n",
    "    try:\n",
    "        title = bs.find('h1', {'class': 'c-article-title'}).text\n",
    "        return title\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring customers’ likeliness to use e-service touchpoints in brick and mortar retail\n",
      "A Two-Phase Framework for Detecting Manipulation Campaigns in Social Media\n",
      "None\n",
      "Applications of Artificial Intelligence in Supply Chain Management and Logistics: Focusing Onto Recognition for Supply Chain Execution\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_title(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Authors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_authors(bs):\n",
    "    \"\"\"\n",
    "    Return list of authors in the format:\n",
    "    [{'name': 'Author Name', 'orcid': orcid}, ...]\n",
    "\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list of dicts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        authors = []\n",
    "        for author in json_data.get('author'):\n",
    "            name = author.get('name')\n",
    "            # split name at comma and reverse\n",
    "            name = name.split(', ')\n",
    "            name = name[1] + ' ' + name[0]\n",
    "            orcid = author.get('url')\n",
    "            authors.append({'name': name,\n",
    "                            'orcid': orcid})\n",
    "        return authors\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Benjamin Barann', 'orcid': 'http://orcid.org/0000-0002-1965-2688'}, {'name': 'Jan H. Betzing', 'orcid': None}, {'name': 'Marco Niemann', 'orcid': None}, {'name': 'Benedikt Hoffmeister', 'orcid': None}, {'name': 'Jörg Becker', 'orcid': None}]\n",
      "[{'name': 'Dennis Assenmacher', 'orcid': None}, {'name': 'Lena Clever', 'orcid': None}, {'name': 'Janina Susanne Pohl', 'orcid': None}, {'name': 'Heike Trautmann', 'orcid': None}, {'name': 'Christian Grimme', 'orcid': None}]\n",
      "None\n",
      "[{'name': 'Bernd Hellingrath', 'orcid': None}, {'name': 'Sandra Lechtenberg', 'orcid': None}]\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_authors(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keywords #TODO may be replaced with BS scraping because weird data structure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def get_Keywords(bs):\n",
    "    \"\"\"\n",
    "    Return list of keywords from json data\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Return list of keywords in the format:\n",
    "    [keyword1, keyword2, ...]\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        keywords_string = json_data.get('keywords')\n",
    "        keywords = keywords_string.split(',')\n",
    "        return keywords\n",
    "    except:\n",
    "        print(\"Error: no keywords found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT in Business', 'e-Commerce/e-business']\n",
      "['Social campaign detection', ' Stream clustering', ' Unsupervised learning']\n",
      "['Java', ' XQuery', ' abstract interpretation', ' higher-order patterns', ' non-deterministic functions']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_Keywords(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abstract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_abstract(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the abstract of the articles, books/preceedings do not have abstracts.\n",
    "    :param json_data: Received json data of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        abstract = json_data.get('description')\n",
    "        return abstract\n",
    "    except:\n",
    "        print(\"Error: no abstract found\")\n",
    "        return None\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-commerce has embraced the digital transformation and innovated with e-service touchpoints to improve customers’ experiences. Now some traditional, less-digitalized brick and mortar (BaM) retailers are starting to counteract the increasing competition by adopting digital touchpoints. However, the academic literature offers little in terms of what determines customers’ behavioral intentions toward e-service touchpoints. Therefore, drawing from the dominant design theory, this article first conceptually adapts selected dominant touchpoints of leading e-commerce solutions to BaM retail. Then 250 shoppers are surveyed regarding the likeliness that they will use the selected touchpoints, followed by an exploratory factor analysis to determine the touchpoints’ characteristics that lead to the shoppers’ assessments. The results suggest that customers prefer touchpoints that support product search and selection, provide information, and increase shopping efficiency. The likeliness that surveyed shoppers will use the touchpoints was affected by the functionality provided, the content conveyed, and the mediating device. The results provide a foundation for further research on customers’ behavioral intentions toward BaM e-service touchpoints and provide useful information for BaM retailers.\n",
      "-------\n",
      "The identification of coordinated campaigns within Social Media is a complex task that is often hindered by missing labels and large amounts of data that have to be processed. We propose a new two-phase framework that uses unsupervised stream clustering for detecting suspicious trends over time in a first step. Afterwards, traditional offline analyses are applied to distinguish between normal trend evolution and malicious manipulation attempts. We demonstrate the applicability of our framework in the context of the final days of the Brexit in 2019/2020.\n",
      "-------\n",
      "None\n",
      "-------\n",
      "Emerging technologies like Artificial Intelligence (AI) show the potential to contribute significantly to the digitalization of supply chains. Nonetheless, the question which approaches from the field of AI are applied within supply chains as well as which supply chain problems or tasks are addressed with AI approaches has not been answered by scientific literature yet. Based on a structured literature review this paper aims at providing an answer to these questions. A special focus is given to the application areas for recognition approaches in supply chain execution, for which this paper provides an overview of those areas research is currently focusing upon.\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_abstract(soup, url))\n",
    "    print(\"-------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pdf #todo #TODO: download"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_pdf(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the pdf link of the publication, if available. Download might require login.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #todo automate download\n",
    "    # differentiate between article, chapter and book\n",
    "    if '/article/' in url:\n",
    "        pdf = bs.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')\n",
    "\n",
    "    elif '/chapter/' in url:\n",
    "        pdf_box = bs.find('div', {'class': 'c-article-access-provider'})\n",
    "        pdf = pdf_box.find('a', {'data-track-action': 'Pdf download'}).get('href')\n",
    "\n",
    "    elif '/book/' in url:\n",
    "        pdf = bs.find('div', {'data-test': 'download-article-link-wrapper',\n",
    "                              'class': 'js-context-bar-sticky-point-desktop'}).find('a', {\n",
    "            'data-track-action': 'Book download - pdf'}).get('href')\n",
    "\n",
    "    # append base url if necesary\n",
    "    if 'link.springer.com' in pdf:\n",
    "        return pdf\n",
    "    else:\n",
    "        return f'https://link.springer.com{pdf}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-030-49570-1_14.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-642-22531-4.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-030-06234-7_27.pdf']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_links = []\n",
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    test_links.append(get_pdf(soup, url))\n",
    "\n",
    "test_links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_soup.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publisher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_publisher(bs):\n",
    "    \"\"\"\n",
    "    Returns the publisher of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        publisher = json_data.get('publisher').get('name')\n",
    "        return publisher\n",
    "    except:\n",
    "        print(\"Error: no publisher found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n",
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_publisher(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def get_year(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the year of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        if ('/chapter/' in url) or ('/article/') in url:\n",
    "            date = json_data.get('datePublished')\n",
    "            year = date.split('-')[0]  # get year from date (if date is available)\n",
    "            return year\n",
    "        if '/book/' in url:\n",
    "            year = json_data.get('copyrightYear')\n",
    "            return year\n",
    "\n",
    "    except:\n",
    "        print(\"Error: no year found\")\n",
    "        print(bs.name)\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2020\n",
      "2011\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_year(soup, url))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publication type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def get_publication_type(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the publication type of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '/book/' in url:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item'}).text\n",
    "        else:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item', 'data-test': 'article-category'}).text\n",
    "        return type\n",
    "    except:\n",
    "        print(\"Error: no publication type found in bs, deriving by url\")\n",
    "        if '/book/' in url:\n",
    "            return 'book'\n",
    "        elif '/chapter/' in url:\n",
    "            return 'chapter'\n",
    "        elif '/article/' in url:\n",
    "            return 'article'\n",
    "        #return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper\n",
      "Conference paper\n",
      "Conference proceedings\n",
      "Chapter\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_publication_type(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}