{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Scraper commands for publications on springer\n",
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here it is only about the steps, to parse are necessary so that it can be included in the end.\n",
    "\n",
    "There are different website types for publications on springer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "data": {
      "text/plain": "['https://link.springer.com/article/10.1007/s12525-020-00445-0',\n 'https://link.springer.com/chapter/10.1007/978-3-030-49570-1_14',\n 'https://link.springer.com/book/10.1007/978-3-642-22531-4',\n 'https://link.springer.com/chapter/10.1007/978-3-030-06234-7_27']"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_doi = 'https://doi.org/10.1007/s12525-020-00445-0'\n",
    "journal_full_link = 'https://link.springer.com/article/10.1007/s12525-020-00445-0'\n",
    "\n",
    "conference_chapter_link = 'https://link.springer.com/chapter/10.1007/978-3-030-49570-1_14'\n",
    "conference_book_link = 'https://link.springer.com/book/10.1007/978-3-642-22531-4'\n",
    "\n",
    "volume_contribution_link = 'https://link.springer.com/chapter/10.1007/978-3-030-06234-7_27'\n",
    "#volume_link = 'https://link.springer.com/book/10.1007/978-3-030-06234-7'\n",
    "\n",
    "springer_links = [journal_full_link, conference_chapter_link, conference_book_link, volume_contribution_link]\n",
    "springer_links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "# identify the type of the link\n",
    "def get_springer_link_type(url):\n",
    "    if '/chapter/' in url:\n",
    "        return 'chapter'\n",
    "    elif '/book/' in url:\n",
    "        return 'book'\n",
    "    elif '/article/' in url:\n",
    "        return 'article'\n",
    "    else:\n",
    "        return 'unknown'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article\n",
      "chapter\n",
      "book\n",
      "chapter\n"
     ]
    }
   ],
   "source": [
    "for link in springer_links:\n",
    "    print(get_springer_link_type(link))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def get_bs(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.5 Safari/605.1.15'}\n",
    "        r = requests.get(url, headers=headers)\n",
    "        print(r.status_code)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "    except:\n",
    "        print('Error: ', url)\n",
    "        return None\n",
    "    return bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "journal_soup = get_bs(journal_full_link)\n",
    "conference_chapter_soup = get_bs(conference_chapter_link)\n",
    "conference_book_soup = get_bs(conference_book_link)\n",
    "volume_contribution_soup = get_bs(volume_contribution_link)\n",
    "springer_soups = [journal_soup, conference_chapter_soup, conference_book_soup, volume_contribution_soup]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [],
   "source": [
    "# get whole data from json and loads to dict\n",
    "# articles need to be prefiltered because they are nested differently.'\n",
    "def get_json_data(bs):\n",
    "    json_string = bs.find('script', {'type': 'application/ld+json'}).text\n",
    "    json_data = json.loads(json_string)\n",
    "\n",
    "    if '{\"mainEntity\":' in json_string:\n",
    "        return json_data['mainEntity']\n",
    "    else:\n",
    "        return json_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating json files for the three different types of publications for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "outputs": [],
   "source": [
    "journal_json = get_json_data(journal_soup)\n",
    "conference_chapter_json = get_json_data(conference_chapter_soup)\n",
    "conference_book_json = get_json_data(conference_book_soup)\n",
    "volume_contribution_json = get_json_data(volume_contribution_soup)\n",
    "json_data_list = [journal_json, conference_chapter_json, conference_book_json, volume_contribution_json]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [],
   "source": [
    "# get names of json fields\n",
    "def get_json_fields(json_data):\n",
    "    return list(json_data.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "['headline',\n 'description',\n 'datePublished',\n 'dateModified',\n 'pageStart',\n 'pageEnd',\n 'license',\n 'sameAs',\n 'keywords',\n 'image',\n 'isPartOf',\n 'publisher',\n 'author',\n 'isAccessibleForFree',\n '@type']"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_fields(journal_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Fields\n",
    "Title #TODO get title also for book (if instruction or with json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [],
   "source": [
    "def get_title(bs):\n",
    "    try:\n",
    "        title = bs.find('h1', {'class': 'c-article-title'}).text\n",
    "        return title\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring customers’ likeliness to use e-service touchpoints in brick and mortar retail\n",
      "A Two-Phase Framework for Detecting Manipulation Campaigns in Social Media\n",
      "None\n",
      "Applications of Artificial Intelligence in Supply Chain Management and Logistics: Focusing Onto Recognition for Supply Chain Execution\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_title(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Authors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "outputs": [],
   "source": [
    "def get_authors(bs):\n",
    "    \"\"\"\n",
    "    Return list of authors in the format:\n",
    "    [{'name': 'Author Name', 'orcid': orcid}, ...]\n",
    "\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list of dicts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        authors = []\n",
    "        for author in json_data.get('author'):\n",
    "            name = author.get('name')\n",
    "            # split name at comma and reverse\n",
    "            name = name.split(', ')\n",
    "            name = name[1] + ' ' + name[0]\n",
    "            orcid = author.get('url')\n",
    "            authors.append({'name': name,\n",
    "                            'orcid': orcid})\n",
    "        return authors\n",
    "    except:  # if no author is found you cannot iterate over None\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Benjamin Barann', 'orcid': 'http://orcid.org/0000-0002-1965-2688'}, {'name': 'Jan H. Betzing', 'orcid': None}, {'name': 'Marco Niemann', 'orcid': None}, {'name': 'Benedikt Hoffmeister', 'orcid': None}, {'name': 'Jörg Becker', 'orcid': None}]\n",
      "[{'name': 'Dennis Assenmacher', 'orcid': None}, {'name': 'Lena Clever', 'orcid': None}, {'name': 'Janina Susanne Pohl', 'orcid': None}, {'name': 'Heike Trautmann', 'orcid': None}, {'name': 'Christian Grimme', 'orcid': None}]\n",
      "None\n",
      "[{'name': 'Bernd Hellingrath', 'orcid': None}, {'name': 'Sandra Lechtenberg', 'orcid': None}]\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_authors(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keywords #TODO may be replaced with BS scraping because weird data structure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [],
   "source": [
    "def get_keywords(bs):\n",
    "    \"\"\"\n",
    "    Return list of keywords from json data\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Return list of keywords in the format:\n",
    "    [keyword1, keyword2, ...]\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        keywords_string = json_data.get('keywords')\n",
    "        keywords = keywords_string.split(',')\n",
    "        return keywords\n",
    "    except:\n",
    "        print(\"Error: no keywords found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT in Business', 'e-Commerce/e-business']\n",
      "['Social campaign detection', ' Stream clustering', ' Unsupervised learning']\n",
      "['Java', ' XQuery', ' abstract interpretation', ' higher-order patterns', ' non-deterministic functions']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_keywords(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abstract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "outputs": [],
   "source": [
    "def get_abstract(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the abstract of the articles, books/proceedings do not have abstracts.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: Received url of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        abstract = json_data.get('description')\n",
    "        return abstract\n",
    "    except:\n",
    "        print(\"Error: no abstract found\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-commerce has embraced the digital transformation and innovated with e-service touchpoints to improve customers’ experiences. Now some traditional, less-digitalized brick and mortar (BaM) retailers are starting to counteract the increasing competition by adopting digital touchpoints. However, the academic literature offers little in terms of what determines customers’ behavioral intentions toward e-service touchpoints. Therefore, drawing from the dominant design theory, this article first conceptually adapts selected dominant touchpoints of leading e-commerce solutions to BaM retail. Then 250 shoppers are surveyed regarding the likeliness that they will use the selected touchpoints, followed by an exploratory factor analysis to determine the touchpoints’ characteristics that lead to the shoppers’ assessments. The results suggest that customers prefer touchpoints that support product search and selection, provide information, and increase shopping efficiency. The likeliness that surveyed shoppers will use the touchpoints was affected by the functionality provided, the content conveyed, and the mediating device. The results provide a foundation for further research on customers’ behavioral intentions toward BaM e-service touchpoints and provide useful information for BaM retailers.\n",
      "-------\n",
      "The identification of coordinated campaigns within Social Media is a complex task that is often hindered by missing labels and large amounts of data that have to be processed. We propose a new two-phase framework that uses unsupervised stream clustering for detecting suspicious trends over time in a first step. Afterwards, traditional offline analyses are applied to distinguish between normal trend evolution and malicious manipulation attempts. We demonstrate the applicability of our framework in the context of the final days of the Brexit in 2019/2020.\n",
      "-------\n",
      "None\n",
      "-------\n",
      "Emerging technologies like Artificial Intelligence (AI) show the potential to contribute significantly to the digitalization of supply chains. Nonetheless, the question which approaches from the field of AI are applied within supply chains as well as which supply chain problems or tasks are addressed with AI approaches has not been answered by scientific literature yet. Based on a structured literature review this paper aims at providing an answer to these questions. A special focus is given to the application areas for recognition approaches in supply chain execution, for which this paper provides an overview of those areas research is currently focusing upon.\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_abstract(soup, url))\n",
    "    print(\"-------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pdf #todo #TODO: download"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "def get_pdf(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the pdf link of the publication, if available. Download might require login. Sometimes the pdf is not in the soup object unfortunately\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf = None\n",
    "        #todo automate download\n",
    "        # differentiate between article, chapter and book\n",
    "        if '/article/' in url:\n",
    "            pdf = bs.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')\n",
    "\n",
    "        elif '/chapter/' in url:\n",
    "            pdf_box = bs.find('div', {'class': 'c-article-access-provider'})\n",
    "            pdf = pdf_box.find('a', {'data-track-action': 'Pdf download'}).get('href')\n",
    "\n",
    "        elif '/book/' in url:\n",
    "            pdf = bs.find('div', {'data-test': 'download-article-link-wrapper',\n",
    "                                  'class': 'js-context-bar-sticky-point-desktop'}).find('a').get('href')\n",
    "        if pdf is not None:\n",
    "            # append base url if necessary\n",
    "            if 'link.springer.com' in pdf:\n",
    "                return pdf\n",
    "            else:\n",
    "                return f'https://link.springer.com{pdf}'\n",
    "    except Exception:\n",
    "        print(\"Error: no pdf found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "data": {
      "text/plain": "['https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-030-49570-1_14.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-642-22531-4.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-030-06234-7_27.pdf']"
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_links = []\n",
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    test_links.append(get_pdf(soup, url))\n",
    "\n",
    "test_links\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "data": {
      "text/plain": "'https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf'"
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_soup.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publisher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "def get_publisher(bs):\n",
    "    \"\"\"\n",
    "    Returns the publisher of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        publisher = json_data.get('publisher').get('name')\n",
    "        return publisher\n",
    "    except:\n",
    "        print(\"Error: no publisher found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n",
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_publisher(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [],
   "source": [
    "def get_year(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the year of the publication\n",
    "    :param url: URL of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        if ('/chapter/' in url) or ('/article/' in url):\n",
    "            date = json_data.get('datePublished')\n",
    "            year = date.split('-')[0]  # get year from date (if date is available)\n",
    "            return year\n",
    "        if '/book/' in url:\n",
    "            year = json_data.get('copyrightYear')\n",
    "            return year\n",
    "\n",
    "    except:\n",
    "        print(\"Error: no year found\")\n",
    "        print(bs.name)\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2020\n",
      "2011\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_year(soup, url))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Page ranges\n",
    "For papers and contributions one can find the page range in the jsond data\n",
    "\n",
    "#### Start page"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [],
   "source": [
    "def get_start_page(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the start page of the publication in the volume/journal/proceeding\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Start page of the publication\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "    if '/chapter/' in url or '/article/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            start_page = json_data.get('pageStart')\n",
    "            return start_page\n",
    "        except:\n",
    "            print(\"Error: no start page found\")\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523\n",
      "201\n",
      "None\n",
      "283\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_start_page(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### End page"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [],
   "source": [
    "def get_end_page(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the end page of the publication in the volume/journal/proceeding\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: End page of the publication\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "    if '/chapter/' in url or '/article/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            end_page = json_data.get('pageEnd')\n",
    "            return end_page\n",
    "        except:\n",
    "            print(\"Error: no end page found\")\n",
    "            return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\n",
      "214\n",
      "None\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_end_page(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Publication type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_publication_type(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the publication type of the publication\n",
    "    :param url: URL of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '/book/' in url:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item'}).text\n",
    "        else:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item', 'data-test': 'article-category'}).text\n",
    "        return type\n",
    "    except:\n",
    "        print(\"Error: no publication type found in bs, deriving by url\")\n",
    "        if '/book/' in url:\n",
    "            return 'Book'\n",
    "        elif '/chapter/' in url:\n",
    "            return 'Chapter'\n",
    "        elif '/article/' in url:\n",
    "            return 'Article'\n",
    "        #return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper\n",
      "Conference paper\n",
      "Conference proceedings\n",
      "Chapter\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_publication_type(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Text of publication\n",
    "Text extraction of journal paper is simple because a unique identification of the tag is possible. For other publications we have to apply further logic to extract the text only. The result is a dictionary with chapter titles as keys and the text of the chapter as value."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [],
   "source": [
    "def extract_text_from_p_tags(p_tags):\n",
    "    \"\"\"\n",
    "    Help method to extract text from multiple p-tags\n",
    "    :param p_tags: List of p-tags as result of a bs search : bs4.element.ResultSet\n",
    "    :return: String with total text\n",
    "    \"\"\"\n",
    "    result_text = ''\n",
    "    for p in p_tags:\n",
    "        if result_text == '':\n",
    "            result_text += p.text  # No break for first paragraph\n",
    "        else:\n",
    "            result_text += f'\\n\\n{p.text}'  # Break for paragraph\n",
    "    return result_text\n",
    "\n",
    "\n",
    "def get_full_text(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the accessible text of the publication structured in different paragraphs. This may be the total text or only a part of.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Returns a list of ordered dictionaries. Each dictionary contains the name respectively text of the paragraph.\n",
    "    \"\"\"\n",
    "\n",
    "    def __get_full_text_chapter(bs, text):\n",
    "        \"\"\"\n",
    "        Internal method to extract text from chapter links\n",
    "        :param bs:\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        body = bs.find('div', class_='c-article-body')  # Body contains all sections\n",
    "        sections = bs.findAll('section')\n",
    "        len(sections)\n",
    "        text_section = ''\n",
    "        for section in sections:\n",
    "            chapter_name = section.find('h2',\n",
    "                                        class_='c-article-section__title js-section-title js-c-reading-companion-sections-item').text\n",
    "            p_tags = section.find('div', class_='c-article-section__content').findAll('p')\n",
    "            chapter_text = extract_text_from_p_tags(p_tags)\n",
    "            text.append({\n",
    "                'chapter_name': chapter_name,\n",
    "                'chapter_text': chapter_text\n",
    "            })\n",
    "            next_sibling_id = section.find_next_sibling().attrs.get('id')\n",
    "\n",
    "            # breaks loop when text sections are completed\n",
    "            if next_sibling_id == 'MagazineFulltextChapterBodySuffix':\n",
    "                break\n",
    "        return text\n",
    "\n",
    "    def __get_full_text_article(bs, text):\n",
    "        \"\"\"\n",
    "        Internal function to extract text from an article\n",
    "        :param bs:\n",
    "        :param text:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        main_div = bs.find('div', class_='main-content')\n",
    "        sections = main_div.findAll('section')\n",
    "        for section in sections:\n",
    "            chapter_name = section.h2.text\n",
    "            p_tags = section.findAll('p')\n",
    "            chapter_text = extract_text_from_p_tags(p_tags)\n",
    "            text.append({\n",
    "                'chapter_name': chapter_name,\n",
    "                'chapter_text': chapter_text\n",
    "            })\n",
    "        return text\n",
    "\n",
    "    text = []\n",
    "\n",
    "    if '/article/' in url:  # article extractions works\n",
    "        try:\n",
    "            return __get_full_text_article(bs, text)\n",
    "        except:\n",
    "            print(\"Error try clause\")\n",
    "\n",
    "    if '/chapter/' in url:\n",
    "        try:\n",
    "            return __get_full_text_chapter(bs, text)\n",
    "        except:\n",
    "            print(\"Error: try clause in chapter\")\n",
    "\n",
    "    if '/book/' in url:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapitel: Introduction \n",
      "\n",
      "How retailers and customers interact is constantly changing. The advent of omni-channel retailing made clear that customer interaction does not stop at a particular channel’s boundaries (Lemon and Verhoef 2016; Saghiri et al. 2017), as exemplified by hybrid customer interactions, where customers use digital and physical channels in parallel (Hosseini et al. 2017; Nüesch et al. 2015).\n",
      "\n",
      "With the emergence of smart retail technologies (Roy et al. 2017) that blur the boundaries between physical and digital channels (Roy et al. 2018), the number of touchpoints (TPs) a retailer must manage is increasing (Lewis et al. 2014; von Briel 2018). While the use of information and communication technology to improve processes has a long history in brick and mortar (BaM) retail, front-stage interactions with customers have primarily been based on person-to-person interaction (Betzing et al. 2018). In contrast, e-commerce, by definition, is built upon customer contact via e-service touchpoints (eTPs). Service is the application of competencies “through deeds, processes, and performances for the benefit of another entity or the entity itself” (Vargo and Lusch 2008, p. 26), which, when conveyed through a digital interface, is called e-service (Beverungen et al. 2011; Rowley 2006). eTPs are stimuli that customers may encounter when interacting with digital interfaces (Barann et al. 2020). In this article, eTPs are assumed to be classes of TPs (Heuchert et al. 2018) with e-commerce functionalities. For example, an online shop might provide access to product-comparison TPs. Trends like “bricks-and-clicks,” where TPs from stationary channels are adapted to e-commerce settings (Herhausen et al. 2015), allow online retailers to improve their existing eTPs and innovate new ones (e.g., Garnier and Poncin 2019; Jiyeon Kim and Forsythe 2008a, 2008b). The e-commerce industry has gained experience with eTPs over the last two decades, so it can be assumed that e-commerce has converged toward a set of dominant eTPs that appear in most online shops (cf. Suárez 2004).\n",
      "\n",
      "Retailers that operate exclusively in the BaM channel face pressure to innovate their TPs since the digital transformation has profoundly impacted the competitive market structure in favor of e-commerce and digital retail business models (V. Kumar et al. 2017; Verhoef et al. 2015). In addition, customers’ expectations regarding digital services offered by BaM retailers are increasing (Blázquez 2014; Bollweg et al. 2020; Hagberg et al. 2016). To create customer value, retailers can choose from a wide variety of technologies and eTPs (Vargo and Lusch 2008; Voorhees et al. 2017; Willems et al. 2017), but doing so is challenging, as their introduction carries risks and uncertainties (Pantano 2014), and BaM retailers have little guidance regarding what eTPs to implement. Research lacks clarity regarding customers’ intentions to use eTPs in BaM retail stores. While research investigates customers’ acceptance of various eTPs in e-commerce,Footnote 1 most studies on channel choice suggest that customers’ behavior in e-commerce and BaM retail differs (Schramm-Klein et al. 2007). However, only a few studies give advice regarding individual technologies and online practices that can be offered in the physical retail servicescape.Footnote 2 To fill this gap, this article investigates customers’ behavioral intentions toward BaM eTPs.\n",
      "\n",
      "Customers are likely to be familiar with the most prominent eTPs in e-commerce, so it can be argued that comparable eTPs for physical stores are a good starting point for BaM retailers to meet customers’ ever-changing expectations and a suitable subject for investigation. Therefore, the first research question is:\n",
      "\n",
      "\n",
      "RQ1: Are customers likely to use eTPs, which have been adopted from e-commerce and adapted to BaM retail?\n",
      "\n",
      "\n",
      "Furthermore, to determine the likeliness that customers will use such adapted eTPs in BaM retail stores, this manuscript aims at assessing what TP characteristics determine customers’ interest in the eTPs. Thus, the second research question is:\n",
      "\n",
      "\n",
      "RQ2: Is the likeliness that customers will use these e-service touchpoints affected by the touchpoints’ characteristics?\n",
      "\n",
      "\n",
      "An exploratory sequential multi-method approach (Creswell 2013; Mingers 2003) was used to answer these research questions and provide a broad overview of eTPs for BaM retail stores. First, a set of dominant eTPs offered by leading e-commerce platforms was selected, and each TP was adapted for use in the physical BaM servicescape. Second, a quantitative survey (Recker 2013) was fielded to 250 potential shoppers to determine the likeliness that they would use the candidate eTPs in a BaM context. Next, the determinants of the likeliness that customers would use the eTPs were subject to statistical tests and an exploratory factor analysis (Fabrigar et al. 1999) to reveal the unobserved TP characteristics that led to the survey results. Related to studies that focus on the overarching channels and interfaces, this work explores the determinants of customers’ behavioral intentions toward eTPs in BaM retail stores. The exploratory results suggest that customers’ intentions to use various kinds of BaM eTPs vary and are affected by their characteristics. Therefore, further research that considers the individual TPs next to more coarse-grained concepts is justified, as is whether to treat groups of eTPs that have common characteristics similarly.\n",
      "\n",
      "The remainder of this article unfolds as follows: First, the research background is introduced, followed by an explanation of the research approach. Then the eTPs are adapted, and the survey results are presented to address RQ1. Next, RQ2 is addressed by revealing the results of the exploratory factor analysis. The penultimate section discusses the findings, and finally, the article concludes with a summary, a discussion of the study’s limitations, and opportunities for further research.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Research background \n",
      "\n",
      "Optimizing the customer experience requires companies to take a fine-grained view of all the TPs its customers have with them (von Briel 2018). Omni-channel management uses “a synergetic management” (Verhoef et al. 2015, p. 176) of TPs across all available channels to improve their overall performance. However, according to Becker and Jaakkola (2020, p. 637), customer experiences are all “non-deliberate, spontaneous responses and reactions to particular stimuli,” which cannot be directly created. Instead, they suggest that a company can define intended experiences, design TP stimuli accordingly, and manage the customers’ TP encounters that follow. Research offers various versions of what constitutes the TP and the channel (e.g., Berendes et al. 2018; Kronqvist and Leinonen 2019; Richardson 2010). The channel usually refers to a particular medium that facilitates the interaction between a company and its customers (Halvorsrud et al. 2016; Neslin et al. 2006). The concepts of offline, online/digital, and mobile channels describe collections of related media, such as online shops and social media, which are specific digital channels or TPs (e.g., Hickman et al. 2019; Jocevski et al. 2019; Straker et al. 2015). Others understand TPs as individual channels or media (e.g., Baxendale et al. 2015; Lim et al. 2015; Straker et al. 2015), actual moments of contact or encounters that constitute customer journeys (e.g., Halvorsrud et al. 2016; Homburg et al. 2017; Verhoef et al. 2015), and perceptible stimuli that offer the potential for encounters (e.g., S. Davis and Longoria 2003; Kronqvist and Leinonen 2019; Richardson 2010). This article follows a differentiated understanding (e.g., Berendes et al. 2018; Følstad and Kvale 2018; Heuchert et al. 2018; Kronqvist and Leinonen 2019) and defines the customer touchpoint as “a stimulus fulfilling a specific role within the customer journey. It has an interface, which grants access to the stimulus and is mediated by a human, an analog object, or a technology situated in a physical or digital sphere. When encountering a touchpoint, a message between the customer and the retailer, its brand, or other customers is transmitted. This encounter causes a customer experience” (Barann et al. 2020, p. 7 in preprint). The customer journey is a process or path made up of a sequence of TPs the customer encounters to use or access a service (Becker and Jaakkola 2020; Følstad and Kvale 2018; Patrício et al. 2011). A medium conveys a whole collection of stimuli via an interface like a smartphone application (app) or a human-mediated service interface. The medium is subsequently assigned to a type of channel (Barann et al. 2020).\n",
      "\n",
      "Figure 1 illustrates the hierarchical relationship among the channel, the medium, the TP interface, and the TP stimuli. Each concept is the subject of its own body of scholarly work. Transcending the hierarchy, research also discusses channel choice, technology acceptance, and customers’ behavioral intentions toward individual TPs.\n",
      "\n",
      "Exemplary Non-Exclusive and Non-Exhaustive Relationships between Channels, Media, Interfaces, and Stimuli. Adapted from Wagner (2015)\n",
      "\n",
      "In the presence of multiple and integrated channels, understanding the determinants of customers’ channel choice behavior is a complex issue that is subject to intense research (Galipoglu et al. 2018; Steven et al. 2018; Neslin et al. 2006). Research finds that marketing efforts, channel attributes, social effects, channel integration, situational factors, and individual differences among customers, such as previous channel experience, determine customers’ channel choice (Melero et al. 2016; Neslin et al. 2006).\n",
      "\n",
      "As a result of the introduction of new digital channels and their increasing interconnections, companies must now ensure that their channels meet their customers’ requirements for each stage of the customer journey, instead of the customer journey as a whole (Zhao and Deng 2020). Customers choose their channels based on the tasks they seek to complete (Maity and Dass 2014), the stage of their customer journey (Frasquet et al. 2015; Hummel et al. 2017), and the degree to which a channel’s attributes are suited to the customer’s shopping goals (Dholakia et al. 2010). The relevance of the channels’ attributes to the customer varies with the situation along the journey. In response, existing research assesses the sequences of choices as parts of customer journeys. The complexity of omni-channel customer journeys makes it a paramount concern for researchers and firms to understand customers’ choices of interactions along these journeys (Barwitz and Maas 2018).\n",
      "\n",
      "Retailers can add a variety of technologies to their BaM stores (Inman and Nikolova 2017), blending them into a holistic and integrated customer experience (Blázquez 2014). When they integrate self-service (e.g., Falk et al. 2007) or other smart retail technologies (e.g., Roy et al. 2018), BaM retailers add new digital service interfaces to their physical servicescape, impacting their customers’ perceptions about the channel. For example, Wagner (2015) finds that the interfaces provided for customers to access an electronic channel impact their channel evaluations. Therefore, retailers should not only consider each channel as a whole but also each channel’s components to understand and guide customers’ channel choice.\n",
      "\n",
      "Customers’ perceptions of value are affected by their in-store experiences, which themselves are affected by technology. To improve this experience, the applied technology has to meet the customers’ expectations and be relevant to them (Blázquez 2014). Besides self-service technologies, mobile technologies can bridge the gap between online and offline channels, as they can mirror the e-commerce experience in BaM retail (Mirsch et al. 2016). These technologies impact the customer journey and enable the introduction of new TPs (Lemon and Verhoef 2016). To select beneficial technologies (Inman and Nikolova 2017), retailers require knowledge about their customers’ acceptance of these technologies (Pantano 2014). Roy et al. (2018, p. 156) suggest academia to “explore customers’ acceptance of specific” technologies in more detail.\n",
      "\n",
      "Studies on the acceptance of retail technologies employ the well-established Technology Acceptance Model (e.g., F. D. Davis 1985, 1989) or the Unified Theory of Acceptance and Use of Technology (Venkatesh et al. 2003, 2012). Such studies analyze factors that impact customers’ attitude toward (e.g., Müller-Seitz et al. 2009; Roy et al. 2018), behavioral intention toward (e.g., Chopdar et al. 2018; Müller-Seitz et al. 2009; Roy et al. 2018), intention to use (e.g., Aloysius et al. 2018; El Azhari and Bennett 2015), and use behavior (e.g., Chopdar et al. 2018; Demoulin and Djelassi 2016) regarding retail technologies like mobile shopping apps (e.g., Chopdar et al. 2018; Natarajan et al. 2018), location-based retail apps (e.g., Kang et al. 2015; Uitz and Koitz 2013), Radio-Frequency Identification (RFID) technologies (e.g., Müller-Seitz et al. 2009; Rothensee and Spiekermann 2008), or self-service technologies (Demoulin and Djelassi 2016; Weijters et al. 2007), as well as the in-store use of personal smartphones (e.g., Mosquera et al. 2018).\n",
      "\n",
      "Studies that address what leads to customers’ acceptance of technologies often miss to consider the impact of specific functionalities when a generic type of technology or an app that might be able to fulfill various tasks along the customer journey is the subject of the analysis. Still, some authors have conducted sub-studies that compared BaM technologies that offer certain functionalities (Inman and Nikolova 2017) or have certain service characteristics (Aloysius et al. 2018). These studies find that certain functionalities and design characteristics of technologies and services affect customers’ perceptions of technology in BaM retail stores. Natarajan et al. (2018) find that the type of device moderates the effect of various variables on the customers’ intentions to use mobile shopping apps. While channel choice is affected by the available interfaces (Wagner 2015), customers’ perceptions of such interfaces depend on the specific functionalities (Aloysius et al. 2018; Inman and Nikolova 2017) and the device used (Natarajan et al. 2018). In retail, the functionalities of, for example, a smartphone app can be considered TPs intended for certain stages of the customer journey (Boyd et al. 2019). Therefore, retailers should consider not only each interface as a whole but its components (i.e., its eTPs) to understand and guide customers’ technology acceptance.\n",
      "\n",
      "TPs offer various means of interaction during the customer journey (Boyd et al. 2019; Jocevski et al. 2019). All of the TPs customers encounter during their journeys have “direct and more indirect effects on purchase and other customer behaviors” (Lemon and Verhoef 2016, p. 82), so optimizing customers’ experiences requires an understanding of what characteristics cause these effects (Ponsignon et al. 2017; Verhoef et al. 2015). This article focuses on the factors that determine customers’ behavioral intentions toward eTPs in BaM stores. This manuscript understands these behavioral intentions as “the degree to which a person has formulated conscious plans to perform or not perform some specified future behavior” (Warshaw and Davis 1985, p. 214), that is, the likelihood that a person uses a specific eTP as part of a future BaM customer journey.\n",
      "\n",
      "Few studies investigate TPs (instead of channels) on a fine-grained level. Some use the TP concept to discuss various channels, media, or interfaces that belong to channels.Footnote 3 Few explicitly name and focus on TP stimuli or encountersFootnote 4 or focus on their characteristics.Footnote 5 Several studies discuss the determinants of customers’ behavioral intentions toward eTPs in an e-commerce context without calling them “touchpoints.”Footnote 6 Some studies analyze customers’ behavioral intentions toward TPs that are adapted from BaM retail to e-commerce (e.g., Garnier and Poncin 2019; Jiyeon Kim and Forsythe 2008a, 2008b). While most research on channel choice suggests that the customer behavior in e-commerce and BaM retail differs (Cervellon et al. 2015; Schramm-Klein et al. 2007), Schramm-Klein et al. (2007) and Walsh et al. (2010) show that customers’ criteria for evaluating e-commerce and BaM stores are similar but also that customers’ evaluation of services is significantly more important in online shops. Still, smart retail technologies in particular (Roy et al. 2017; Roy et al. 2018), along with the hybrid customer interactions they foster (Hosseini et al. 2017; Nüesch et al. 2015), unfold a new smart servicescape (Sanjit K. Roy et al. 2019) that combines aspects of BaM retail with those of e-commerce, leading to a technology-mediated in-store experience (Roy et al. 2017). Therefore, whether results from studies on eTPs in e-commerce can be transferred to BaM retail remains in question.\n",
      "\n",
      "However, only a few studies focus on customers’ behavioral intentions toward eTPs in this hybrid setting, although they do not use the term TP but use online practices and technologies (Lazaris et al. 2015a, 2015b), features (Burke 2002), or services (e.g., de Kerviler et al. 2016; Schierz et al. 2010), or name the particular TP under consideration. For example, studies focus on customers’ acceptance of mobile information search (de Kerviler et al. 2016), mobile self-checkout (Johnson et al. 2019), mobile payment (de Kerviler et al. 2016; C. Kim et al. 2010; Schierz et al. 2010), mobile coupons (Liu et al. 2015), mobile recommendation agents (Kowatsch and Maass 2010), mobile marketing (Persaud and Azhar 2012), or specific fashion retail eTPs (H.-Y. Kim et al. 2017; Weinhard et al. 2017). Some articles on self-service technologies (e.g., Aloysius et al. 2018; Demoulin and Djelassi 2016) are concerned with specific self-checkout TPs. Similar to this work, Lazaris et al. (2015a, 2015b) compare customers’ valuation of various online practices and technologies in BaM retail stores.\n",
      "\n",
      "Not all studies use theoretical constructs to measure customers’ behavioral intentions toward (e.g., Liu et al. 2015), intentions to use (e.g., de Kerviler et al. 2016; C. Kim et al. 2010; H.-Y. Kim et al. 2017), intentions to participate in using (e.g., Persaud and Azhar 2012), or attitudes toward (e.g., de Kerviler et al. 2016; H.-Y. Kim et al. 2017; Schierz et al. 2010) eTP in BaM retail. Studies indicate that customers’ perceptions of, attitudes toward, and behavioral intentions differ across various eTPs (H.-Y. Kim et al. 2017) and that the predictors of their intention to use various TPs also differ (de Kerviler et al. 2016; H.-Y. Kim et al. 2017). Lazaris et al. (2015a, 2015b) use two samples in two studies to analyze customers’ perceptions of the importance of the same technologies and practices applied in BaM retail stores. In both studies, the groups of eTPs whose ratings are strong or weak are similar, and they find no significant differences in the subsets of TPs. de Kerviler et al. (2016) also find that the strength of the spillover between customers’ behavioral intentions toward different eTPs is positively related to their similarity.\n",
      "\n",
      "While such studies provide first insights into the determinants of customers’ behavioral intentions toward eTPs in BaM retail, the literature covers only a small portion of extant BaM eTPs, and there is no consensus about the approach to be used to measure the determinants that cause customers’ behavioral intentions toward eTPs in BaM retail. In summary, then, this exploratory study investigates the factors that determine the likeliness that customers would use eTPs in BaM retail, that is, how customers choose the means to communicate, interact, and exchange with other actors, such as the retailer, during their BaM customer journeys. Fig. 2 provides an overview of some of the relationships considered by the interdependent research streams at each level. Appendix A provides additional details about related works in these literature streams.\n",
      "\n",
      "Exemplary Research Perspectives in Channel Choice, Technology Acceptance, and Behavioral Intentions Toward Touchpoints (Numbers refer to the IDs in Table A.1 in Appendix A)\n",
      "\n",
      "Even though doing so is unconventional in the area of information systems research (Mingers 2001), the posited research questions ask for a combination of empirical and interpretative methods: While assessing the likeliness that customers would use eTPs (RQ1) implies empirical work, understanding the factors that cause customers to use the TPs (RQ2) requires going beyond quantitative work, so this study uses a data-driven (Müller et al. 2016) multi-method approach (Mingers 2003) to address its research questions. This mix of methods allows for an exploratory discussion of multi-sourced eTPs candidates that cover both innovative (still theoretical) eTPs and existing and implemented eTPs that are chosen from an initial qualitative web-content analysis. The structure and contextualization of the methods used in the research framework are visualized in Fig. 3. With the output of each step, typically being the input for its successor, an explanatory, sequential approach is followed (Creswell 2013). This study extends the work of Betzing et al. (2019) by using an in-depth analysis to discuss the underlying factors causing the likeliness that customers would use eTPs in BaM retail stores, transcending the mere descriptive ranking of eTPs that are likely to be used.\n",
      "\n",
      "Research Framework\n",
      "\n",
      "The first step was to identify candidate TPs for the analysis using a qualitative web-content analysis approach (Mayring 2014), following the lens of dominant design theory (Suárez and Utterback 1995) and acknowledging the lack of a formally derived list of eTPs for BaM retail in the literature. Through the systematic analysis of popular e-commerce solutions, a selection of commonly offered eTP candidates with which customers are likely to be familiar was selected.\n",
      "\n",
      "To assess the likeliness that customers would use generic BaM eTPs—and not specific e-commerce instantiations (e.g., the Amazon shopping cart)—their features were identified to adapt them to BaM retail. In keeping with Beverungen et al. (2011), service blueprints were created to transfer the services from one servicescape to the other. These blueprints were also used to support the discussions between the researchers and to inform the survey design.\n",
      "\n",
      "A quantitative survey research approach was followed (Recker 2013) to capture the likeliness that shoppers will use the BaM eTPs (RQ1) derived in the preceding step. As method advocates like Bitner et al. (2008) recommend initial training to establish a common understanding of formalized models like service blueprints, these blueprints would have been unsuitable for describing the eTPs to survey participants. Hence, similar to Inman and Nikolova (2017), Aloysius et al. (2018), and Kleijnen et al. (2007) who used textual descriptions to describe technologies or services under investigation, each eTP was described by using a less formalized description of the blueprints, keeping the semantic essence while changing the syntactical frame. Alternative approaches turned out to be inappropriate, as practical implementations of the eTPs in BaM retail stores are scattered across retailers, and several identified eTPs still lack a BaM implementation. While lab experiments would have allowed investigating specific TPs on a more detailed and technical level, the description-based survey was preferable for three reasons: First, a wider variety of TPs could be covered by avoiding costly prototype implementations. Second, abstracting from the specifics of the individual TPs allowed to observe more general TP-spanning characteristics affecting the likeliness that customers would use them. Third, by asking participants to conduct an imaginative shopping trip in a local BaM store that started to offer a series of eTPs rather than evaluating customer perceptions at a specific BaM store, the survey abstracted from contextual aspects that might have affected the results.\n",
      "\n",
      "Based on the data collected in the preceding step, correlation tests (Kendall 1938; Pearson 1895; Spearman 1904) and multivariate multiple (Dattalo 2013) ordinal logistic regressions were performed to analyze the results and provide a basis for answering RQ1. To clarify the survey results and provide a foundation to answer RQ2, an exploratory factor analysis (EFA) was conducted on the 26 survey items capturing the likeliness that the participants would use the individual eTPs. An EFA is a statistical approach that can be used to identify the common underlying dimensions or structures of survey items by analyzing their interrelationships (Hair et al. 2013). In contrast to confirmatory factor analysis, the purpose of which is to evaluate a proposed theory, EFA is used if no prior theory exists (Williams et al. 2010). The factor analysis found seven unobserved characteristics that caused the variance in the data. Finally, to ensure a theoretically grounded interpretation of these factors, three researchers independently coded each of the adapted eTPs in terms of their common TP characteristics (see Table E.4 in Appendix E.2) and the initial blueprints.\n",
      "\n",
      "This section covers the “Data Collection” phase and also the first analytical elements (i.e., the “Descriptive Statistics”). As this article is an extension to Betzing et al. (2019), the first two steps (“Qualitative Web Analysis” and “Blueprinting”) are shortened, as this article’s focus is the subsequent statistical analysis and interpretation. Further details on these steps can also be found in the Appendices B and C.\n",
      "\n",
      "Since no comprehensive scientific overview of potential eTPs for BaM retail stores was found, dominant eTPs that are promising for adaptation in the physical retail servicescape were derived from e-commerce. A qualitative web-content analysis (Mayring 2014) was conducted following the lens of dominant design theory, which proposes that a product category establishes a representative set of functions over time that is then accepted as standard (Suárez and Utterback 1995). This lens has been applied to technological milestones like microprocessor designs, PC operating systems, and television systems (Suárez 2004; Suárez and Utterback 1995). Murmann and Frenken (2006) develop a generalized framework for dominant design research, advancing this theoretical lens by making it applicable not only to technologies but to multi-level systems (Kask 2011). Therefore, as Kask (2011) argues, it is even applicable to organizational systems like market channels that are comprised of various elements with different missions. The dominance of technology can be investigated on several levels of analysis, one of which is by considering “technological artifacts as [being] composed of subsystems that are linked together [...] through specific interfaces” (Suárez 2004, p. 274).\n",
      "\n",
      "E-commerce systems can be considered such artifacts, as they are digital interfaces that belong to the online channel and are composed of various eTPs. As e-commerce is a mature domain (V. Kumar et al. 2017), it is fair to suppose that leading e-commerce systems have set a dominant design that is comprised of a set of functions that represent the requirements of various types of users (cf. Suárez and Utterback 1995). Accordingly, the designs of the eTPs that leading e-commerce systems offer most often can be considered to be dominant and that they are likely to be used in BaM retail stores as well.\n",
      "\n",
      "Therefore, the proprietary solutions of Amazon, Otto, and Zalando, the German e-commerce market leaders (Betzing et al. 2019; EHI Retail Institute 2018), were analyzed and major instances of five widespread commercial off-the-shelf (COTS) e-commerce solutions—Shopify, Magento, WooCommerce, XT:Commerce, and Shopware—were assessed (Betzing et al. 2019; Datanyze 2018). To address variances that may result from national peculiarities, customization, and differing product categories, three major European e-commerce retailers were sampled for each of the five solutions. Thirty-five eTPs were identified from which any that were not offered by at least four instances (lack of commonality) or that required an online shop for service delivery were filtered out, resulting in twenty adaptable eTPs.\n",
      "\n",
      "Service blueprints were created to transfer the eTPs from e-commerce to BaM retail (cf. Beverungen et al. 2011). Service blueprinting is a well-established, customer-focused modeling method for service innovation and improvement (Beverungen et al. 2011; Bitner et al. 2008) that yields “a picture or map that portrays the [planned] customer experience and the service system, so that the different people involved in [its development][...] can understand it objectively, regardless of their roles or their individual points of view” (Zeithaml et al. 2017, p. 238).\n",
      "\n",
      "Figure 4 illustrates the adapted In-Store Navigation (S) TP as an example of a service blueprint. Creating the service blueprints involved considering the mediating technology and the necessary activities to be performed by the customer and the BaM retailer (as the service provider). To accommodate customers’ use of various digital devices in accessing service, the original blueprinting method was extended with an additional layer that listed the digital devices that could be used to consume the service. Frequent discussion among three researchers ensured that the blueprints were (a) suitable representations of the identified eTPs and were (b) not subject to excess bias.\n",
      "\n",
      "Exemplary Service Blueprint for an Adapted In-Store Navigation (S) Touchpoint\n",
      "\n",
      "The 20 e-commerce eTPs were adapted to the 26 BaM eTPs, as depicted in Table 1, mostly mediated by a smartphone app. Numeric differences are due to the mapping applied, which mapped some multiple-input TPs to a single output TP and vice versa, and different mediating devices—i.e., terminal and smartphone—were considered for some of the TPs. The full descriptions of the adapted eTPs and their service blueprints can be found in Appendix C of this manuscript for researchers who want to reproduce (Peng 2011) and/or extend this article’s contributions.\n",
      "\n",
      "To provide additional structure, each eTP was initially categorized into one of four categories based on its value:\n",
      "\n",
      "Search & Navigation: eTPs in this category are primarily solution-oriented shopping aids (Chang and Kukar-Kinney 2011) in the pre-purchase stage (Lemon and Verhoef 2016) that assist in reducing search time and information overload (Betzing et al. 2019).\n",
      "\n",
      "Product Information: eTPs in this category are research-supporting shopping aids (Chang and Kukar-Kinney 2011) in the pre-purchase state that assist with information retrieval and alternative evaluations (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Selection & Checkout: eTPs in this category aid customers in planning, conducting, and controlling past, current, and future purchases (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Communication & Support: eTPs in this category are marketing, customer engagement, and customer care-centric eTPs that are independent of the customer journey stage (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Survey Research Approach\n",
      "\n",
      "While the adaption of dominant e-commerce TPs appears promising for BaM retailers, whether and to what extent customers are likely to use them remains unclear, as “a dominant design is not always that design which has greatest technological sweetness” (Suárez and Utterback 1995, p. 417). Therefore, a quantitative online survey (Recker 2013) was conducted to get an idea of customers’ behavioral intentions toward eTPs. Participants were first asked to imagine themselves going on a shopping trip in a futuristic BaM retail store that offers digitally enhanced services via a touchscreen terminal and/or an app on their smartphone. Participants were asked to abstract from the type of products sold and focused on the service offerings. Next, the eTP categories were introduced. Throughout the survey, each eTP was introduced in one paragraph. For example, the Product Comparison TP was described as follows: “Imagine yourself planning to select a product, e.g., a new television, out of a set of similar options. Within the Smart Store, you can use your Companion App to scan two to multiple products’ QR-Codes and compare them with each other. A table with relevant information on each product, e.g., size, price, and technical features will be displayed. Likewise, you can use a Terminal to compare multiple products by entering the product names.”\n",
      "\n",
      "The likeliness that the participant would use the eTP was surveyed using a single five-point Likert scale item (e.g., Bernard 2013) (e.g., “How likely would it be for you to use such a Product Comparison Service via an App?”). If applicable, a second item was included to investigate the alternative implementation on a terminal. The participants were also asked whether they use their smartphones to support their activities in BaM stores and how frequently they shop online. Participants provided demographic information, including their country of origin, education, gender, and age.\n",
      "\n",
      "Since BaM retail is prevalent in society, the survey was not limited to a particular audience but used prolific.co, a recruiting platform that provides researchers with representative samples of participants in terms of age, gender, and educational level, to recruit a diverse sample of more than 300 participants aged eighteen and older who were from Western countries (Betzing et al. 2019, p. 565).\n",
      "\n",
      "An attention-check question (adapted from Oppenheimer et al. (2009)) used to filter out inattentive participants yielded 250 valid responses. All but one participant had purchased goods and services online at least once: Nine participants (3.6%) engaged in e-commerce activities daily, 105 (42.0%) did so weekly, half did so roughly once a month, and ten used e-commerce as infrequently as once a year. The average age of the participants was 32.69 years (\\( \\overset{\\sim }{x} \\) = 31 years, σ = 9.96 years), 53.6% of whom were women. Participants came from the United Kingdom (145), the United States (52), Canada (12), Portugal (9), the Netherlands (4), and sixteen other European countries (28). Almost all the respondents (99.20%) reported owning a smartphone, and 72.80% reported using their smartphones or tablets in stores to support their shopping process. The average time participants required to complete the survey was 9 min and 37 s. Participants received £1.15 for their participation (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Figure 5 shows the distribution of the responses to the eTPs, sorted by category and in descending order by average rating. The global average rating was 3.58 points. The Social Media TP ranked worst with an average of points, while the Mobile Self-Checkout TP ranked highest with an average of 4.35 points. The comparison of the four touchpoint categories revealed that respondents were most likely to use the selection and checkout TPs (∅ 3.92 points). Product information TPs (∅ 3.79 points) and search and navigation TPs (∅ 3.73 points) ranked similarly, whereas respondents were much less likely to use the communication and support TPs (∅ 2.94 points). The Social Media (σ2 = 1.71; σ = 1.31), Periodic Newsletter (σ2 = 1.64; σ = 1.28), Location-Based Newsletter (σ2 =1.60; σ = 1.27), and Messaging TPs (σ2 = 1.48; σ = 1.22) were the most controversial (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Distribution of the Likeliness that Customers Would Use the E-Service Touchpoints (grouped by touchpoint categories, with groups in descending order of average score)\n",
      "\n",
      "Six eTPs were surveyed regarding the two service interfaces, smartphone (S) and in-store terminal (T). The results show that respondents preferred smartphones over terminals by an average of .50 points, and every e-service was ranked higher when it was accessed via a smartphone app. Differences in the likeliness that customers would use the smartphone and terminal variants were lowest for the Product Exploration (S&T) TPs (.26 points) and highest for the Product Information (S&T) TPs (.71 points) (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Pairwise Spearman’s rank coefficients ρ between each e-service and the respondents’ ages indicated no significant relationships for TPs other than the TPs Product Comparison (T) (ρ = .48; p < .001), Read Product Review (T) (ρ = .45; p < .01), and FAQ (T) (ρ = .39; p < .01), all of which had a positive relationship with age. On the other hand, the Social Media TP (ρ = −.43; p < .01) had a negative relationship with age. Kendall’s τb did not indicate significant relationships between gender and the respondents’ answers, except for a weak positive relationship between female respondents and the Messaging TP (τb = .16; p < .01). However, women were, on average, .08 points more likely to use the TPs than men were. Although not statistically significant, women were more likely than men were to use a smartphone (.31 points) or an in-store terminal (.38 points) to read product reviews (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Spearman’s rank coefficient was employed again to assess relationships between the eTPs. Results show that TPs accessed via a terminal correlated with each other but not with other TPs. Several communication and support TPs had comparatively strong relationships with each other: The Product Exploration (S) TP strongly correlated with the In-Store Navigation (S) (ρ = .51), and the Product Information (S) TP (ρ = .46). Likewise, the In-Store Navigation (S) and Product Information (S) TPs were also strongly correlated (ρ = .51). A scatter plot showing the results of this analysis is provided in Fig. D.1 in Appendix D.1 (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Finally, 26 ordinal logistic regressions were performed, each of which considered the likeliness that participants would use one of the eTPs as the dependent variable and, as independent variables, the respondents’ BaM demographics, smartphone use, and online shopping frequency (see Table D.1 in Appendix D.2).Footnote 7 In addition to reconfirming relationships like the influence of being female on the likeliness that a participant would use the Read Product Review (S&T) and the Messaging TPs, the results revealed further effects between the independent variables and the likeliness that participants would to use certain eTPs. For example, retail-related smartphone use was a significant predictor of the likeliness that participants would use most eTPs. Other results are considered in the discussion section of this manuscript.\n",
      "\n",
      "Overall, the relationships between the variables and the correlations between the BaM eTPs differed, giving a reason to assess whether unobserved eTPs characteristics could explain these variances. Therefore, an exploratory factor analysis (Fabrigar et al. 1999) was conducted to reveal the factors behind the likeliness that customers would use the BaM eTPs in the sample. Because of this research’s exploratory nature, no a priori assumptions about the characteristics were made. Instead, a variety of possible eTPs were included. Still, a ratio of approximately five survey items to one derived factor was reached (Fabrigar et al. 1999). Regarding the suitability of the sample, the response to variable ratio is in the mid-field, approximately 10:1 (Comrey 1973; Williams et al. 2010), and the anti-image correlation matrix did not reveal any high partial correlations (Hair et al. 2013). The Kaiser-Meyer-Olkin Measure of Sampling Adequacy (Kaiser 1970; Kaiser and Rice 1974) showed a “meritorious” (Hair et al. 2013, p. 102) score of .858, and Bartlett’s Test of Sphericity also passed with a p-value of .000 (Hair et al. 2013). In keeping with the analysis’ goal of identifying the characteristics of eTPs that affect the likeliness that customers would use them, the factor extraction method was selected (Hair et al. 2013). A common factor analysis (CFA) with principal axis factoring was chosen instead of principal component analysis (PCA) because CFA identifies latent constructs, which results in a reflective model of factors that cause the observed variables (Costello and Osborne 2005; Gorsuch 1997; Henson and Roberts 2006). The frequently applied orthogonal VARIMAX rotation was used as a factor rotation method to identify unique uncorrelated factors (Henson and Roberts 2006). An initial solution with seven factors was derived based on the scree test and parallel analysis (95th percentile) (Costello and Osborne 2005; Fabrigar et al. 1999; Glorfeld 1995; Hair et al. 2013). Only the Product Availability and the App-Equipped Clerk TPs had loadings smaller than the recommended threshold value of .4 (Ferguson and Cox 1993; Hair et al. 2013). Likewise, the FAQ (T) and Read Product Review (T) TPs showed cross-loadings higher than .4 on more than one factor, causing the algorithm to return two factors that had just one variable strongly loading onto them. As suggested by literature (Ferguson and Cox 1993; Hair et al. 2013), these variables were removed from the model. Performing these tests on the reduced data revealed no issues.\n",
      "\n",
      "Fig. 6 presents the resulting factors and their loadings. This final model explains 51.578% of the variance (see Table E.1 in Appendix E.1), which is larger than the threshold value suggested by Merenda (1997). Table E.2 and Table E.3 in Appendix E.1 provide information on the rotated factor matrix, factor loadings, and the factor score coefficient matrix. Fig. E.1 in Appendix E.3 also shows that all eTPs described by a corresponding factor significantly correlate internally, and in some cases, these correlations are comparatively strong.\n",
      "\n",
      "Factors Affecting the Likeliness that Customers Would Use the E-Service Touchpoints\n",
      "\n",
      "Factor interpretation is a qualitative process that focuses on the researchers’ understanding of the survey items onto which a factor loads most heavily. Therefore, each survey item is assigned to the factor with the highest loading and only considered once during the process (Hair et al. 2013; Williams et al. 2010). To support this interpretation, TP characteristics were derived from the literature for coding the eTPs based on the survey descriptions. Only a few studies explicitly name and delimit characteristics of TPs. Table E.4 in Appendix E.2 explains the adapted characteristics that were applied. In effect, the eTPs were coded according to the themes “content display” (i.e., information, promotion, support, or revenue), “purpose of use” (i.e., function, diversion, or interaction), and “direction of communication” (i.e., simplex or duplex) (Straker et al. 2015, p. 114). They were also coded according to the “ownership” (Lemon and Verhoef 2016) of the medium that grants access to the eTP (i.e., customer-owned, employee-used, or retailer-owned). Finally, the eTPs were assigned to a stage of the customer journey (Hoyer et al. 2012; Lemon and Verhoef 2016; J. Lu 2017; Neslin et al. 2006).\n",
      "\n",
      "Three researchers independently coded the eTPs—6 categories with 18 features were coded for each of the 26 eTPs, yielding 468 items for each coder. By means of Holsti’s coefficient of reliability (Holsti 1969), an inter-coder reliability of rH = .86 was reached, which shows a strong agreement that is within the accepted range of .8–1.0 for nominal-scaled judgment-based data (Perreault and Leigh 1989). All deviations were discussed until a consensus was reached.\n",
      "\n",
      "The characteristics of all eTPs that are affected by a specific factor were then jointly considered to support the interpretation process. Groups of characteristics with strong or weak overlaps served as the basis for naming the factors. The results of this process are discussed below.\n",
      "\n",
      "F1: External Influential Messages as Content: F1 causes the likeliness that customers will use mostly promotion or support TPs independent of the customer journey stage, focusing on social aspects, recreational activities, and interactions. The Location-Based Newsletter received the highest factor score among the touchpoints affected by F1.\n",
      "\n",
      "F2: Terminal as Medium: F2 causes the likeliness that customers use functional eTPs mediated by a terminal that provides access to additional product or location information. The CFA suggested that some of the terminal TPs were also affected by the factors that cause the likeliness that customers will use the respective smartphone app variants.\n",
      "\n",
      "F3: Supported Product Search as Functionality: F3 causes the likeliness that customers will use functional eTPs that provide additional information for their search process during the customer journey. Within this group of eTPs, the In-Store Navigation (S), which is associated with customers’ search processes, received the highest factor score.\n",
      "\n",
      "F4: Answer Inquiries as Functionality: F4 affects the likeliness that customers will use informational eTPs, which mainly answer inquiries about the selection of alternatives and are shopping aids that allow customers to find the right products and get answers to questions quickly.\n",
      "\n",
      "F5: Historical Customer Data as Content: F5 describes two functional support TPs that provide access to historical customer data. While the Order History TP informs both the alternative evaluation and the post-purchase stage of the customer journey, the Recently Viewed Products TP allows customers to keep track of products they have already considered during their evaluation of alternatives.\n",
      "\n",
      "F6: Supported Checkout Procedure as TP Functionality: F5 causes the likeliness that customers will use revenue TPs that support the purchase stage of the customer journey. They provide alternative means for the checkout process and are meant to improve shopping efficiency.\n",
      "\n",
      "F7: Supported Product Collection as TP Functionality: Finally, F7 causes the likeliness that customers will use functional eTPs that keep track of the planned and actual shopping basket.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Discussion \n",
      "\n",
      "The results provide first exploratory insights into customers’ behavioral intentions toward eTPs in BaM stores. These insights have several implications for research and practice. Overall, the survey participants were likely to use the BaM eTPs. They preferred TPs that aid in searching for products, finding information, selecting products, or facilitating a more efficient customer journey. In contrast, there was considerably less interest in communication and support eTPs. The regression showed that prior BaM retail-store-related smartphone use was a significant predictor of the likeliness that the surveyed shoppers would use many of the eTPs. Not significantly affected were most of the terminal TPs, the Order History, and the Write Product Review TPs. However, the latter two TPs were weakly but significantly positively affected by the frequency of online shopping, which also had a weak positive impact on the Product Exploration (S), App-Equipped Clerk, Read Product Review (S&T), Recently Viewed Products, Mobile Self-Checkout, Sales-Floor Checkout, Social Media, and the Location-Based Newsletter TPs. Males were less likely to use the Read Product Review (S&T) and Messaging TPs than women were. Finally, the Sales-Floor Checkout, Shopping List, and Location-Based Newsletter TPs were negatively affected by the participants’ education levelFootnote 8 (see Table D.1 in Appendix D.2). The moderate correlations between some touchpoints (see Fig. D.1 in Appendix D.1) indicate a potential for bundling service offerings, albeit, without an immediate need for BaM retailers to act. The factor analysis uncovered seven factors that affect the likeliness that customers would use the proposed eTPs. The TPs that are described by a factor correlate (see Fig. E.1 in Appendix E.3), indicating that customers could perceive the corresponding TPs as being similar. The results support research that found that customers perceive groups of eTPs as similar (Lazaris et al. 2015a, 2015b), and that found stronger spillover effects for similar TPs (de Kerviler et al. 2016). Thus, this article provides preliminary evidence that the likeliness that customers will use eTPs in BaM stores is affected by the TPs’ characteristics and, so it indicates that it could be reasonable to treat eTPs that form such groups similarly. The identified factors are discussed in the following.\n",
      "\n",
      "Since its inception, e-commerce has been primarily functional in nature (Noble et al. 2005), making its utilitarian benefits for information search vital to customers (Blázquez 2014), particularly, because the usefulness of a channel for facilitating product information search affects the frequency of product searches and purchases through that channel (Jihyun Kim and Lee 2008). By complementing physical stores with eTPs, the e-commerce experience can be replicated in BaM retail (Mirsch et al. 2016; Roy et al. 2017; Roy et al. 2018). Technology supports the in-store shopping process and improves the customer experience (Renko and Druzijanic 2014; Tyrväinen and Karjaluoto 2019; Verhoef et al. 2015). As the factor analysis indicates, the highest-rated eTPs aid customers in their search, collection, and selection of products (F3, F7, and F4) and or more efficient checkout procedures (F6). The eTPs that are affected by these factors can be considered research-supporting and solution-oriented shopping aids (Chang and Kukar-Kinney 2011) that increase customers’ shopping effectiveness (i.e., finding the right products) and efficiency (i.e., fast service) (Blázquez 2014; Meuter et al. 2003).\n",
      "\n",
      "The informational and functional eTPs that are affected by the factors F3 and F7 support customers in product search and retrieval. According to prior research, behavioral intentions toward mobile information search in BaM retail stores are typically affected by customers’ perceptions of its benefits (de Kerviler et al. 2016). In addition, prior research suggests that the utilitarian benefits of digital TPs are more important than their hedonic benefits (Vannucci and Pantano 2019). Functional in-store technologies are shown to cause fewer privacy concerns than others and may even reduce them in mobile apps, including promotional TPs (Inman and Nikolova 2017). However, the technology and its mediated information must be trustworthy, and customers’ privacy concerns could still limit their acceptance (Resatsch et al. 2008).\n",
      "\n",
      "F4 affects three eTPs that allow customers to gather information for their evaluation of alternatives or purchase decisions. Thus, the likeliness that customers will use these eTPs could be affected by their ability to find the right products and get answers to questions quickly. The information provided by these eTPs is product-related, customer-generated, and brand-generated. The survey results support extant studies’ suggestion(e.g., Tyrväinen and Karjaluoto 2019) to implement eTPs that allow customers to compare products. Also, the positive attitude of the surveyed shoppers toward the Read Product Review (S) TP is unsurprising since prior research argues for the importance of direct customer-to-customer (C2C) interaction in BaM retail stores (Harris et al. 1997). C2C interaction also has a stronger impact on satisfaction than customer-to-employee interaction does (Harris et al. 1997), which, in turn, can impact customers’ attitudes about a store (Lee and Lim 2017). However, the impact of digital C2C interactions like product reviews on purchase behavior in e-commerce differs based on the customer’s age (von Helversen et al. 2018). As channel characteristics can moderate such effects, the impact of novel digitally enabled C2C interactions in the smart BaM servicescape requires further investigation (Libai et al. 2010). In addition, the surveyed shoppers were less likely to use the FAQ (S) TP than they were to use the other two eTPs. Similarly, Kim and Stoel (2005) show that, compared to other TPs in e-commerce, customer attitudes toward FAQ TPs were, on average, the lowest. Still, Kim and Stoel (2005) find that such TPs affect purchase intentions. Therefore, further research should investigate such BaM TPs in more detail.\n",
      "\n",
      "Finally, F6 affected two TPs that are concerned with alternative checkout services. Overall, prior research finds varying impacts of perceived usefulness, the relative advantage in terms of time-savings and reduced customer confusion, ease of use, risks, perceived security, and compatibility on the customers’ intention to use mobile self-checkout or payment eTPs (Aloysius et al. 2018; de Kerviler et al. 2016; Johnson et al. 2019; C. Kim et al. 2010; Schierz et al. 2010). In the survey, Mobile Self-Checkout was the most prominent eTP. The participants’ online shopping frequency had a weak but significant positive impact on the likeliness that they would use this eTP (see Table D.1 in Appendix D.2). Usually, customers attach importance to and have a positive attitude about self-checkout TPs (Inman and Nikolova 2017; Lazaris et al. 2015a, 2015b), as they provide several benefits (Renko and Druzijanic 2014), including improved efficiency because they are faster than their employee-operated counterparts (Vannucci and Pantano 2019; Vuckovac et al. 2017). By reducing the time and effort required in shopping in BaM stores, retailers can drive store patronage intentions (Baker et al. 2002). Time convenience was also shown to have positive impacts on customers’ perceptions of the value of the mobile channel, which encourages customers to use the channel (Kleijnen et al. 2007). In contrast, the Sales-Floor Checkout received lower ratings by the shoppers surveyed on average. Further research should investigate whether dependence on employees reduces customers’ perceptions of an eTP’s potential to save time. The participants’ prior BaM-retail-related smartphone use had a significant positive impact on the likeliness that they would use this eTP (see Table D.1 in Appendix D.2). In addition, its similarity to the existing self-checkouts offered by some retailers may have positively affected the participants’ perceptions of the Mobile Self-Checkout TP, so an exposure or a spillover effect could have occurred (de Kerviler et al. 2016; Zajonc 1968), which could be subject to further research.\n",
      "\n",
      "In sum, based on the findings from the survey and prior research, BaM retailers should design and introduce easy-to-use eTPs that, depending on the industry, provide utilitarian and/or hedonic benefits with low privacy concerns for the pre-purchase stage (e.g., for additional store-generated, product-related, or customer-generated information) and the purchase stage (e.g., more efficient checkout services). However, considering prior research, in addition to customer benefits and acceptance, the retailers’ benefits and outcomes should also be considered (Inman and Nikolova 2017; Renko and Druzijanic 2014). In e-commerce, for example, search support, FAQs, and product-comparison services can affect customers’ purchase intentions (M. Kim and Stoel 2005). Therefore, further research could consider the effect of eTPs on customers’ purchase intention in BaM retail stores in more detail. For instance, digital shopping lists can contain fewer items but result in more hedonic and unplanned purchases (Huang and Yang 2018), and customers spend more money in BaM stores when they use the internet to search for information (Sands et al. 2010) and are more likely to buy fresh products if they are provided with (real-time) information via eTPs (Fagerstrøm et al. 2017), making such eTPs potential revenue drivers.\n",
      "\n",
      "Content-related factors are concerned with influential external input from the retailer or from other customers (F1) and access to historical customer data (F5). F1 loads onto several promotional and support TPs that have a diversional or interactional nature. Some of the TPs that are affected by F1 are among those that are least desirable.\n",
      "\n",
      "F1 affects three promotional eTPs—the Product Recommendation and the two Newsletter TPs—meant to stimulate customers to recognize needs based on previous purchases. According to prior research, customers’ brand trust, shopping styles, and perceived value affect their intention to participate in mobile marketing (Persaud and Azhar 2012). Research highlights customers’ negative sentiment toward intrusive communication and personalization in BaM stores (Burke 2002) and even suggests lower use intentions and stronger privacy concerns for personalized e-services in BaM retail stores than in e-commerce (Wetzlinger et al. 2017). It may be for these reasons that, similar to other studies (Lazaris et al. 2015a, 2015b), participants gave the Product Recommendation TPs mediocre ratings. In contrast, other studies argue that customers prefer stores that offer Product Recommendation TPs and show that customers’ behavioral intentions toward such eTPs are driven by their perceived usefulness (Kowatsch and Maass 2010). Relative advantages and personalization are also shown to have a positive mediated impact (i.e., via satisfaction and perceived risk) on customers’ behavioral intentions toward retail technologies (Roy et al. 2017). Vannucci and Pantano (2019) find that customers have more trust in the suggestions made by digital TPs than they have in those made by human TPs. However, past e-commerce research suggests that personalization has no effect on purchase intentions (M. Kim and Stoel 2005). Future research could consider in more detail the factors affecting customers’ behavioral intentions toward BaM Product Recommendation TPs and their impact on customers’ purchase intentions.\n",
      "\n",
      "The Location-Based Newsletter received the second-lowest average rating among the eTPs in the survey. Research on location-based retail services and apps finds varying impacts of perceived usefulness, cognitive/affective involvement, ease of use, flow (i.e., enjoyment, control, and concentration), trust, and privacy concerns on customers (Kang et al. 2015; Uitz and Koitz 2013; Zhou 2016). For example, the positive impact of affective involvement on the intention to use is greater for experientially oriented customers (Kang et al. 2015). Companies can also affect flow, trust, and privacy concerns, all of which can affect customers’ continuance intention through the quality of the system, service, and information (Zhou 2016). This article’s survey results show that privacy concerns may be reflected by the average higher rating of the Location-Based Newsletter TP’s periodic counterpart. Prior research finds that different means of delivery, interface mobility, and customers’ privacy needs affect revenues from location-based marketing differently (Banerjee et al. 2020). Therefore, research and practice should consider different design options, when designing location-based eTPs.\n",
      "\n",
      "F1 also affects three supportive TPs that are of a diversional and interactional nature (cf. Straker et al. 2015). Aside from its potential to reduce the frustration of finding store employees, the likeliness that the surveyed shoppers would use the Messaging TP, which is not bound to a specific stage of the customer journey, was lower on average than twenty of the other eTPs. In an e-commerce context, prior research shows that service quality and customer satisfaction have indirect impacts (i.e., via perceived usefulness and ease of use) on customers’ acceptance of support chats (Elmorshidy 2013). However, customers usually attach more importance to personal contact in BaM retail stores (Schramm-Klein et al. 2007) and prefer C2C interactions over customer-to-employee interactions (Harris et al. 1997). These preferences might explain the lower rating of the eTP in this regard, as an eTP might be seen as impersonal and lacking direct human interaction. Further research could investigate the impact of these preferences in more detail.\n",
      "\n",
      "The Write Product Review TP is the fourth least likely to be used, and the Social Media TP the least likely. However, prior research shows that social media can affect purchase decisions in BaM retail stores. The trust and loyalty of several customer segments are affected by user-generated content differently (Beurer-Züllig and Klaas 2020), so such TPs should not be overlooked. For example, in fashion retail, in addition to perceived usefulness, perceived enjoyment is an essential determinant of customers’ behavioral intentions toward various eTPs, including social media (H.-Y. Kim et al. 2017). Similarly, Weinhard et al. (2017) find that customers’ hedonic motivations have a strong impact on behavioral intentions and that the customers’ willingness to provide personal information is almost as important.\n",
      "\n",
      "In sum, F1 affects stage independent, post-purchase, and pre-purchase TPs that allow customers to create user-generated and consume brand-generated content. F1 could indicate that BaM shoppers are still critical of personalized and intrusive communication (cf. Burke 2002) in a hybrid BaM servicescape and, so they perceive eTPs that enable them to influence other customers as being similar to those that try to influence them through brand-generated content. F1 could also indicate that customers perceive eTPs, which complement the activities along the traditional BaM customer journey, as less useful than those supporting existing activities.\n",
      "\n",
      "The second content-related factor (F5) affects the likeliness that customers will use two functional eTPs that give them access to historical customer data, thus supporting the alternative evaluation and post-purchase stages. Both eTPs received moderate ratings from the surveyed shoppers. The frequency of online shopping had a weak positive impact on the Order History and the Recently Viewed Products TPs, and the latter was also significantly affected by prior BaM-retail-related smartphone use (see Table D.1 in Appendix D.2). Either the shoppers perceived these TPs as less intrusive (cf. Burke 2002) than those affected by F1, or they perceived more advantage from and control over them (cf. Roy et al. 2017). Further research could investigate customers’ perceptions of the collection, presentation, and analysis of customer data in the context of various BaM eTPs in more detail.\n",
      "\n",
      "Considering the survey results and the findings of prior research, BaM retailers should implement non-intrusive promotional and interactional TPs that customers perceive as useful and enjoyable, and that consider their privacy needs. When eTPs use historical data, BaM retailers should consider customers’ perceptions of the eTPs’ usefulness and customers’ control over them.\n",
      "\n",
      "Finally, one factor (F2) is concerned with the terminal as an access medium. On average, the terminal-based eTPs received a lower rating by the surveyed shoppers than their smartphone-based counterparts. Thus, the survey results suggest that customers might prefer using their smartphones to access eTPs in BaM stores. Prior research suggests that mobile shopping technologies facilitate customer-retailer interconnectedness, consumer empowerment, and proximity- as well as web-based consumer engagement (Faulds et al. 2018). However, older customers may still be more likely to favor a terminal or human-mediated eTPs (see Table D.1 in Appendix D.2), as they may be less confident using modern and sophisticated self-service technologies (Dean 2008; Y.-S. Wang and Shih 2009) and may miss human interaction when they evaluate self-service technologies (Dean 2008). Additional research could investigate older customers’ expectations about the media used to convey eTPs.\n",
      "\n",
      "In addition to customers’ age, prior research discusses several reasons for customers’ preference for one medium over another. Similar to the impact of media richness on the fit with a task and the overall choice of a channel (Maity and Dass 2014), media richness, which varies across devices (Rieger and Majchrzak 2018), may affect customers’ perceptions and acceptance of eTP interfaces. The interfaces used to access electronic channels via devices also affect customers’ evaluations of these channels (Wagner 2015). Furthermore, prior research shows that the task-technology-fit affects customers’ utilitarian motivations to use e-commerce (Klopping and McKinney 2004) and their perception of the usefulness, ease of use, and convenience of online channel interfaces (Wagner 2015). Moreover, the type of device in e-commerce affects customer engagement, increases the impact of their perceptions of the risk associated with their purchase decisions (Cozzarin and Dimitrov 2016), and moderates the relationships between their perceptions of the e-business technology’s usefulness and their attitudes toward it (Sumak et al. 2017). According to Natarajan et al. (2018), the type of device moderates the impact of perceived usefulness and enjoyment on the intention to use mobile shopping apps. Similarly, Aloysius et al. (2018) show that the relationship between ease of use of and the intention to use a mobile self-checkout is significant only in a mobile scanning and stationary payment scenario. This finding indicates that the mobility of the medium used to access an eTP in BaM stores could moderate this relationship under certain circumstances. Finally, besides in-store terminals, smartphones, and other digital interfaces (Betzing et al. 2018; Willems et al. 2017), humans can act as mediators of BaM eTPs, as illustrated by the App-Equipped Clerk and the Sales-Floor Checkout TPs. Especially as the orientation of customers toward personal communication and contact is stronger in BaM stores than it is in e-commerce stores (Schramm-Klein et al. 2007), human interfaces for e-service provision should not be neglected. However, Vannucci and Pantano (2019) suggest that customers have more trust in digital TPs than they do in human TPs. While self-service interfaces might reduce the frequency of interpersonal interactions, they provide alternatives to the human service interface and increase the quality of customer-to-employee interactions (Pantano and Migliarese 2014). Therefore, future research could investigate which media is most suitable for accessing specific groups of eTPs in BaM retail stores. BaM retailers, too, should consider the type of media and interfaces when they design eTPs and identify the most suitable options for their customers in their given context.\n",
      "\n",
      "While prior research finds that the evaluation of service offerings is significantly more important for customers in e-commerce settings, it also suggests that there are no differences in the service orientations of BaM and e-commerce customers (Schramm-Klein et al. 2007). Furthermore, in a smart servicescape (Sanjit K. Roy et al. 2019), experience with technology has a mediating impact on customers’ behavioral intentions toward such technologies and their loyalty toward the retailer (Roy et al. 2017). The variables that are known from channel choice and technology acceptance studies in an e-commerce context are also shown to affect the purchase intention in omni-channel environments (Juaneda-Ayensa et al. 2016; Kazancoglu and Aydin 2018; Susanto et al. 2018). Therefore, considering customers’ perceptions of individual eTPs in BaM retail and the determinants of customers’ behavioral intentions toward eTPs along the BaM customer journey has value. Future research could assess the potential of adapting existing theoretical models (e.g., Taherdoost 2018) and research to eTPs in BaM retail stores.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Conclusion \n",
      "\n",
      "An understanding of customers’ behavioral intentions toward eTPs in BaM retail stores is useful for researchers and practitioners alike, given the increasing number of potential TPs (Lewis et al. 2014; von Briel 2018), more complex omni-channel customer journeys (Barwitz and Maas 2018), and the risks and costs that are associated with the implementation of digital channels and technologies (Karjaluoto and Huhtamäki 2010; Pantano 2014). As empirical research is required to inform theory and promote retailers’ adoption and customers’ intentions toward these TPs, this article makes two contributions:\n",
      "\n",
      "First, the study uses a survey to provide an overview of the likeliness that customers would use BaM TPs that are adopted from e-commerce and conceptually adapted for the use in BaM retail stores. Second, based on an EFA, first exploitative insights on the factors that cause customers’ behavioral intentions toward BaM eTPs are discussed as a foundation for future research. From a managerial perspective, the results inform BaM retailers about issues that should be considered when they implement eTPs. From a theoretical perspective, this article contributes insights about customers’ behavioral intentions toward eTPs in BaM retail stores and suggests taking a closer look at TPs to clarify customers’ acceptance of interfaces and, ultimately, their choice of channel. As the results suggest that customers perceive groups of eTPs as similar in BaM retail stores, this article also guides future research in investigating the eTPs that form such groups simultaneously or treat them in a similar manner.\n",
      "\n",
      "This article’s exploratory multi-method approach comes with caveats and limitations that leave room for further research. First, this study is agnostic to contextual factors of the physical servicescape like the size of the store, the retailer’s assortment, and its location. The survey captured the likeliness that the participants would use dominant eTPs in an online survey based on simple textual descriptions (cf. Aloysius et al. 2018; Inman and Nikolova 2017; Kleijnen et al. 2007) concerned with an abstract BaM store instead of in a prototype-based lab experiment. Thus, the results derived from the generic yet artificial setting of this study should not be transferred to a real-world situation without critical reflection. The eTPs’ relevance to customers might differ based on omitted contextual factors like goods sold or certain store properties. For example, hedonic eTPs might be especially useful in fashion retail (H.-Y. Kim et al. 2017), whereas the usefulness of product information TPs might be related to the complexity of the product sold (Resatsch et al. 2008). Therefore, future research should consider BaM eTPs against the backdrop of different product categories, store sizes, and competitive strategies (e.g., service quality leadership vs. cost optimization) (Porter 1998). While such contextual factors reveal paths for future research, the generic setting of this manuscript’s exploratory multi-method approach, which is independent of such determinants, can be regarded as an unbiased greenfield approach to identifying and investigating potentially useful eTPs.\n",
      "\n",
      "Second, while the textual eTP descriptions allowed customers’ general intentions toward a variety of BaM eTPs to be investigated, the impact of detailed eTPs design characteristics was not taken into account. Future research could evaluate variants of eTP implementations in lab experiments or BaM stores and assess the effect of such design characteristics. By working with real instantiations of eTPs, such studies could integrate the likeliness of customers’ using individual TPs into existing survey instruments. Such studies should also pay attention to the interdependencies among the TPs available in the given scenario by conducting, for example, a conjoint analysis.\n",
      "\n",
      "Third, no a priori assumptions on the TPs’ characteristics were made—instead, a variety of possible eTPs were included—so the identified factors should not be considered collectively exhaustive but as first insights into the determinants of customers’ behavioral intention toward eTPs in a hybrid servicescape that mirrors e-commerce experiences in BaM retail stores. Future work on both TP characteristics in general and their impact on behavioral intentions in BaM retail stores in particular is needed.\n",
      "\n",
      "Fourth, this study took a static view (Kranzbühler et al. 2017) on firm-controlled (Becker and Jaakkola 2020) eTPs in BaM stores. Future research could consider a dynamic, relationship-oriented view (Kranzbühler et al. 2017) to investigate the spillover effects (de Kerviler et al. 2016) between eTPs within and across different customer journeys. Future research could also look into selection and design criteria for BaM eTPs from an organizational perspective (Inman and Nikolova 2017; Kranzbühler et al. 2017) or consider non-controllable eTPs that reside outside company borders (Becker and Jaakkola 2020). In addition, instead of BaM smartphone use and online shopping frequency, future research could investigate the impact of prior experiences with specific eTPs on behavioral intentions in and across various channels.\n",
      "\n",
      "Finally, future research could investigate whether a set of typical BaM eTPs could eventually prevail by using the multiple case study method (Recker 2013) to identify a generalizable dominant design (Suárez and Utterback 1995) of BaM eTPs.\n",
      "\n",
      "In sum, this manuscript lays the foundation for a better understanding of customers’ interaction choices (Barwitz and Maas 2018) in the smart BaM servicescape (Sanjit K. Roy et al. 2019) and offers ample opportunities for further research.\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = get_full_text(journal_soup, journal_full_link)\n",
    "\n",
    "for chapter in text:\n",
    "    chapter_name = chapter['chapter_name']\n",
    "    chapter_text = chapter['chapter_text']\n",
    "    print(f'Kapitel: {chapter_name} \\n')\n",
    "    print(chapter_text)\n",
    "    print('\\n \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kapitel:  Abstract \n",
      "\n",
      "The identification of coordinated campaigns within Social Media is a complex task that is often hindered by missing labels and large amounts of data that have to be processed. We propose a new two-phase framework that uses unsupervised stream clustering for detecting suspicious trends over time in a first step. Afterwards, traditional offline analyses are applied to distinguish between normal trend evolution and malicious manipulation attempts. We demonstrate the applicability of our framework in the context of the final days of the Brexit in 2019/2020.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 1 Introduction \n",
      "\n",
      "Social media has become an important infrastructure for modern information sharing and networking. In most developed countries, the majority of people are already connected via one or multiple platforms [6]. Even more important, decision makers like politicians or multiplicators like journalists are also an integral part of social media networks. These groups function as bridge between the social media ecosystem and the offline world outside social media. While politicians try to get in touch with the sentiment of public debates about their programs or decisions, journalists try to pick up stories and use the public sphere as additional outlet.\n",
      "\n",
      "Quite logically, social media has become a central platform for campaigns. Politicians try to reach the public with their ideas, but in contrast to former media types, users can also reach politicians directly. Both can also try to initiate societal debates by placing topics. And when journalists pick up these topics because they seem of critical importance in social media, their reach goes even beyond the boundaries of the social media ecosystem.\n",
      "\n",
      "As such it is of utmost importance not only for journalists but for the whole society to provide some transparency on campaigns in social media. This shall provide insights into the origins of and motivations behind an observed topic: is a campaign organic or orchestrated (automatic as well as human-driven), i.e., who is participating in these campaigns? What means are employed when placing a topic?\n",
      "\n",
      "These questions go beyond the challenge of classifying single accounts as social bots or humans. We have to consider interaction of actors and thus the complete (or a representative sample of the) data stream, which is produced on a social media platform. These analyses do no longer focus on singular accounts or a group of users but on the content produced over time. Clearly, the corpus of data that needs to be analyzed is far too large for human manual inspection. But also classical methods of data analysis are not capable to store all data and process it in real time. Real-time detection of possible campaigns, however, is necessary to not lag behind with analysis, when topics reach critical popularity. At the same time, we still need to verify whether campaigns are organic or artificial. This decision can usually not be made ad-hoc and often needs a deeper, sometimes even forensic analysis of campaign data.\n",
      "\n",
      "In order to address both challenges at the same time, we propose a two-phase framework which supports both campaign and trend detection and a-posteriori in-depth analysis of respective data. Our idea integrates a stream-based unsupervised detection of critical topics and an independent, offline, and extendable analytics environment. This allows to instantly identify upcoming and important topics and subsequently analyze and verify their artificial character. Note that this approach should be considered as a human-in-the-loop support tool, where no automatic decision on a campaign’s quality is made. In principle, it is designed to enable detection and transparent analysis of current topics in many contexts, either the discovery of new and interesting topics or the fight against manipulation via artificial campaigns.\n",
      "\n",
      "The rest of this work is structured as follows: the next section will summarize related research in the context of this work and then Sect. 3 will detail the two-step framework’s concept proposed in this paper. Section 4 shows the application of our framework in the context of the Brexit discussion two months before and at the final Brexit date at the end of January 2020. Finally, Sect. 5 summarizes and discusses the results of our work and provides some future perspectives.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 2 Related Work \n",
      "\n",
      "Social media has been discussed as environment for disinformation, manipulation, or deception for more than a decade [8] and since the Brexit decision in 2016 as well as the election of Donald Trump for president of the United States, social media is considered an important infrastructure for manipulating societies [3, 22]. Much effort has been put into the (computer-aided) detection of automation in social media. Social Bots are considered very potent actors in the distribution of disinformation [10, 11, 14, 18], and consequently, detection techniques for social bots have been (and still are) an important topic of research [9, 10, 13, 20]. While research started with a focus on the classification of single accounts as bots- or human-driven, some recent publications emphasize the importance of detecting collaboration of multiple actors [9, 12]. An exceptionally early proposal was made by Lee [16] already in 2014 to discriminate campaigns into organic and non-organic ones. While the first arises from classic human interaction in social media the latter type of campaigns is promoted by artificial or automated mechanisms or purchased and supported by the social platform [16].\n",
      "\n",
      "Campaign detection started with offline analysis of network data and topologies, the clustering of posted or shared content, and the investigation of topics’ temporal development. All applied techniques and extracted features mainly aimed for supporting or enabling machine learning approaches. More recent detection approaches afterwards focused on the application of machine learning in campaign detection in order to identify characteristic patterns of organic and non-organic campaigns [10, 20].\n",
      "\n",
      "However, there are some major disadvantages of (supervised) machine learning approaches in this context: \n",
      "\n",
      "Models have to be trained using labelled data. Especially for campaigns in social media, this kind of data is usually not sufficiently available. An insufficient data base, however, makes the approaches imprecise.\n",
      "\n",
      "The learned patterns can only capture the characteristics found in available input and learning data. That is, the machine learning approaches may become outdated and inflexible regarding new kinds of orchestrated campaigns.\n",
      "\n",
      "There is some recent work [7, 9, 23] which addresses the application of unsupervised detection methods like clustering and network analysis as solutions to some of the issues. These approaches do not need initial training and can detect unknown characteristics. However, as correctly pointed out in [23], these methods are computationally too complex to handle the observed amount of social media content in real-time.\n",
      "\n",
      "In this work, we pick up a proposal we recently made, i.e. using stream-clustering approaches for topic detection [2] and apply it as a first step in a two-phase analysis process. We propose the augmentation of the detection of campaign candidates with a subsequent analysis phase. In this second phase, previous mentioned established group- or single account analysis can be applied to verify or reject whether a campaign is malicious or not and to possibly detect responsible actors in this campaign. As such, we consider this work as a step towards an integration of modern classification approaches into campaign detection for fast and precise transparency in social media communication.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 3 The Two-Phase Framework for Detection and Analysis \n",
      "\n",
      "In the following, we introduce our two-phase framework for automated campaign detection. The framework is depicted in Fig. 1. Within the first phase, the incoming text data stream (e.g. Twitter stream) is processed into tfidf vectors and aggregated via the textClust algorithm [5]. The algorithm handles text stream data and clusters similar documents together into so-called micro-clusters, which represent the recently discussed topics of the stream. Additionally, a micro-cluster filtering is applied. By this, topics, which behave suspiciously in terms of their development over time, are extracted. In the second phase, these topics can be further analyzed, via numerous metrics and visual representations of text (meta-) data.\n",
      "\n",
      "2-phase framework for analyzing suspicious cluster evolution\n",
      "\n",
      "Stream clustering algorithms apply clustering on potentially unbounded data streams in an online fashion. The fact that the stream is potentially unbounded makes it impossible to store the complete data for calculations [4, 19]. Due to this, observations can be processed only once. As the complete range of the data is not known in advance, the stream clustering algorithm needs to be able to adjust clusters online and in real-time.\n",
      "\n",
      "The stream clustering algorithm can be divided into two phases: In the online phase, micro-clusters are derived directly from the incoming observations. A micro-cluster is an aggregation of observations, which are locally dense. While the concrete observations are discarded after the distance calculations, the clusters are stored as representation of the actual data distribution. In the offline-phase, the respective micro-clusters can be clustered on-demand via traditional clustering techniques. This phase is independent from the online phase and can be scheduled on demand at any point in time. As here only the limited number of micro-clusters, as a representation of the original data is used, the calculations can be done by using the data multiple times.\n",
      "\n",
      "In contrast to incremental clustering algorithms, stream clustering algorithms must be able to deal with the explicit notion of time. The complete range of data is not known at the beginning and the distribution of the stream data may change over time (which is known as concept drift). Therefore, micro-clusters need mechanisms to adapt to changes in the data stream. To simulate a temporal drift, micro-clusters are usually weighted. The weight ensures that clusters, which are not updated by new observations for a while, will be decayed slowly. If the weight falls below a threshold, the cluster is removed completely.\n",
      "\n",
      "textClust: The idea of micro-clusters as representation of stream data was originally designed for numeric data. Nevertheless, the idea can be transformed to textual data as well [1].\n",
      "\n",
      "For our experiments, we use the textClust algorithm [5]. Within the textClust algorithm, the produced micro-clusters mc are represented as 4-tuples:\n",
      "\n",
      "The relative importance of a micro-cluster is reflected by its tokens t (namely most describing words) and its weight w. The weight is increased by 1 each time a new observation is allocated to the cluster. To be able to detect concept-drifts and account for temporal changes, the weight is exponentially decayed at each time step by\n",
      "\n",
      "where \\(\\lambda \\) denotes the fading factor, \\(t_{now}\\) the current time and t the time the specific micro-cluster was last updated. A cleanup procedure is applied every \\(t_{gap}\\) time steps where all micro-clusters below a predefined threshold are removed from the clustering result. The same applies for all tokens within a respective micro-cluster.\n",
      "\n",
      "The term frequency of representative cluster words as n-grams is denoted in the tf vector. Distance calculations between two micro-clusters using the cosine similarity are based on the tfidf vectors. Note, that the tfidf representation extends the traditional term frequency by weighting down words that appear in many documents, as they are considered to be less important. For every new observation, first a new micro-cluster is created and second, the distance to all other micro-clusters is calculated. If the new micro-cluster is in small distance (below a certain threshold r) to one of the existing micro-clusters, it is merged with the respective cluster. Otherwise, the new micro-cluster remains and is added to the set of all micro-clusters.\n",
      "\n",
      "The similarity of two tfidf vectors is calculated via the adjusted cosine-similarity. Within this metric, the average weight of the micro-cluster is taken into account. Therefore, each token (within a certain cluster) is weighted relative to the average weight. Let A and B represent two tfidf vectors from two different micro-clusters. The adjusted cosine similarity between them with their respective means \\(\\mu _A\\) and \\(\\mu _B\\) is then defined as follows:\n",
      "\n",
      "The fourth element within the micro-cluster definition ID captures the post IDs, which relate to the corresponding texts within a cluster. The post ID vector is irrelevant within the clustering phase, but gets important in the second phase of the framework, when suspicious stream data is analyzed in more detail.\n",
      "\n",
      "Micro-cluster Monitoring to Detect Campaigns: A micro-cluster represents a topic discussed in the text stream. Each cluster consists of tokens, which describe the content, as well as a weight, which represents the importance (number of associated text instances) of the cluster.\n",
      "\n",
      "Next to the overall topic monitoring of the incoming stream data, we are especially interested in suspicious stream behavior. The identification of rapidly arising and growing clusters might be of interest in the field of trend or campaign detection. Especially, since we are interested in non-organic campaigns, driven by bots or trolls, the temporal evolution of the campaign can be used as an indication for unusual behavior [21]. Since it is not feasible to manually inspect the complete number of micro-clusters over time, an automated filtering step has to be applied. In an earlier work, we already proposed a method that reduces the number of micro-clusters by focusing on micro-clusters that do exhibit a significant change of weights within the last cleanup procedure [2].\n",
      "\n",
      "In addition to storing only the actual weight w of the cluster, the weight before the last update \\(w_{last}\\) is included for calculating the difference \\(\\varDelta _w = w - w_{last}\\) within tgap cluster updates. Based on this, the average weight change \\(\\mu _w = \\frac{\\sum _i{\\varDelta _{w_{i}}}}{k}\\) of all micro-clusters k, as well as the respective standard deviation \\(\\sigma _w = \\sqrt{\\frac{1}{k-1}\\sum _{i=1}^{k} (\\varDelta _{w_i} -\\mu )^2}\\), can be computed. The Chebyshev’s inequality is used to determine clusters with unusual weight patterns [17]. The inequality states that:\n",
      "\n",
      "where X is a random variable with expected value \\(\\mu \\), standard deviation \\(\\sigma \\) and t any positive number. To ensure a feasible amount of clusters to (manually) analyze in a second step, we chose \\(6 \\sigma \\) \\((t=6)\\) as threshold. The parameter setting can be adjusted depending on the context, as well as the underlying data. With this parameter setting about 3% of the micro-clusters are selected for further analysis, which is (in this case) a suitable amount for further investigations. The set of clusters of further interest I is thereby defined as:\n",
      "\n",
      "Within the first phase of the framework, textual stream content is clustered and suspicious cluster evolution is filtered online and in real-time. In a second offline phase, suspicious clusters can be further examined. Here, all kinds of (computationally) expensive analyses can be applied. On the one hand, the micro-cluster content can be examined by the help of the stored cluster tokens. On the other hand, the user is able to gather meta-data via the ID vector of the suspicious micro-cluster. As the ID vector captures all post IDs of the respective cluster, the Twitter REST API can be used to extract post meta data, e.g. the author ID or name. Further, meta data about the author can be gathered simultaneously. With the meta data the user is able to enrich the underlying data enormously. Especially for the detection of non-organic campaigns, further information about the human user is indispensable.\n",
      "\n",
      "Authors of a micro-cluster can be analyzed regarding the age of their accounts, their post behavior, as well as their number of followers and followees. In the second phase of the micro-cluster analysis, visual representations can help to identify non-normal behavior. A dashboard can extremely help to visualize underlying structures in data and meta data of the post and accounts. Exploring e.g. the number of distinct accounts responsible for a micro-cluster, or checking the average age of the accounts, could help to identify social bots.\n",
      "\n",
      "Furthermore, established bot detection methods can be applied. A well-known example for a bot detection method, which could be easily applied when the author ID is known, is the Botometer approach [20]. This tool gives an indication, whether an account is presumable steered by a human or a bot, by taking several meta data into account. Applying algorithms like the Botometer in the second phase of the framework can help to give an impression of the origin of the campaign and may help to detect non-organic campaigns.\n",
      "\n",
      "Dashboard prototype to evaluate micro-cluster trends in the second phase\n",
      "\n",
      "In this work a first prototype of our dashboard is used for evaluation purposesFootnote 1 (see Fig. 2). We only rely on simple offline metrics which can be directly extracted from the tweets gathered during our experiments. Within the dashboard a variety of data and meta data can be visualized. For a first setting, we implemented figures and metrics representing the number of distinct accounts, the age of the accounts, such as the number of followers, and the percentage of verified accounts contributing within the specific topic. Further, we show how many an which posts are contained in this cluster at which point in time. This list is not exhaustive and can be complemented and customized. Up to now, we do not utilize additional supervised methods such as Botometer and leave this open for future research.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 4 Case Study and Evaluation \n",
      "\n",
      "In this work we exemplary demonstrate our framework in the context of the Brexit movement. Fur this purpose, we collected Twitter data by utilizing the platform’s Streaming API. Twitter proclaims that the API provides \\(1\\%\\) of the global traffic produced by the platform. Preliminary experiments showed that by filtering specific hashtags (in this case we only filter out tweets containing the term Brexit), we are able to obtain almost a complete conversation history [7]. More precisely, we collected data in late 2019, before the Brexit (between 20th and the 27th of November) and on the actual Brexit day on the first of February. We explicitly removed retweets from our analysis since we want to identify trends only based on original content excluding simply exaggerated trends based on retweet cascades [15]. In total we gathered roughly 1.3 million tweets, which were clustered by our textClust algorithm.\n",
      "\n",
      "As specified in Sect. 3.1, the textClust algorithm requires some parameters that have to be set in advance. Especially \\(\\lambda , r\\) and \\(t_{gap}\\) do highly influence the final clustering result. The \\(\\lambda \\) parameter affects how fast micro-clusters fade out over time and is thus responsible for the overall lifetime of a topic. While a small value ensures that micro-clusters, which are not frequently updated, are not immediately discarded from the set of all micro-clusters, a larger value dismisses them rigorously. Also, \\(t_{gap}\\) influences which clusters are discarded since a larger value leaves more time for potential micro-cluster updates (and cleaning). The distance threshold r affects the granularity of micro-clusters. While a large value merges tfidf vectors which are not necessarily very similar to each other (and therefore may represent different topics), a small value only merges sentences which are almost identical. The choice of suitable parameters does highly depend on the underlying data set. Therefore, we cannot rely on best-practice parameter settings. In context of our data set we systematically tested different parameter combinations. We found that \\(\\lambda \\) also influences the number of identified trends. Since the Brexit day itself was very popular on Twitter with more than one million Tweets only on that day, we set a higher \\(\\lambda \\) in this scenario. Therefore we decided to set \\(\\lambda \\) to 0.001 (November) and 0.002 (Brexit day) respectively. We set \\(t_{gap}\\) to a fixed value of 100 and specified the distance threshold rather generously as 0.6. For all our experiments we used term-fading (fading according to elapsed time and not number of observations) to compensate variances in the stream throughput due to day/night cycles.\n",
      "\n",
      "Large micro-cluster that emerged from promoted Twitter campaign\n",
      "\n",
      "A quantitative evaluation of our approach is almost infeasible due to missing ground-truth data. In this proof-of-concept analysis we show that our framework is actually able to detect trending content within the Twitter stream. When we inspected the filtered micro-clusters from the data gathered between the 20th and the 27th of November, we identified one micro-cluster which exhibits a significantly higher cluster weight than all other ones (see Fig. 3). Consequently, we inspected this micro-cluster more in-depth, utilizing our Dashboard prototype. In total 1900 Tweets are assigned to that specific micro-cluster, with 1850 unique users. This implies that this unusual peak cannot be explained by single spamming accounts. However, we found that the message which was tweeted by all these different accounts is always exactly the same, motivating people to vote for the Conservative party to get the Brexit done (see Fig. 4). It has to be again emphasized that we explicitly excluded retweets from our clustering. Therefore, the observed phenomenon is an unusual distribution pattern. Since we have access to the original Tweet IDs, we inspected the Tweet more in detail. Interestingly, each of the Tweets in question consists of an additional button by which people are able to easily share the same content on their profile (via a new original Tweet) with one click. Further investigation revealed that this so-called call-to-action button is one feature of Twitter intended for businesses to reach their customers. Surprisingly, this feature also seems to be used in political context and has significant impact on the global conversation stream of that topic. Despite the high cluster weight, the trend lasted only a few hours and completely faded out afterwards.\n",
      "\n",
      "Call-to-action button for promoted tweets\n",
      "\n",
      "While our filtering approach during the first phase drastically reduces the number of interesting micro-clusters, it is not guaranteed that all of them do exhibit non-organic trends that should be classified as malicious. In context of the actual Brexit day (first of February 2020), we exemplary show how normal evolving trends can be distinguished from non-organic ones and how the second phase of our framework supports this differentiation. Within Fig. 5, we display three micro-clusters which all represent different topics that were discussed on Twitter that day. The blue trace represents a micro-cluster, containing tweets where users simply wished a happy Brexit day (similar to birthday wishes). As it can be inspected in the Figure, the trend (increase of the micro-cluster weight) started approximately at 8:00 AM with its peak 15 min later. This is not surprising, since it simply reflects that people started posting about the Brexit after they woke up (at nighttime the tweet throughput is significantly smaller than during the day). After the peak of the micro-cluster it slowly fades out until the end of the day, implying that the throughput of newly arriving tweets decreases over time. The green trace corresponds to a micro-cluster that summarized tweets about the first two cases of the corona virus in Britain which coincidentally happened at the same day. Again, the micro-cluster was created and immediately increases in it’s weight. Afterwards, similar to the Happy Brexit micro-cluster, the weight is slowly faded out during the day. The last micro-cluster established at 13PM and captures tweets about Putin which subliminally imply his involvement in the Brexit and that he finally wins. In contrast to the other two clusters, we observe a sharp weight edge with rapid fading after peaking.\n",
      "\n",
      "Organic and non-organic micro-cluster trends at the Brexit day (Color figure online)\n",
      "\n",
      "While the first cluster is an appropriate example for an organic trend that naturally arose due to the topic relevance, the last two both are not easy to interpret, since they contain controversial content that may originate from targeted opinion manipulation. Again, we utilized our Dashboard prototype to inspect those micro-clusters more in-depth. The corona virus cluster in total consisted of about 300 tweets. All tweets were posted by different authors who mainly originate from the UK. Also, the actual content of the tweets differed from each other. Although the term corona virus was always included in the tweet, the wording was always different. However, most tweets embedded an external URL, which linked to a BBC article which was published one day beforeFootnote 2. Using these insights, we conclude that the corona virus trend evolved also in an organic manner and was triggered by the newspaper article. Lastly, we inspect the cluster about Putin. Here, we observe completely different meta-data: First, all of the 320 tweets that were assigned to that cluster only originated from 60 accounts. Further inspection of the different users revealed that 124 tweets (almost \\(40\\%\\) of the cluster tweets) were produced by one single account. The message which was posted by that account was always the same. The only difference was that each tweet mentioned different political individuals. Hence, we deduce that this micro-cluster resulted from a dedicated spamming attack by one single account. For crossvalidation, we used the Botometer service to check whether this specific account can be classified as a bot (automated program). Although the content score is slightly higher than average, Botometer classifies the account as human. However, as we already stated in preliminary work, the Botometer system can be fooled and it is furthermore not of the uttermost importance to identify whether an account is automated or not. The overall goal should be the identification of malicious coordinated campaigns, executed by humans or non-humans [12].\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 5 Discussion and Future Work \n",
      "\n",
      "In this work we proposed a new two-phase framework that is capable of identifying artificially created and organic trends on social media stream data. By utilizing unsupervised stream clustering combined with an additional filtering approach, we can circumvent the problem of missing ground-truth data during the first online phase and simultaneously reduce the amount of unimportant data that has to be inspected manually. Within a second offline phase, we use meta-information that was persisted to secondary memory during clustering to get additional insights into the cluster contents. Within a Dashboard prototype the information is aggregated to valuable KPIs. Our experiments show that our framework is capable of identifying different types of trends. Ranging from simple spammers to coordination via multiple accounts, we revealed organic and non-organic trends that highly affected the overall discussion about the Brexit. We realize that the second offline step is necessary to get reliable insights regarding the type of trend and to verify or reject whether a campaign is malicious or not.\n",
      "\n",
      "While we currently only employ simple aggregation metrics within the second phase of our framework, there is a lot of room for applying additional, more sophisticated analyses such as the identification of user networks. Upcoming research should also focus on optimal parameter configuration. Ideally, parameters should be automatically adjusted during the online phase. The insights from different cluster evolution can also be used to produce ground-truth data within a semi-supervised setting. Via the cluster filtering method, information of suspicious post development and account meta data is gathered. After validation, this data might serve as ground-truth in supervised campaign detection approaches.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel:  Notes \n",
      "\n",
      "A python implementation of textClust and the corresponding dashboard can be downloaded here: https://textclust.com/.\n",
      "\n",
      "The article can be accessed here: https://www.bbc.com/news/health-51325192.\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "text = get_full_text(conference_chapter_soup, conference_chapter_link)\n",
    "\n",
    "for chapter in text:\n",
    "    chapter_name = chapter['chapter_name']\n",
    "    chapter_text = chapter['chapter_text']\n",
    "    print(f'Kapitel: {chapter_name} \\n')\n",
    "    print(chapter_text)\n",
    "    print('\\n \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "TEXT NR: 1 VON https://link.springer.com/article/10.1007/s12525-020-00445-0\n",
      "----------------------------------------\n",
      "Kapitel: Introduction \n",
      "\n",
      "How retailers and customers interact is constantly changing. The advent of omni-channel retailing made clear that customer interaction does not stop at a particular channel’s boundaries (Lemon and Verhoef 2016; Saghiri et al. 2017), as exemplified by hybrid customer interactions, where customers use digital and physical channels in parallel (Hosseini et al. 2017; Nüesch et al. 2015).\n",
      "\n",
      "With the emergence of smart retail technologies (Roy et al. 2017) that blur the boundaries between physical and digital channels (Roy et al. 2018), the number of touchpoints (TPs) a retailer must manage is increasing (Lewis et al. 2014; von Briel 2018). While the use of information and communication technology to improve processes has a long history in brick and mortar (BaM) retail, front-stage interactions with customers have primarily been based on person-to-person interaction (Betzing et al. 2018). In contrast, e-commerce, by definition, is built upon customer contact via e-service touchpoints (eTPs). Service is the application of competencies “through deeds, processes, and performances for the benefit of another entity or the entity itself” (Vargo and Lusch 2008, p. 26), which, when conveyed through a digital interface, is called e-service (Beverungen et al. 2011; Rowley 2006). eTPs are stimuli that customers may encounter when interacting with digital interfaces (Barann et al. 2020). In this article, eTPs are assumed to be classes of TPs (Heuchert et al. 2018) with e-commerce functionalities. For example, an online shop might provide access to product-comparison TPs. Trends like “bricks-and-clicks,” where TPs from stationary channels are adapted to e-commerce settings (Herhausen et al. 2015), allow online retailers to improve their existing eTPs and innovate new ones (e.g., Garnier and Poncin 2019; Jiyeon Kim and Forsythe 2008a, 2008b). The e-commerce industry has gained experience with eTPs over the last two decades, so it can be assumed that e-commerce has converged toward a set of dominant eTPs that appear in most online shops (cf. Suárez 2004).\n",
      "\n",
      "Retailers that operate exclusively in the BaM channel face pressure to innovate their TPs since the digital transformation has profoundly impacted the competitive market structure in favor of e-commerce and digital retail business models (V. Kumar et al. 2017; Verhoef et al. 2015). In addition, customers’ expectations regarding digital services offered by BaM retailers are increasing (Blázquez 2014; Bollweg et al. 2020; Hagberg et al. 2016). To create customer value, retailers can choose from a wide variety of technologies and eTPs (Vargo and Lusch 2008; Voorhees et al. 2017; Willems et al. 2017), but doing so is challenging, as their introduction carries risks and uncertainties (Pantano 2014), and BaM retailers have little guidance regarding what eTPs to implement. Research lacks clarity regarding customers’ intentions to use eTPs in BaM retail stores. While research investigates customers’ acceptance of various eTPs in e-commerce,Footnote 1 most studies on channel choice suggest that customers’ behavior in e-commerce and BaM retail differs (Schramm-Klein et al. 2007). However, only a few studies give advice regarding individual technologies and online practices that can be offered in the physical retail servicescape.Footnote 2 To fill this gap, this article investigates customers’ behavioral intentions toward BaM eTPs.\n",
      "\n",
      "Customers are likely to be familiar with the most prominent eTPs in e-commerce, so it can be argued that comparable eTPs for physical stores are a good starting point for BaM retailers to meet customers’ ever-changing expectations and a suitable subject for investigation. Therefore, the first research question is:\n",
      "\n",
      "\n",
      "RQ1: Are customers likely to use eTPs, which have been adopted from e-commerce and adapted to BaM retail?\n",
      "\n",
      "\n",
      "Furthermore, to determine the likeliness that customers will use such adapted eTPs in BaM retail stores, this manuscript aims at assessing what TP characteristics determine customers’ interest in the eTPs. Thus, the second research question is:\n",
      "\n",
      "\n",
      "RQ2: Is the likeliness that customers will use these e-service touchpoints affected by the touchpoints’ characteristics?\n",
      "\n",
      "\n",
      "An exploratory sequential multi-method approach (Creswell 2013; Mingers 2003) was used to answer these research questions and provide a broad overview of eTPs for BaM retail stores. First, a set of dominant eTPs offered by leading e-commerce platforms was selected, and each TP was adapted for use in the physical BaM servicescape. Second, a quantitative survey (Recker 2013) was fielded to 250 potential shoppers to determine the likeliness that they would use the candidate eTPs in a BaM context. Next, the determinants of the likeliness that customers would use the eTPs were subject to statistical tests and an exploratory factor analysis (Fabrigar et al. 1999) to reveal the unobserved TP characteristics that led to the survey results. Related to studies that focus on the overarching channels and interfaces, this work explores the determinants of customers’ behavioral intentions toward eTPs in BaM retail stores. The exploratory results suggest that customers’ intentions to use various kinds of BaM eTPs vary and are affected by their characteristics. Therefore, further research that considers the individual TPs next to more coarse-grained concepts is justified, as is whether to treat groups of eTPs that have common characteristics similarly.\n",
      "\n",
      "The remainder of this article unfolds as follows: First, the research background is introduced, followed by an explanation of the research approach. Then the eTPs are adapted, and the survey results are presented to address RQ1. Next, RQ2 is addressed by revealing the results of the exploratory factor analysis. The penultimate section discusses the findings, and finally, the article concludes with a summary, a discussion of the study’s limitations, and opportunities for further research.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Research background \n",
      "\n",
      "Optimizing the customer experience requires companies to take a fine-grained view of all the TPs its customers have with them (von Briel 2018). Omni-channel management uses “a synergetic management” (Verhoef et al. 2015, p. 176) of TPs across all available channels to improve their overall performance. However, according to Becker and Jaakkola (2020, p. 637), customer experiences are all “non-deliberate, spontaneous responses and reactions to particular stimuli,” which cannot be directly created. Instead, they suggest that a company can define intended experiences, design TP stimuli accordingly, and manage the customers’ TP encounters that follow. Research offers various versions of what constitutes the TP and the channel (e.g., Berendes et al. 2018; Kronqvist and Leinonen 2019; Richardson 2010). The channel usually refers to a particular medium that facilitates the interaction between a company and its customers (Halvorsrud et al. 2016; Neslin et al. 2006). The concepts of offline, online/digital, and mobile channels describe collections of related media, such as online shops and social media, which are specific digital channels or TPs (e.g., Hickman et al. 2019; Jocevski et al. 2019; Straker et al. 2015). Others understand TPs as individual channels or media (e.g., Baxendale et al. 2015; Lim et al. 2015; Straker et al. 2015), actual moments of contact or encounters that constitute customer journeys (e.g., Halvorsrud et al. 2016; Homburg et al. 2017; Verhoef et al. 2015), and perceptible stimuli that offer the potential for encounters (e.g., S. Davis and Longoria 2003; Kronqvist and Leinonen 2019; Richardson 2010). This article follows a differentiated understanding (e.g., Berendes et al. 2018; Følstad and Kvale 2018; Heuchert et al. 2018; Kronqvist and Leinonen 2019) and defines the customer touchpoint as “a stimulus fulfilling a specific role within the customer journey. It has an interface, which grants access to the stimulus and is mediated by a human, an analog object, or a technology situated in a physical or digital sphere. When encountering a touchpoint, a message between the customer and the retailer, its brand, or other customers is transmitted. This encounter causes a customer experience” (Barann et al. 2020, p. 7 in preprint). The customer journey is a process or path made up of a sequence of TPs the customer encounters to use or access a service (Becker and Jaakkola 2020; Følstad and Kvale 2018; Patrício et al. 2011). A medium conveys a whole collection of stimuli via an interface like a smartphone application (app) or a human-mediated service interface. The medium is subsequently assigned to a type of channel (Barann et al. 2020).\n",
      "\n",
      "Figure 1 illustrates the hierarchical relationship among the channel, the medium, the TP interface, and the TP stimuli. Each concept is the subject of its own body of scholarly work. Transcending the hierarchy, research also discusses channel choice, technology acceptance, and customers’ behavioral intentions toward individual TPs.\n",
      "\n",
      "Exemplary Non-Exclusive and Non-Exhaustive Relationships between Channels, Media, Interfaces, and Stimuli. Adapted from Wagner (2015)\n",
      "\n",
      "In the presence of multiple and integrated channels, understanding the determinants of customers’ channel choice behavior is a complex issue that is subject to intense research (Galipoglu et al. 2018; Steven et al. 2018; Neslin et al. 2006). Research finds that marketing efforts, channel attributes, social effects, channel integration, situational factors, and individual differences among customers, such as previous channel experience, determine customers’ channel choice (Melero et al. 2016; Neslin et al. 2006).\n",
      "\n",
      "As a result of the introduction of new digital channels and their increasing interconnections, companies must now ensure that their channels meet their customers’ requirements for each stage of the customer journey, instead of the customer journey as a whole (Zhao and Deng 2020). Customers choose their channels based on the tasks they seek to complete (Maity and Dass 2014), the stage of their customer journey (Frasquet et al. 2015; Hummel et al. 2017), and the degree to which a channel’s attributes are suited to the customer’s shopping goals (Dholakia et al. 2010). The relevance of the channels’ attributes to the customer varies with the situation along the journey. In response, existing research assesses the sequences of choices as parts of customer journeys. The complexity of omni-channel customer journeys makes it a paramount concern for researchers and firms to understand customers’ choices of interactions along these journeys (Barwitz and Maas 2018).\n",
      "\n",
      "Retailers can add a variety of technologies to their BaM stores (Inman and Nikolova 2017), blending them into a holistic and integrated customer experience (Blázquez 2014). When they integrate self-service (e.g., Falk et al. 2007) or other smart retail technologies (e.g., Roy et al. 2018), BaM retailers add new digital service interfaces to their physical servicescape, impacting their customers’ perceptions about the channel. For example, Wagner (2015) finds that the interfaces provided for customers to access an electronic channel impact their channel evaluations. Therefore, retailers should not only consider each channel as a whole but also each channel’s components to understand and guide customers’ channel choice.\n",
      "\n",
      "Customers’ perceptions of value are affected by their in-store experiences, which themselves are affected by technology. To improve this experience, the applied technology has to meet the customers’ expectations and be relevant to them (Blázquez 2014). Besides self-service technologies, mobile technologies can bridge the gap between online and offline channels, as they can mirror the e-commerce experience in BaM retail (Mirsch et al. 2016). These technologies impact the customer journey and enable the introduction of new TPs (Lemon and Verhoef 2016). To select beneficial technologies (Inman and Nikolova 2017), retailers require knowledge about their customers’ acceptance of these technologies (Pantano 2014). Roy et al. (2018, p. 156) suggest academia to “explore customers’ acceptance of specific” technologies in more detail.\n",
      "\n",
      "Studies on the acceptance of retail technologies employ the well-established Technology Acceptance Model (e.g., F. D. Davis 1985, 1989) or the Unified Theory of Acceptance and Use of Technology (Venkatesh et al. 2003, 2012). Such studies analyze factors that impact customers’ attitude toward (e.g., Müller-Seitz et al. 2009; Roy et al. 2018), behavioral intention toward (e.g., Chopdar et al. 2018; Müller-Seitz et al. 2009; Roy et al. 2018), intention to use (e.g., Aloysius et al. 2018; El Azhari and Bennett 2015), and use behavior (e.g., Chopdar et al. 2018; Demoulin and Djelassi 2016) regarding retail technologies like mobile shopping apps (e.g., Chopdar et al. 2018; Natarajan et al. 2018), location-based retail apps (e.g., Kang et al. 2015; Uitz and Koitz 2013), Radio-Frequency Identification (RFID) technologies (e.g., Müller-Seitz et al. 2009; Rothensee and Spiekermann 2008), or self-service technologies (Demoulin and Djelassi 2016; Weijters et al. 2007), as well as the in-store use of personal smartphones (e.g., Mosquera et al. 2018).\n",
      "\n",
      "Studies that address what leads to customers’ acceptance of technologies often miss to consider the impact of specific functionalities when a generic type of technology or an app that might be able to fulfill various tasks along the customer journey is the subject of the analysis. Still, some authors have conducted sub-studies that compared BaM technologies that offer certain functionalities (Inman and Nikolova 2017) or have certain service characteristics (Aloysius et al. 2018). These studies find that certain functionalities and design characteristics of technologies and services affect customers’ perceptions of technology in BaM retail stores. Natarajan et al. (2018) find that the type of device moderates the effect of various variables on the customers’ intentions to use mobile shopping apps. While channel choice is affected by the available interfaces (Wagner 2015), customers’ perceptions of such interfaces depend on the specific functionalities (Aloysius et al. 2018; Inman and Nikolova 2017) and the device used (Natarajan et al. 2018). In retail, the functionalities of, for example, a smartphone app can be considered TPs intended for certain stages of the customer journey (Boyd et al. 2019). Therefore, retailers should consider not only each interface as a whole but its components (i.e., its eTPs) to understand and guide customers’ technology acceptance.\n",
      "\n",
      "TPs offer various means of interaction during the customer journey (Boyd et al. 2019; Jocevski et al. 2019). All of the TPs customers encounter during their journeys have “direct and more indirect effects on purchase and other customer behaviors” (Lemon and Verhoef 2016, p. 82), so optimizing customers’ experiences requires an understanding of what characteristics cause these effects (Ponsignon et al. 2017; Verhoef et al. 2015). This article focuses on the factors that determine customers’ behavioral intentions toward eTPs in BaM stores. This manuscript understands these behavioral intentions as “the degree to which a person has formulated conscious plans to perform or not perform some specified future behavior” (Warshaw and Davis 1985, p. 214), that is, the likelihood that a person uses a specific eTP as part of a future BaM customer journey.\n",
      "\n",
      "Few studies investigate TPs (instead of channels) on a fine-grained level. Some use the TP concept to discuss various channels, media, or interfaces that belong to channels.Footnote 3 Few explicitly name and focus on TP stimuli or encountersFootnote 4 or focus on their characteristics.Footnote 5 Several studies discuss the determinants of customers’ behavioral intentions toward eTPs in an e-commerce context without calling them “touchpoints.”Footnote 6 Some studies analyze customers’ behavioral intentions toward TPs that are adapted from BaM retail to e-commerce (e.g., Garnier and Poncin 2019; Jiyeon Kim and Forsythe 2008a, 2008b). While most research on channel choice suggests that the customer behavior in e-commerce and BaM retail differs (Cervellon et al. 2015; Schramm-Klein et al. 2007), Schramm-Klein et al. (2007) and Walsh et al. (2010) show that customers’ criteria for evaluating e-commerce and BaM stores are similar but also that customers’ evaluation of services is significantly more important in online shops. Still, smart retail technologies in particular (Roy et al. 2017; Roy et al. 2018), along with the hybrid customer interactions they foster (Hosseini et al. 2017; Nüesch et al. 2015), unfold a new smart servicescape (Sanjit K. Roy et al. 2019) that combines aspects of BaM retail with those of e-commerce, leading to a technology-mediated in-store experience (Roy et al. 2017). Therefore, whether results from studies on eTPs in e-commerce can be transferred to BaM retail remains in question.\n",
      "\n",
      "However, only a few studies focus on customers’ behavioral intentions toward eTPs in this hybrid setting, although they do not use the term TP but use online practices and technologies (Lazaris et al. 2015a, 2015b), features (Burke 2002), or services (e.g., de Kerviler et al. 2016; Schierz et al. 2010), or name the particular TP under consideration. For example, studies focus on customers’ acceptance of mobile information search (de Kerviler et al. 2016), mobile self-checkout (Johnson et al. 2019), mobile payment (de Kerviler et al. 2016; C. Kim et al. 2010; Schierz et al. 2010), mobile coupons (Liu et al. 2015), mobile recommendation agents (Kowatsch and Maass 2010), mobile marketing (Persaud and Azhar 2012), or specific fashion retail eTPs (H.-Y. Kim et al. 2017; Weinhard et al. 2017). Some articles on self-service technologies (e.g., Aloysius et al. 2018; Demoulin and Djelassi 2016) are concerned with specific self-checkout TPs. Similar to this work, Lazaris et al. (2015a, 2015b) compare customers’ valuation of various online practices and technologies in BaM retail stores.\n",
      "\n",
      "Not all studies use theoretical constructs to measure customers’ behavioral intentions toward (e.g., Liu et al. 2015), intentions to use (e.g., de Kerviler et al. 2016; C. Kim et al. 2010; H.-Y. Kim et al. 2017), intentions to participate in using (e.g., Persaud and Azhar 2012), or attitudes toward (e.g., de Kerviler et al. 2016; H.-Y. Kim et al. 2017; Schierz et al. 2010) eTP in BaM retail. Studies indicate that customers’ perceptions of, attitudes toward, and behavioral intentions differ across various eTPs (H.-Y. Kim et al. 2017) and that the predictors of their intention to use various TPs also differ (de Kerviler et al. 2016; H.-Y. Kim et al. 2017). Lazaris et al. (2015a, 2015b) use two samples in two studies to analyze customers’ perceptions of the importance of the same technologies and practices applied in BaM retail stores. In both studies, the groups of eTPs whose ratings are strong or weak are similar, and they find no significant differences in the subsets of TPs. de Kerviler et al. (2016) also find that the strength of the spillover between customers’ behavioral intentions toward different eTPs is positively related to their similarity.\n",
      "\n",
      "While such studies provide first insights into the determinants of customers’ behavioral intentions toward eTPs in BaM retail, the literature covers only a small portion of extant BaM eTPs, and there is no consensus about the approach to be used to measure the determinants that cause customers’ behavioral intentions toward eTPs in BaM retail. In summary, then, this exploratory study investigates the factors that determine the likeliness that customers would use eTPs in BaM retail, that is, how customers choose the means to communicate, interact, and exchange with other actors, such as the retailer, during their BaM customer journeys. Fig. 2 provides an overview of some of the relationships considered by the interdependent research streams at each level. Appendix A provides additional details about related works in these literature streams.\n",
      "\n",
      "Exemplary Research Perspectives in Channel Choice, Technology Acceptance, and Behavioral Intentions Toward Touchpoints (Numbers refer to the IDs in Table A.1 in Appendix A)\n",
      "\n",
      "Even though doing so is unconventional in the area of information systems research (Mingers 2001), the posited research questions ask for a combination of empirical and interpretative methods: While assessing the likeliness that customers would use eTPs (RQ1) implies empirical work, understanding the factors that cause customers to use the TPs (RQ2) requires going beyond quantitative work, so this study uses a data-driven (Müller et al. 2016) multi-method approach (Mingers 2003) to address its research questions. This mix of methods allows for an exploratory discussion of multi-sourced eTPs candidates that cover both innovative (still theoretical) eTPs and existing and implemented eTPs that are chosen from an initial qualitative web-content analysis. The structure and contextualization of the methods used in the research framework are visualized in Fig. 3. With the output of each step, typically being the input for its successor, an explanatory, sequential approach is followed (Creswell 2013). This study extends the work of Betzing et al. (2019) by using an in-depth analysis to discuss the underlying factors causing the likeliness that customers would use eTPs in BaM retail stores, transcending the mere descriptive ranking of eTPs that are likely to be used.\n",
      "\n",
      "Research Framework\n",
      "\n",
      "The first step was to identify candidate TPs for the analysis using a qualitative web-content analysis approach (Mayring 2014), following the lens of dominant design theory (Suárez and Utterback 1995) and acknowledging the lack of a formally derived list of eTPs for BaM retail in the literature. Through the systematic analysis of popular e-commerce solutions, a selection of commonly offered eTP candidates with which customers are likely to be familiar was selected.\n",
      "\n",
      "To assess the likeliness that customers would use generic BaM eTPs—and not specific e-commerce instantiations (e.g., the Amazon shopping cart)—their features were identified to adapt them to BaM retail. In keeping with Beverungen et al. (2011), service blueprints were created to transfer the services from one servicescape to the other. These blueprints were also used to support the discussions between the researchers and to inform the survey design.\n",
      "\n",
      "A quantitative survey research approach was followed (Recker 2013) to capture the likeliness that shoppers will use the BaM eTPs (RQ1) derived in the preceding step. As method advocates like Bitner et al. (2008) recommend initial training to establish a common understanding of formalized models like service blueprints, these blueprints would have been unsuitable for describing the eTPs to survey participants. Hence, similar to Inman and Nikolova (2017), Aloysius et al. (2018), and Kleijnen et al. (2007) who used textual descriptions to describe technologies or services under investigation, each eTP was described by using a less formalized description of the blueprints, keeping the semantic essence while changing the syntactical frame. Alternative approaches turned out to be inappropriate, as practical implementations of the eTPs in BaM retail stores are scattered across retailers, and several identified eTPs still lack a BaM implementation. While lab experiments would have allowed investigating specific TPs on a more detailed and technical level, the description-based survey was preferable for three reasons: First, a wider variety of TPs could be covered by avoiding costly prototype implementations. Second, abstracting from the specifics of the individual TPs allowed to observe more general TP-spanning characteristics affecting the likeliness that customers would use them. Third, by asking participants to conduct an imaginative shopping trip in a local BaM store that started to offer a series of eTPs rather than evaluating customer perceptions at a specific BaM store, the survey abstracted from contextual aspects that might have affected the results.\n",
      "\n",
      "Based on the data collected in the preceding step, correlation tests (Kendall 1938; Pearson 1895; Spearman 1904) and multivariate multiple (Dattalo 2013) ordinal logistic regressions were performed to analyze the results and provide a basis for answering RQ1. To clarify the survey results and provide a foundation to answer RQ2, an exploratory factor analysis (EFA) was conducted on the 26 survey items capturing the likeliness that the participants would use the individual eTPs. An EFA is a statistical approach that can be used to identify the common underlying dimensions or structures of survey items by analyzing their interrelationships (Hair et al. 2013). In contrast to confirmatory factor analysis, the purpose of which is to evaluate a proposed theory, EFA is used if no prior theory exists (Williams et al. 2010). The factor analysis found seven unobserved characteristics that caused the variance in the data. Finally, to ensure a theoretically grounded interpretation of these factors, three researchers independently coded each of the adapted eTPs in terms of their common TP characteristics (see Table E.4 in Appendix E.2) and the initial blueprints.\n",
      "\n",
      "This section covers the “Data Collection” phase and also the first analytical elements (i.e., the “Descriptive Statistics”). As this article is an extension to Betzing et al. (2019), the first two steps (“Qualitative Web Analysis” and “Blueprinting”) are shortened, as this article’s focus is the subsequent statistical analysis and interpretation. Further details on these steps can also be found in the Appendices B and C.\n",
      "\n",
      "Since no comprehensive scientific overview of potential eTPs for BaM retail stores was found, dominant eTPs that are promising for adaptation in the physical retail servicescape were derived from e-commerce. A qualitative web-content analysis (Mayring 2014) was conducted following the lens of dominant design theory, which proposes that a product category establishes a representative set of functions over time that is then accepted as standard (Suárez and Utterback 1995). This lens has been applied to technological milestones like microprocessor designs, PC operating systems, and television systems (Suárez 2004; Suárez and Utterback 1995). Murmann and Frenken (2006) develop a generalized framework for dominant design research, advancing this theoretical lens by making it applicable not only to technologies but to multi-level systems (Kask 2011). Therefore, as Kask (2011) argues, it is even applicable to organizational systems like market channels that are comprised of various elements with different missions. The dominance of technology can be investigated on several levels of analysis, one of which is by considering “technological artifacts as [being] composed of subsystems that are linked together [...] through specific interfaces” (Suárez 2004, p. 274).\n",
      "\n",
      "E-commerce systems can be considered such artifacts, as they are digital interfaces that belong to the online channel and are composed of various eTPs. As e-commerce is a mature domain (V. Kumar et al. 2017), it is fair to suppose that leading e-commerce systems have set a dominant design that is comprised of a set of functions that represent the requirements of various types of users (cf. Suárez and Utterback 1995). Accordingly, the designs of the eTPs that leading e-commerce systems offer most often can be considered to be dominant and that they are likely to be used in BaM retail stores as well.\n",
      "\n",
      "Therefore, the proprietary solutions of Amazon, Otto, and Zalando, the German e-commerce market leaders (Betzing et al. 2019; EHI Retail Institute 2018), were analyzed and major instances of five widespread commercial off-the-shelf (COTS) e-commerce solutions—Shopify, Magento, WooCommerce, XT:Commerce, and Shopware—were assessed (Betzing et al. 2019; Datanyze 2018). To address variances that may result from national peculiarities, customization, and differing product categories, three major European e-commerce retailers were sampled for each of the five solutions. Thirty-five eTPs were identified from which any that were not offered by at least four instances (lack of commonality) or that required an online shop for service delivery were filtered out, resulting in twenty adaptable eTPs.\n",
      "\n",
      "Service blueprints were created to transfer the eTPs from e-commerce to BaM retail (cf. Beverungen et al. 2011). Service blueprinting is a well-established, customer-focused modeling method for service innovation and improvement (Beverungen et al. 2011; Bitner et al. 2008) that yields “a picture or map that portrays the [planned] customer experience and the service system, so that the different people involved in [its development][...] can understand it objectively, regardless of their roles or their individual points of view” (Zeithaml et al. 2017, p. 238).\n",
      "\n",
      "Figure 4 illustrates the adapted In-Store Navigation (S) TP as an example of a service blueprint. Creating the service blueprints involved considering the mediating technology and the necessary activities to be performed by the customer and the BaM retailer (as the service provider). To accommodate customers’ use of various digital devices in accessing service, the original blueprinting method was extended with an additional layer that listed the digital devices that could be used to consume the service. Frequent discussion among three researchers ensured that the blueprints were (a) suitable representations of the identified eTPs and were (b) not subject to excess bias.\n",
      "\n",
      "Exemplary Service Blueprint for an Adapted In-Store Navigation (S) Touchpoint\n",
      "\n",
      "The 20 e-commerce eTPs were adapted to the 26 BaM eTPs, as depicted in Table 1, mostly mediated by a smartphone app. Numeric differences are due to the mapping applied, which mapped some multiple-input TPs to a single output TP and vice versa, and different mediating devices—i.e., terminal and smartphone—were considered for some of the TPs. The full descriptions of the adapted eTPs and their service blueprints can be found in Appendix C of this manuscript for researchers who want to reproduce (Peng 2011) and/or extend this article’s contributions.\n",
      "\n",
      "To provide additional structure, each eTP was initially categorized into one of four categories based on its value:\n",
      "\n",
      "Search & Navigation: eTPs in this category are primarily solution-oriented shopping aids (Chang and Kukar-Kinney 2011) in the pre-purchase stage (Lemon and Verhoef 2016) that assist in reducing search time and information overload (Betzing et al. 2019).\n",
      "\n",
      "Product Information: eTPs in this category are research-supporting shopping aids (Chang and Kukar-Kinney 2011) in the pre-purchase state that assist with information retrieval and alternative evaluations (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Selection & Checkout: eTPs in this category aid customers in planning, conducting, and controlling past, current, and future purchases (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Communication & Support: eTPs in this category are marketing, customer engagement, and customer care-centric eTPs that are independent of the customer journey stage (Betzing et al. 2019; Lemon and Verhoef 2016).\n",
      "\n",
      "Survey Research Approach\n",
      "\n",
      "While the adaption of dominant e-commerce TPs appears promising for BaM retailers, whether and to what extent customers are likely to use them remains unclear, as “a dominant design is not always that design which has greatest technological sweetness” (Suárez and Utterback 1995, p. 417). Therefore, a quantitative online survey (Recker 2013) was conducted to get an idea of customers’ behavioral intentions toward eTPs. Participants were first asked to imagine themselves going on a shopping trip in a futuristic BaM retail store that offers digitally enhanced services via a touchscreen terminal and/or an app on their smartphone. Participants were asked to abstract from the type of products sold and focused on the service offerings. Next, the eTP categories were introduced. Throughout the survey, each eTP was introduced in one paragraph. For example, the Product Comparison TP was described as follows: “Imagine yourself planning to select a product, e.g., a new television, out of a set of similar options. Within the Smart Store, you can use your Companion App to scan two to multiple products’ QR-Codes and compare them with each other. A table with relevant information on each product, e.g., size, price, and technical features will be displayed. Likewise, you can use a Terminal to compare multiple products by entering the product names.”\n",
      "\n",
      "The likeliness that the participant would use the eTP was surveyed using a single five-point Likert scale item (e.g., Bernard 2013) (e.g., “How likely would it be for you to use such a Product Comparison Service via an App?”). If applicable, a second item was included to investigate the alternative implementation on a terminal. The participants were also asked whether they use their smartphones to support their activities in BaM stores and how frequently they shop online. Participants provided demographic information, including their country of origin, education, gender, and age.\n",
      "\n",
      "Since BaM retail is prevalent in society, the survey was not limited to a particular audience but used prolific.co, a recruiting platform that provides researchers with representative samples of participants in terms of age, gender, and educational level, to recruit a diverse sample of more than 300 participants aged eighteen and older who were from Western countries (Betzing et al. 2019, p. 565).\n",
      "\n",
      "An attention-check question (adapted from Oppenheimer et al. (2009)) used to filter out inattentive participants yielded 250 valid responses. All but one participant had purchased goods and services online at least once: Nine participants (3.6%) engaged in e-commerce activities daily, 105 (42.0%) did so weekly, half did so roughly once a month, and ten used e-commerce as infrequently as once a year. The average age of the participants was 32.69 years (\\( \\overset{\\sim }{x} \\) = 31 years, σ = 9.96 years), 53.6% of whom were women. Participants came from the United Kingdom (145), the United States (52), Canada (12), Portugal (9), the Netherlands (4), and sixteen other European countries (28). Almost all the respondents (99.20%) reported owning a smartphone, and 72.80% reported using their smartphones or tablets in stores to support their shopping process. The average time participants required to complete the survey was 9 min and 37 s. Participants received £1.15 for their participation (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Figure 5 shows the distribution of the responses to the eTPs, sorted by category and in descending order by average rating. The global average rating was 3.58 points. The Social Media TP ranked worst with an average of points, while the Mobile Self-Checkout TP ranked highest with an average of 4.35 points. The comparison of the four touchpoint categories revealed that respondents were most likely to use the selection and checkout TPs (∅ 3.92 points). Product information TPs (∅ 3.79 points) and search and navigation TPs (∅ 3.73 points) ranked similarly, whereas respondents were much less likely to use the communication and support TPs (∅ 2.94 points). The Social Media (σ2 = 1.71; σ = 1.31), Periodic Newsletter (σ2 = 1.64; σ = 1.28), Location-Based Newsletter (σ2 =1.60; σ = 1.27), and Messaging TPs (σ2 = 1.48; σ = 1.22) were the most controversial (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Distribution of the Likeliness that Customers Would Use the E-Service Touchpoints (grouped by touchpoint categories, with groups in descending order of average score)\n",
      "\n",
      "Six eTPs were surveyed regarding the two service interfaces, smartphone (S) and in-store terminal (T). The results show that respondents preferred smartphones over terminals by an average of .50 points, and every e-service was ranked higher when it was accessed via a smartphone app. Differences in the likeliness that customers would use the smartphone and terminal variants were lowest for the Product Exploration (S&T) TPs (.26 points) and highest for the Product Information (S&T) TPs (.71 points) (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Pairwise Spearman’s rank coefficients ρ between each e-service and the respondents’ ages indicated no significant relationships for TPs other than the TPs Product Comparison (T) (ρ = .48; p < .001), Read Product Review (T) (ρ = .45; p < .01), and FAQ (T) (ρ = .39; p < .01), all of which had a positive relationship with age. On the other hand, the Social Media TP (ρ = −.43; p < .01) had a negative relationship with age. Kendall’s τb did not indicate significant relationships between gender and the respondents’ answers, except for a weak positive relationship between female respondents and the Messaging TP (τb = .16; p < .01). However, women were, on average, .08 points more likely to use the TPs than men were. Although not statistically significant, women were more likely than men were to use a smartphone (.31 points) or an in-store terminal (.38 points) to read product reviews (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Spearman’s rank coefficient was employed again to assess relationships between the eTPs. Results show that TPs accessed via a terminal correlated with each other but not with other TPs. Several communication and support TPs had comparatively strong relationships with each other: The Product Exploration (S) TP strongly correlated with the In-Store Navigation (S) (ρ = .51), and the Product Information (S) TP (ρ = .46). Likewise, the In-Store Navigation (S) and Product Information (S) TPs were also strongly correlated (ρ = .51). A scatter plot showing the results of this analysis is provided in Fig. D.1 in Appendix D.1 (Betzing et al. 2019, p. 565).\n",
      "\n",
      "Finally, 26 ordinal logistic regressions were performed, each of which considered the likeliness that participants would use one of the eTPs as the dependent variable and, as independent variables, the respondents’ BaM demographics, smartphone use, and online shopping frequency (see Table D.1 in Appendix D.2).Footnote 7 In addition to reconfirming relationships like the influence of being female on the likeliness that a participant would use the Read Product Review (S&T) and the Messaging TPs, the results revealed further effects between the independent variables and the likeliness that participants would to use certain eTPs. For example, retail-related smartphone use was a significant predictor of the likeliness that participants would use most eTPs. Other results are considered in the discussion section of this manuscript.\n",
      "\n",
      "Overall, the relationships between the variables and the correlations between the BaM eTPs differed, giving a reason to assess whether unobserved eTPs characteristics could explain these variances. Therefore, an exploratory factor analysis (Fabrigar et al. 1999) was conducted to reveal the factors behind the likeliness that customers would use the BaM eTPs in the sample. Because of this research’s exploratory nature, no a priori assumptions about the characteristics were made. Instead, a variety of possible eTPs were included. Still, a ratio of approximately five survey items to one derived factor was reached (Fabrigar et al. 1999). Regarding the suitability of the sample, the response to variable ratio is in the mid-field, approximately 10:1 (Comrey 1973; Williams et al. 2010), and the anti-image correlation matrix did not reveal any high partial correlations (Hair et al. 2013). The Kaiser-Meyer-Olkin Measure of Sampling Adequacy (Kaiser 1970; Kaiser and Rice 1974) showed a “meritorious” (Hair et al. 2013, p. 102) score of .858, and Bartlett’s Test of Sphericity also passed with a p-value of .000 (Hair et al. 2013). In keeping with the analysis’ goal of identifying the characteristics of eTPs that affect the likeliness that customers would use them, the factor extraction method was selected (Hair et al. 2013). A common factor analysis (CFA) with principal axis factoring was chosen instead of principal component analysis (PCA) because CFA identifies latent constructs, which results in a reflective model of factors that cause the observed variables (Costello and Osborne 2005; Gorsuch 1997; Henson and Roberts 2006). The frequently applied orthogonal VARIMAX rotation was used as a factor rotation method to identify unique uncorrelated factors (Henson and Roberts 2006). An initial solution with seven factors was derived based on the scree test and parallel analysis (95th percentile) (Costello and Osborne 2005; Fabrigar et al. 1999; Glorfeld 1995; Hair et al. 2013). Only the Product Availability and the App-Equipped Clerk TPs had loadings smaller than the recommended threshold value of .4 (Ferguson and Cox 1993; Hair et al. 2013). Likewise, the FAQ (T) and Read Product Review (T) TPs showed cross-loadings higher than .4 on more than one factor, causing the algorithm to return two factors that had just one variable strongly loading onto them. As suggested by literature (Ferguson and Cox 1993; Hair et al. 2013), these variables were removed from the model. Performing these tests on the reduced data revealed no issues.\n",
      "\n",
      "Fig. 6 presents the resulting factors and their loadings. This final model explains 51.578% of the variance (see Table E.1 in Appendix E.1), which is larger than the threshold value suggested by Merenda (1997). Table E.2 and Table E.3 in Appendix E.1 provide information on the rotated factor matrix, factor loadings, and the factor score coefficient matrix. Fig. E.1 in Appendix E.3 also shows that all eTPs described by a corresponding factor significantly correlate internally, and in some cases, these correlations are comparatively strong.\n",
      "\n",
      "Factors Affecting the Likeliness that Customers Would Use the E-Service Touchpoints\n",
      "\n",
      "Factor interpretation is a qualitative process that focuses on the researchers’ understanding of the survey items onto which a factor loads most heavily. Therefore, each survey item is assigned to the factor with the highest loading and only considered once during the process (Hair et al. 2013; Williams et al. 2010). To support this interpretation, TP characteristics were derived from the literature for coding the eTPs based on the survey descriptions. Only a few studies explicitly name and delimit characteristics of TPs. Table E.4 in Appendix E.2 explains the adapted characteristics that were applied. In effect, the eTPs were coded according to the themes “content display” (i.e., information, promotion, support, or revenue), “purpose of use” (i.e., function, diversion, or interaction), and “direction of communication” (i.e., simplex or duplex) (Straker et al. 2015, p. 114). They were also coded according to the “ownership” (Lemon and Verhoef 2016) of the medium that grants access to the eTP (i.e., customer-owned, employee-used, or retailer-owned). Finally, the eTPs were assigned to a stage of the customer journey (Hoyer et al. 2012; Lemon and Verhoef 2016; J. Lu 2017; Neslin et al. 2006).\n",
      "\n",
      "Three researchers independently coded the eTPs—6 categories with 18 features were coded for each of the 26 eTPs, yielding 468 items for each coder. By means of Holsti’s coefficient of reliability (Holsti 1969), an inter-coder reliability of rH = .86 was reached, which shows a strong agreement that is within the accepted range of .8–1.0 for nominal-scaled judgment-based data (Perreault and Leigh 1989). All deviations were discussed until a consensus was reached.\n",
      "\n",
      "The characteristics of all eTPs that are affected by a specific factor were then jointly considered to support the interpretation process. Groups of characteristics with strong or weak overlaps served as the basis for naming the factors. The results of this process are discussed below.\n",
      "\n",
      "F1: External Influential Messages as Content: F1 causes the likeliness that customers will use mostly promotion or support TPs independent of the customer journey stage, focusing on social aspects, recreational activities, and interactions. The Location-Based Newsletter received the highest factor score among the touchpoints affected by F1.\n",
      "\n",
      "F2: Terminal as Medium: F2 causes the likeliness that customers use functional eTPs mediated by a terminal that provides access to additional product or location information. The CFA suggested that some of the terminal TPs were also affected by the factors that cause the likeliness that customers will use the respective smartphone app variants.\n",
      "\n",
      "F3: Supported Product Search as Functionality: F3 causes the likeliness that customers will use functional eTPs that provide additional information for their search process during the customer journey. Within this group of eTPs, the In-Store Navigation (S), which is associated with customers’ search processes, received the highest factor score.\n",
      "\n",
      "F4: Answer Inquiries as Functionality: F4 affects the likeliness that customers will use informational eTPs, which mainly answer inquiries about the selection of alternatives and are shopping aids that allow customers to find the right products and get answers to questions quickly.\n",
      "\n",
      "F5: Historical Customer Data as Content: F5 describes two functional support TPs that provide access to historical customer data. While the Order History TP informs both the alternative evaluation and the post-purchase stage of the customer journey, the Recently Viewed Products TP allows customers to keep track of products they have already considered during their evaluation of alternatives.\n",
      "\n",
      "F6: Supported Checkout Procedure as TP Functionality: F5 causes the likeliness that customers will use revenue TPs that support the purchase stage of the customer journey. They provide alternative means for the checkout process and are meant to improve shopping efficiency.\n",
      "\n",
      "F7: Supported Product Collection as TP Functionality: Finally, F7 causes the likeliness that customers will use functional eTPs that keep track of the planned and actual shopping basket.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Discussion \n",
      "\n",
      "The results provide first exploratory insights into customers’ behavioral intentions toward eTPs in BaM stores. These insights have several implications for research and practice. Overall, the survey participants were likely to use the BaM eTPs. They preferred TPs that aid in searching for products, finding information, selecting products, or facilitating a more efficient customer journey. In contrast, there was considerably less interest in communication and support eTPs. The regression showed that prior BaM retail-store-related smartphone use was a significant predictor of the likeliness that the surveyed shoppers would use many of the eTPs. Not significantly affected were most of the terminal TPs, the Order History, and the Write Product Review TPs. However, the latter two TPs were weakly but significantly positively affected by the frequency of online shopping, which also had a weak positive impact on the Product Exploration (S), App-Equipped Clerk, Read Product Review (S&T), Recently Viewed Products, Mobile Self-Checkout, Sales-Floor Checkout, Social Media, and the Location-Based Newsletter TPs. Males were less likely to use the Read Product Review (S&T) and Messaging TPs than women were. Finally, the Sales-Floor Checkout, Shopping List, and Location-Based Newsletter TPs were negatively affected by the participants’ education levelFootnote 8 (see Table D.1 in Appendix D.2). The moderate correlations between some touchpoints (see Fig. D.1 in Appendix D.1) indicate a potential for bundling service offerings, albeit, without an immediate need for BaM retailers to act. The factor analysis uncovered seven factors that affect the likeliness that customers would use the proposed eTPs. The TPs that are described by a factor correlate (see Fig. E.1 in Appendix E.3), indicating that customers could perceive the corresponding TPs as being similar. The results support research that found that customers perceive groups of eTPs as similar (Lazaris et al. 2015a, 2015b), and that found stronger spillover effects for similar TPs (de Kerviler et al. 2016). Thus, this article provides preliminary evidence that the likeliness that customers will use eTPs in BaM stores is affected by the TPs’ characteristics and, so it indicates that it could be reasonable to treat eTPs that form such groups similarly. The identified factors are discussed in the following.\n",
      "\n",
      "Since its inception, e-commerce has been primarily functional in nature (Noble et al. 2005), making its utilitarian benefits for information search vital to customers (Blázquez 2014), particularly, because the usefulness of a channel for facilitating product information search affects the frequency of product searches and purchases through that channel (Jihyun Kim and Lee 2008). By complementing physical stores with eTPs, the e-commerce experience can be replicated in BaM retail (Mirsch et al. 2016; Roy et al. 2017; Roy et al. 2018). Technology supports the in-store shopping process and improves the customer experience (Renko and Druzijanic 2014; Tyrväinen and Karjaluoto 2019; Verhoef et al. 2015). As the factor analysis indicates, the highest-rated eTPs aid customers in their search, collection, and selection of products (F3, F7, and F4) and or more efficient checkout procedures (F6). The eTPs that are affected by these factors can be considered research-supporting and solution-oriented shopping aids (Chang and Kukar-Kinney 2011) that increase customers’ shopping effectiveness (i.e., finding the right products) and efficiency (i.e., fast service) (Blázquez 2014; Meuter et al. 2003).\n",
      "\n",
      "The informational and functional eTPs that are affected by the factors F3 and F7 support customers in product search and retrieval. According to prior research, behavioral intentions toward mobile information search in BaM retail stores are typically affected by customers’ perceptions of its benefits (de Kerviler et al. 2016). In addition, prior research suggests that the utilitarian benefits of digital TPs are more important than their hedonic benefits (Vannucci and Pantano 2019). Functional in-store technologies are shown to cause fewer privacy concerns than others and may even reduce them in mobile apps, including promotional TPs (Inman and Nikolova 2017). However, the technology and its mediated information must be trustworthy, and customers’ privacy concerns could still limit their acceptance (Resatsch et al. 2008).\n",
      "\n",
      "F4 affects three eTPs that allow customers to gather information for their evaluation of alternatives or purchase decisions. Thus, the likeliness that customers will use these eTPs could be affected by their ability to find the right products and get answers to questions quickly. The information provided by these eTPs is product-related, customer-generated, and brand-generated. The survey results support extant studies’ suggestion(e.g., Tyrväinen and Karjaluoto 2019) to implement eTPs that allow customers to compare products. Also, the positive attitude of the surveyed shoppers toward the Read Product Review (S) TP is unsurprising since prior research argues for the importance of direct customer-to-customer (C2C) interaction in BaM retail stores (Harris et al. 1997). C2C interaction also has a stronger impact on satisfaction than customer-to-employee interaction does (Harris et al. 1997), which, in turn, can impact customers’ attitudes about a store (Lee and Lim 2017). However, the impact of digital C2C interactions like product reviews on purchase behavior in e-commerce differs based on the customer’s age (von Helversen et al. 2018). As channel characteristics can moderate such effects, the impact of novel digitally enabled C2C interactions in the smart BaM servicescape requires further investigation (Libai et al. 2010). In addition, the surveyed shoppers were less likely to use the FAQ (S) TP than they were to use the other two eTPs. Similarly, Kim and Stoel (2005) show that, compared to other TPs in e-commerce, customer attitudes toward FAQ TPs were, on average, the lowest. Still, Kim and Stoel (2005) find that such TPs affect purchase intentions. Therefore, further research should investigate such BaM TPs in more detail.\n",
      "\n",
      "Finally, F6 affected two TPs that are concerned with alternative checkout services. Overall, prior research finds varying impacts of perceived usefulness, the relative advantage in terms of time-savings and reduced customer confusion, ease of use, risks, perceived security, and compatibility on the customers’ intention to use mobile self-checkout or payment eTPs (Aloysius et al. 2018; de Kerviler et al. 2016; Johnson et al. 2019; C. Kim et al. 2010; Schierz et al. 2010). In the survey, Mobile Self-Checkout was the most prominent eTP. The participants’ online shopping frequency had a weak but significant positive impact on the likeliness that they would use this eTP (see Table D.1 in Appendix D.2). Usually, customers attach importance to and have a positive attitude about self-checkout TPs (Inman and Nikolova 2017; Lazaris et al. 2015a, 2015b), as they provide several benefits (Renko and Druzijanic 2014), including improved efficiency because they are faster than their employee-operated counterparts (Vannucci and Pantano 2019; Vuckovac et al. 2017). By reducing the time and effort required in shopping in BaM stores, retailers can drive store patronage intentions (Baker et al. 2002). Time convenience was also shown to have positive impacts on customers’ perceptions of the value of the mobile channel, which encourages customers to use the channel (Kleijnen et al. 2007). In contrast, the Sales-Floor Checkout received lower ratings by the shoppers surveyed on average. Further research should investigate whether dependence on employees reduces customers’ perceptions of an eTP’s potential to save time. The participants’ prior BaM-retail-related smartphone use had a significant positive impact on the likeliness that they would use this eTP (see Table D.1 in Appendix D.2). In addition, its similarity to the existing self-checkouts offered by some retailers may have positively affected the participants’ perceptions of the Mobile Self-Checkout TP, so an exposure or a spillover effect could have occurred (de Kerviler et al. 2016; Zajonc 1968), which could be subject to further research.\n",
      "\n",
      "In sum, based on the findings from the survey and prior research, BaM retailers should design and introduce easy-to-use eTPs that, depending on the industry, provide utilitarian and/or hedonic benefits with low privacy concerns for the pre-purchase stage (e.g., for additional store-generated, product-related, or customer-generated information) and the purchase stage (e.g., more efficient checkout services). However, considering prior research, in addition to customer benefits and acceptance, the retailers’ benefits and outcomes should also be considered (Inman and Nikolova 2017; Renko and Druzijanic 2014). In e-commerce, for example, search support, FAQs, and product-comparison services can affect customers’ purchase intentions (M. Kim and Stoel 2005). Therefore, further research could consider the effect of eTPs on customers’ purchase intention in BaM retail stores in more detail. For instance, digital shopping lists can contain fewer items but result in more hedonic and unplanned purchases (Huang and Yang 2018), and customers spend more money in BaM stores when they use the internet to search for information (Sands et al. 2010) and are more likely to buy fresh products if they are provided with (real-time) information via eTPs (Fagerstrøm et al. 2017), making such eTPs potential revenue drivers.\n",
      "\n",
      "Content-related factors are concerned with influential external input from the retailer or from other customers (F1) and access to historical customer data (F5). F1 loads onto several promotional and support TPs that have a diversional or interactional nature. Some of the TPs that are affected by F1 are among those that are least desirable.\n",
      "\n",
      "F1 affects three promotional eTPs—the Product Recommendation and the two Newsletter TPs—meant to stimulate customers to recognize needs based on previous purchases. According to prior research, customers’ brand trust, shopping styles, and perceived value affect their intention to participate in mobile marketing (Persaud and Azhar 2012). Research highlights customers’ negative sentiment toward intrusive communication and personalization in BaM stores (Burke 2002) and even suggests lower use intentions and stronger privacy concerns for personalized e-services in BaM retail stores than in e-commerce (Wetzlinger et al. 2017). It may be for these reasons that, similar to other studies (Lazaris et al. 2015a, 2015b), participants gave the Product Recommendation TPs mediocre ratings. In contrast, other studies argue that customers prefer stores that offer Product Recommendation TPs and show that customers’ behavioral intentions toward such eTPs are driven by their perceived usefulness (Kowatsch and Maass 2010). Relative advantages and personalization are also shown to have a positive mediated impact (i.e., via satisfaction and perceived risk) on customers’ behavioral intentions toward retail technologies (Roy et al. 2017). Vannucci and Pantano (2019) find that customers have more trust in the suggestions made by digital TPs than they have in those made by human TPs. However, past e-commerce research suggests that personalization has no effect on purchase intentions (M. Kim and Stoel 2005). Future research could consider in more detail the factors affecting customers’ behavioral intentions toward BaM Product Recommendation TPs and their impact on customers’ purchase intentions.\n",
      "\n",
      "The Location-Based Newsletter received the second-lowest average rating among the eTPs in the survey. Research on location-based retail services and apps finds varying impacts of perceived usefulness, cognitive/affective involvement, ease of use, flow (i.e., enjoyment, control, and concentration), trust, and privacy concerns on customers (Kang et al. 2015; Uitz and Koitz 2013; Zhou 2016). For example, the positive impact of affective involvement on the intention to use is greater for experientially oriented customers (Kang et al. 2015). Companies can also affect flow, trust, and privacy concerns, all of which can affect customers’ continuance intention through the quality of the system, service, and information (Zhou 2016). This article’s survey results show that privacy concerns may be reflected by the average higher rating of the Location-Based Newsletter TP’s periodic counterpart. Prior research finds that different means of delivery, interface mobility, and customers’ privacy needs affect revenues from location-based marketing differently (Banerjee et al. 2020). Therefore, research and practice should consider different design options, when designing location-based eTPs.\n",
      "\n",
      "F1 also affects three supportive TPs that are of a diversional and interactional nature (cf. Straker et al. 2015). Aside from its potential to reduce the frustration of finding store employees, the likeliness that the surveyed shoppers would use the Messaging TP, which is not bound to a specific stage of the customer journey, was lower on average than twenty of the other eTPs. In an e-commerce context, prior research shows that service quality and customer satisfaction have indirect impacts (i.e., via perceived usefulness and ease of use) on customers’ acceptance of support chats (Elmorshidy 2013). However, customers usually attach more importance to personal contact in BaM retail stores (Schramm-Klein et al. 2007) and prefer C2C interactions over customer-to-employee interactions (Harris et al. 1997). These preferences might explain the lower rating of the eTP in this regard, as an eTP might be seen as impersonal and lacking direct human interaction. Further research could investigate the impact of these preferences in more detail.\n",
      "\n",
      "The Write Product Review TP is the fourth least likely to be used, and the Social Media TP the least likely. However, prior research shows that social media can affect purchase decisions in BaM retail stores. The trust and loyalty of several customer segments are affected by user-generated content differently (Beurer-Züllig and Klaas 2020), so such TPs should not be overlooked. For example, in fashion retail, in addition to perceived usefulness, perceived enjoyment is an essential determinant of customers’ behavioral intentions toward various eTPs, including social media (H.-Y. Kim et al. 2017). Similarly, Weinhard et al. (2017) find that customers’ hedonic motivations have a strong impact on behavioral intentions and that the customers’ willingness to provide personal information is almost as important.\n",
      "\n",
      "In sum, F1 affects stage independent, post-purchase, and pre-purchase TPs that allow customers to create user-generated and consume brand-generated content. F1 could indicate that BaM shoppers are still critical of personalized and intrusive communication (cf. Burke 2002) in a hybrid BaM servicescape and, so they perceive eTPs that enable them to influence other customers as being similar to those that try to influence them through brand-generated content. F1 could also indicate that customers perceive eTPs, which complement the activities along the traditional BaM customer journey, as less useful than those supporting existing activities.\n",
      "\n",
      "The second content-related factor (F5) affects the likeliness that customers will use two functional eTPs that give them access to historical customer data, thus supporting the alternative evaluation and post-purchase stages. Both eTPs received moderate ratings from the surveyed shoppers. The frequency of online shopping had a weak positive impact on the Order History and the Recently Viewed Products TPs, and the latter was also significantly affected by prior BaM-retail-related smartphone use (see Table D.1 in Appendix D.2). Either the shoppers perceived these TPs as less intrusive (cf. Burke 2002) than those affected by F1, or they perceived more advantage from and control over them (cf. Roy et al. 2017). Further research could investigate customers’ perceptions of the collection, presentation, and analysis of customer data in the context of various BaM eTPs in more detail.\n",
      "\n",
      "Considering the survey results and the findings of prior research, BaM retailers should implement non-intrusive promotional and interactional TPs that customers perceive as useful and enjoyable, and that consider their privacy needs. When eTPs use historical data, BaM retailers should consider customers’ perceptions of the eTPs’ usefulness and customers’ control over them.\n",
      "\n",
      "Finally, one factor (F2) is concerned with the terminal as an access medium. On average, the terminal-based eTPs received a lower rating by the surveyed shoppers than their smartphone-based counterparts. Thus, the survey results suggest that customers might prefer using their smartphones to access eTPs in BaM stores. Prior research suggests that mobile shopping technologies facilitate customer-retailer interconnectedness, consumer empowerment, and proximity- as well as web-based consumer engagement (Faulds et al. 2018). However, older customers may still be more likely to favor a terminal or human-mediated eTPs (see Table D.1 in Appendix D.2), as they may be less confident using modern and sophisticated self-service technologies (Dean 2008; Y.-S. Wang and Shih 2009) and may miss human interaction when they evaluate self-service technologies (Dean 2008). Additional research could investigate older customers’ expectations about the media used to convey eTPs.\n",
      "\n",
      "In addition to customers’ age, prior research discusses several reasons for customers’ preference for one medium over another. Similar to the impact of media richness on the fit with a task and the overall choice of a channel (Maity and Dass 2014), media richness, which varies across devices (Rieger and Majchrzak 2018), may affect customers’ perceptions and acceptance of eTP interfaces. The interfaces used to access electronic channels via devices also affect customers’ evaluations of these channels (Wagner 2015). Furthermore, prior research shows that the task-technology-fit affects customers’ utilitarian motivations to use e-commerce (Klopping and McKinney 2004) and their perception of the usefulness, ease of use, and convenience of online channel interfaces (Wagner 2015). Moreover, the type of device in e-commerce affects customer engagement, increases the impact of their perceptions of the risk associated with their purchase decisions (Cozzarin and Dimitrov 2016), and moderates the relationships between their perceptions of the e-business technology’s usefulness and their attitudes toward it (Sumak et al. 2017). According to Natarajan et al. (2018), the type of device moderates the impact of perceived usefulness and enjoyment on the intention to use mobile shopping apps. Similarly, Aloysius et al. (2018) show that the relationship between ease of use of and the intention to use a mobile self-checkout is significant only in a mobile scanning and stationary payment scenario. This finding indicates that the mobility of the medium used to access an eTP in BaM stores could moderate this relationship under certain circumstances. Finally, besides in-store terminals, smartphones, and other digital interfaces (Betzing et al. 2018; Willems et al. 2017), humans can act as mediators of BaM eTPs, as illustrated by the App-Equipped Clerk and the Sales-Floor Checkout TPs. Especially as the orientation of customers toward personal communication and contact is stronger in BaM stores than it is in e-commerce stores (Schramm-Klein et al. 2007), human interfaces for e-service provision should not be neglected. However, Vannucci and Pantano (2019) suggest that customers have more trust in digital TPs than they do in human TPs. While self-service interfaces might reduce the frequency of interpersonal interactions, they provide alternatives to the human service interface and increase the quality of customer-to-employee interactions (Pantano and Migliarese 2014). Therefore, future research could investigate which media is most suitable for accessing specific groups of eTPs in BaM retail stores. BaM retailers, too, should consider the type of media and interfaces when they design eTPs and identify the most suitable options for their customers in their given context.\n",
      "\n",
      "While prior research finds that the evaluation of service offerings is significantly more important for customers in e-commerce settings, it also suggests that there are no differences in the service orientations of BaM and e-commerce customers (Schramm-Klein et al. 2007). Furthermore, in a smart servicescape (Sanjit K. Roy et al. 2019), experience with technology has a mediating impact on customers’ behavioral intentions toward such technologies and their loyalty toward the retailer (Roy et al. 2017). The variables that are known from channel choice and technology acceptance studies in an e-commerce context are also shown to affect the purchase intention in omni-channel environments (Juaneda-Ayensa et al. 2016; Kazancoglu and Aydin 2018; Susanto et al. 2018). Therefore, considering customers’ perceptions of individual eTPs in BaM retail and the determinants of customers’ behavioral intentions toward eTPs along the BaM customer journey has value. Future research could assess the potential of adapting existing theoretical models (e.g., Taherdoost 2018) and research to eTPs in BaM retail stores.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: Conclusion \n",
      "\n",
      "An understanding of customers’ behavioral intentions toward eTPs in BaM retail stores is useful for researchers and practitioners alike, given the increasing number of potential TPs (Lewis et al. 2014; von Briel 2018), more complex omni-channel customer journeys (Barwitz and Maas 2018), and the risks and costs that are associated with the implementation of digital channels and technologies (Karjaluoto and Huhtamäki 2010; Pantano 2014). As empirical research is required to inform theory and promote retailers’ adoption and customers’ intentions toward these TPs, this article makes two contributions:\n",
      "\n",
      "First, the study uses a survey to provide an overview of the likeliness that customers would use BaM TPs that are adopted from e-commerce and conceptually adapted for the use in BaM retail stores. Second, based on an EFA, first exploitative insights on the factors that cause customers’ behavioral intentions toward BaM eTPs are discussed as a foundation for future research. From a managerial perspective, the results inform BaM retailers about issues that should be considered when they implement eTPs. From a theoretical perspective, this article contributes insights about customers’ behavioral intentions toward eTPs in BaM retail stores and suggests taking a closer look at TPs to clarify customers’ acceptance of interfaces and, ultimately, their choice of channel. As the results suggest that customers perceive groups of eTPs as similar in BaM retail stores, this article also guides future research in investigating the eTPs that form such groups simultaneously or treat them in a similar manner.\n",
      "\n",
      "This article’s exploratory multi-method approach comes with caveats and limitations that leave room for further research. First, this study is agnostic to contextual factors of the physical servicescape like the size of the store, the retailer’s assortment, and its location. The survey captured the likeliness that the participants would use dominant eTPs in an online survey based on simple textual descriptions (cf. Aloysius et al. 2018; Inman and Nikolova 2017; Kleijnen et al. 2007) concerned with an abstract BaM store instead of in a prototype-based lab experiment. Thus, the results derived from the generic yet artificial setting of this study should not be transferred to a real-world situation without critical reflection. The eTPs’ relevance to customers might differ based on omitted contextual factors like goods sold or certain store properties. For example, hedonic eTPs might be especially useful in fashion retail (H.-Y. Kim et al. 2017), whereas the usefulness of product information TPs might be related to the complexity of the product sold (Resatsch et al. 2008). Therefore, future research should consider BaM eTPs against the backdrop of different product categories, store sizes, and competitive strategies (e.g., service quality leadership vs. cost optimization) (Porter 1998). While such contextual factors reveal paths for future research, the generic setting of this manuscript’s exploratory multi-method approach, which is independent of such determinants, can be regarded as an unbiased greenfield approach to identifying and investigating potentially useful eTPs.\n",
      "\n",
      "Second, while the textual eTP descriptions allowed customers’ general intentions toward a variety of BaM eTPs to be investigated, the impact of detailed eTPs design characteristics was not taken into account. Future research could evaluate variants of eTP implementations in lab experiments or BaM stores and assess the effect of such design characteristics. By working with real instantiations of eTPs, such studies could integrate the likeliness of customers’ using individual TPs into existing survey instruments. Such studies should also pay attention to the interdependencies among the TPs available in the given scenario by conducting, for example, a conjoint analysis.\n",
      "\n",
      "Third, no a priori assumptions on the TPs’ characteristics were made—instead, a variety of possible eTPs were included—so the identified factors should not be considered collectively exhaustive but as first insights into the determinants of customers’ behavioral intention toward eTPs in a hybrid servicescape that mirrors e-commerce experiences in BaM retail stores. Future work on both TP characteristics in general and their impact on behavioral intentions in BaM retail stores in particular is needed.\n",
      "\n",
      "Fourth, this study took a static view (Kranzbühler et al. 2017) on firm-controlled (Becker and Jaakkola 2020) eTPs in BaM stores. Future research could consider a dynamic, relationship-oriented view (Kranzbühler et al. 2017) to investigate the spillover effects (de Kerviler et al. 2016) between eTPs within and across different customer journeys. Future research could also look into selection and design criteria for BaM eTPs from an organizational perspective (Inman and Nikolova 2017; Kranzbühler et al. 2017) or consider non-controllable eTPs that reside outside company borders (Becker and Jaakkola 2020). In addition, instead of BaM smartphone use and online shopping frequency, future research could investigate the impact of prior experiences with specific eTPs on behavioral intentions in and across various channels.\n",
      "\n",
      "Finally, future research could investigate whether a set of typical BaM eTPs could eventually prevail by using the multiple case study method (Recker 2013) to identify a generalizable dominant design (Suárez and Utterback 1995) of BaM eTPs.\n",
      "\n",
      "In sum, this manuscript lays the foundation for a better understanding of customers’ interaction choices (Barwitz and Maas 2018) in the smart BaM servicescape (Sanjit K. Roy et al. 2019) and offers ample opportunities for further research.\n",
      "\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "TEXT NR: 2 VON https://link.springer.com/chapter/10.1007/978-3-030-49570-1_14\n",
      "----------------------------------------\n",
      "Kapitel:  Abstract \n",
      "\n",
      "The identification of coordinated campaigns within Social Media is a complex task that is often hindered by missing labels and large amounts of data that have to be processed. We propose a new two-phase framework that uses unsupervised stream clustering for detecting suspicious trends over time in a first step. Afterwards, traditional offline analyses are applied to distinguish between normal trend evolution and malicious manipulation attempts. We demonstrate the applicability of our framework in the context of the final days of the Brexit in 2019/2020.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 1 Introduction \n",
      "\n",
      "Social media has become an important infrastructure for modern information sharing and networking. In most developed countries, the majority of people are already connected via one or multiple platforms [6]. Even more important, decision makers like politicians or multiplicators like journalists are also an integral part of social media networks. These groups function as bridge between the social media ecosystem and the offline world outside social media. While politicians try to get in touch with the sentiment of public debates about their programs or decisions, journalists try to pick up stories and use the public sphere as additional outlet.\n",
      "\n",
      "Quite logically, social media has become a central platform for campaigns. Politicians try to reach the public with their ideas, but in contrast to former media types, users can also reach politicians directly. Both can also try to initiate societal debates by placing topics. And when journalists pick up these topics because they seem of critical importance in social media, their reach goes even beyond the boundaries of the social media ecosystem.\n",
      "\n",
      "As such it is of utmost importance not only for journalists but for the whole society to provide some transparency on campaigns in social media. This shall provide insights into the origins of and motivations behind an observed topic: is a campaign organic or orchestrated (automatic as well as human-driven), i.e., who is participating in these campaigns? What means are employed when placing a topic?\n",
      "\n",
      "These questions go beyond the challenge of classifying single accounts as social bots or humans. We have to consider interaction of actors and thus the complete (or a representative sample of the) data stream, which is produced on a social media platform. These analyses do no longer focus on singular accounts or a group of users but on the content produced over time. Clearly, the corpus of data that needs to be analyzed is far too large for human manual inspection. But also classical methods of data analysis are not capable to store all data and process it in real time. Real-time detection of possible campaigns, however, is necessary to not lag behind with analysis, when topics reach critical popularity. At the same time, we still need to verify whether campaigns are organic or artificial. This decision can usually not be made ad-hoc and often needs a deeper, sometimes even forensic analysis of campaign data.\n",
      "\n",
      "In order to address both challenges at the same time, we propose a two-phase framework which supports both campaign and trend detection and a-posteriori in-depth analysis of respective data. Our idea integrates a stream-based unsupervised detection of critical topics and an independent, offline, and extendable analytics environment. This allows to instantly identify upcoming and important topics and subsequently analyze and verify their artificial character. Note that this approach should be considered as a human-in-the-loop support tool, where no automatic decision on a campaign’s quality is made. In principle, it is designed to enable detection and transparent analysis of current topics in many contexts, either the discovery of new and interesting topics or the fight against manipulation via artificial campaigns.\n",
      "\n",
      "The rest of this work is structured as follows: the next section will summarize related research in the context of this work and then Sect. 3 will detail the two-step framework’s concept proposed in this paper. Section 4 shows the application of our framework in the context of the Brexit discussion two months before and at the final Brexit date at the end of January 2020. Finally, Sect. 5 summarizes and discusses the results of our work and provides some future perspectives.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 2 Related Work \n",
      "\n",
      "Social media has been discussed as environment for disinformation, manipulation, or deception for more than a decade [8] and since the Brexit decision in 2016 as well as the election of Donald Trump for president of the United States, social media is considered an important infrastructure for manipulating societies [3, 22]. Much effort has been put into the (computer-aided) detection of automation in social media. Social Bots are considered very potent actors in the distribution of disinformation [10, 11, 14, 18], and consequently, detection techniques for social bots have been (and still are) an important topic of research [9, 10, 13, 20]. While research started with a focus on the classification of single accounts as bots- or human-driven, some recent publications emphasize the importance of detecting collaboration of multiple actors [9, 12]. An exceptionally early proposal was made by Lee [16] already in 2014 to discriminate campaigns into organic and non-organic ones. While the first arises from classic human interaction in social media the latter type of campaigns is promoted by artificial or automated mechanisms or purchased and supported by the social platform [16].\n",
      "\n",
      "Campaign detection started with offline analysis of network data and topologies, the clustering of posted or shared content, and the investigation of topics’ temporal development. All applied techniques and extracted features mainly aimed for supporting or enabling machine learning approaches. More recent detection approaches afterwards focused on the application of machine learning in campaign detection in order to identify characteristic patterns of organic and non-organic campaigns [10, 20].\n",
      "\n",
      "However, there are some major disadvantages of (supervised) machine learning approaches in this context: \n",
      "\n",
      "Models have to be trained using labelled data. Especially for campaigns in social media, this kind of data is usually not sufficiently available. An insufficient data base, however, makes the approaches imprecise.\n",
      "\n",
      "The learned patterns can only capture the characteristics found in available input and learning data. That is, the machine learning approaches may become outdated and inflexible regarding new kinds of orchestrated campaigns.\n",
      "\n",
      "There is some recent work [7, 9, 23] which addresses the application of unsupervised detection methods like clustering and network analysis as solutions to some of the issues. These approaches do not need initial training and can detect unknown characteristics. However, as correctly pointed out in [23], these methods are computationally too complex to handle the observed amount of social media content in real-time.\n",
      "\n",
      "In this work, we pick up a proposal we recently made, i.e. using stream-clustering approaches for topic detection [2] and apply it as a first step in a two-phase analysis process. We propose the augmentation of the detection of campaign candidates with a subsequent analysis phase. In this second phase, previous mentioned established group- or single account analysis can be applied to verify or reject whether a campaign is malicious or not and to possibly detect responsible actors in this campaign. As such, we consider this work as a step towards an integration of modern classification approaches into campaign detection for fast and precise transparency in social media communication.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 3 The Two-Phase Framework for Detection and Analysis \n",
      "\n",
      "In the following, we introduce our two-phase framework for automated campaign detection. The framework is depicted in Fig. 1. Within the first phase, the incoming text data stream (e.g. Twitter stream) is processed into tfidf vectors and aggregated via the textClust algorithm [5]. The algorithm handles text stream data and clusters similar documents together into so-called micro-clusters, which represent the recently discussed topics of the stream. Additionally, a micro-cluster filtering is applied. By this, topics, which behave suspiciously in terms of their development over time, are extracted. In the second phase, these topics can be further analyzed, via numerous metrics and visual representations of text (meta-) data.\n",
      "\n",
      "2-phase framework for analyzing suspicious cluster evolution\n",
      "\n",
      "Stream clustering algorithms apply clustering on potentially unbounded data streams in an online fashion. The fact that the stream is potentially unbounded makes it impossible to store the complete data for calculations [4, 19]. Due to this, observations can be processed only once. As the complete range of the data is not known in advance, the stream clustering algorithm needs to be able to adjust clusters online and in real-time.\n",
      "\n",
      "The stream clustering algorithm can be divided into two phases: In the online phase, micro-clusters are derived directly from the incoming observations. A micro-cluster is an aggregation of observations, which are locally dense. While the concrete observations are discarded after the distance calculations, the clusters are stored as representation of the actual data distribution. In the offline-phase, the respective micro-clusters can be clustered on-demand via traditional clustering techniques. This phase is independent from the online phase and can be scheduled on demand at any point in time. As here only the limited number of micro-clusters, as a representation of the original data is used, the calculations can be done by using the data multiple times.\n",
      "\n",
      "In contrast to incremental clustering algorithms, stream clustering algorithms must be able to deal with the explicit notion of time. The complete range of data is not known at the beginning and the distribution of the stream data may change over time (which is known as concept drift). Therefore, micro-clusters need mechanisms to adapt to changes in the data stream. To simulate a temporal drift, micro-clusters are usually weighted. The weight ensures that clusters, which are not updated by new observations for a while, will be decayed slowly. If the weight falls below a threshold, the cluster is removed completely.\n",
      "\n",
      "textClust: The idea of micro-clusters as representation of stream data was originally designed for numeric data. Nevertheless, the idea can be transformed to textual data as well [1].\n",
      "\n",
      "For our experiments, we use the textClust algorithm [5]. Within the textClust algorithm, the produced micro-clusters mc are represented as 4-tuples:\n",
      "\n",
      "The relative importance of a micro-cluster is reflected by its tokens t (namely most describing words) and its weight w. The weight is increased by 1 each time a new observation is allocated to the cluster. To be able to detect concept-drifts and account for temporal changes, the weight is exponentially decayed at each time step by\n",
      "\n",
      "where \\(\\lambda \\) denotes the fading factor, \\(t_{now}\\) the current time and t the time the specific micro-cluster was last updated. A cleanup procedure is applied every \\(t_{gap}\\) time steps where all micro-clusters below a predefined threshold are removed from the clustering result. The same applies for all tokens within a respective micro-cluster.\n",
      "\n",
      "The term frequency of representative cluster words as n-grams is denoted in the tf vector. Distance calculations between two micro-clusters using the cosine similarity are based on the tfidf vectors. Note, that the tfidf representation extends the traditional term frequency by weighting down words that appear in many documents, as they are considered to be less important. For every new observation, first a new micro-cluster is created and second, the distance to all other micro-clusters is calculated. If the new micro-cluster is in small distance (below a certain threshold r) to one of the existing micro-clusters, it is merged with the respective cluster. Otherwise, the new micro-cluster remains and is added to the set of all micro-clusters.\n",
      "\n",
      "The similarity of two tfidf vectors is calculated via the adjusted cosine-similarity. Within this metric, the average weight of the micro-cluster is taken into account. Therefore, each token (within a certain cluster) is weighted relative to the average weight. Let A and B represent two tfidf vectors from two different micro-clusters. The adjusted cosine similarity between them with their respective means \\(\\mu _A\\) and \\(\\mu _B\\) is then defined as follows:\n",
      "\n",
      "The fourth element within the micro-cluster definition ID captures the post IDs, which relate to the corresponding texts within a cluster. The post ID vector is irrelevant within the clustering phase, but gets important in the second phase of the framework, when suspicious stream data is analyzed in more detail.\n",
      "\n",
      "Micro-cluster Monitoring to Detect Campaigns: A micro-cluster represents a topic discussed in the text stream. Each cluster consists of tokens, which describe the content, as well as a weight, which represents the importance (number of associated text instances) of the cluster.\n",
      "\n",
      "Next to the overall topic monitoring of the incoming stream data, we are especially interested in suspicious stream behavior. The identification of rapidly arising and growing clusters might be of interest in the field of trend or campaign detection. Especially, since we are interested in non-organic campaigns, driven by bots or trolls, the temporal evolution of the campaign can be used as an indication for unusual behavior [21]. Since it is not feasible to manually inspect the complete number of micro-clusters over time, an automated filtering step has to be applied. In an earlier work, we already proposed a method that reduces the number of micro-clusters by focusing on micro-clusters that do exhibit a significant change of weights within the last cleanup procedure [2].\n",
      "\n",
      "In addition to storing only the actual weight w of the cluster, the weight before the last update \\(w_{last}\\) is included for calculating the difference \\(\\varDelta _w = w - w_{last}\\) within tgap cluster updates. Based on this, the average weight change \\(\\mu _w = \\frac{\\sum _i{\\varDelta _{w_{i}}}}{k}\\) of all micro-clusters k, as well as the respective standard deviation \\(\\sigma _w = \\sqrt{\\frac{1}{k-1}\\sum _{i=1}^{k} (\\varDelta _{w_i} -\\mu )^2}\\), can be computed. The Chebyshev’s inequality is used to determine clusters with unusual weight patterns [17]. The inequality states that:\n",
      "\n",
      "where X is a random variable with expected value \\(\\mu \\), standard deviation \\(\\sigma \\) and t any positive number. To ensure a feasible amount of clusters to (manually) analyze in a second step, we chose \\(6 \\sigma \\) \\((t=6)\\) as threshold. The parameter setting can be adjusted depending on the context, as well as the underlying data. With this parameter setting about 3% of the micro-clusters are selected for further analysis, which is (in this case) a suitable amount for further investigations. The set of clusters of further interest I is thereby defined as:\n",
      "\n",
      "Within the first phase of the framework, textual stream content is clustered and suspicious cluster evolution is filtered online and in real-time. In a second offline phase, suspicious clusters can be further examined. Here, all kinds of (computationally) expensive analyses can be applied. On the one hand, the micro-cluster content can be examined by the help of the stored cluster tokens. On the other hand, the user is able to gather meta-data via the ID vector of the suspicious micro-cluster. As the ID vector captures all post IDs of the respective cluster, the Twitter REST API can be used to extract post meta data, e.g. the author ID or name. Further, meta data about the author can be gathered simultaneously. With the meta data the user is able to enrich the underlying data enormously. Especially for the detection of non-organic campaigns, further information about the human user is indispensable.\n",
      "\n",
      "Authors of a micro-cluster can be analyzed regarding the age of their accounts, their post behavior, as well as their number of followers and followees. In the second phase of the micro-cluster analysis, visual representations can help to identify non-normal behavior. A dashboard can extremely help to visualize underlying structures in data and meta data of the post and accounts. Exploring e.g. the number of distinct accounts responsible for a micro-cluster, or checking the average age of the accounts, could help to identify social bots.\n",
      "\n",
      "Furthermore, established bot detection methods can be applied. A well-known example for a bot detection method, which could be easily applied when the author ID is known, is the Botometer approach [20]. This tool gives an indication, whether an account is presumable steered by a human or a bot, by taking several meta data into account. Applying algorithms like the Botometer in the second phase of the framework can help to give an impression of the origin of the campaign and may help to detect non-organic campaigns.\n",
      "\n",
      "Dashboard prototype to evaluate micro-cluster trends in the second phase\n",
      "\n",
      "In this work a first prototype of our dashboard is used for evaluation purposesFootnote 1 (see Fig. 2). We only rely on simple offline metrics which can be directly extracted from the tweets gathered during our experiments. Within the dashboard a variety of data and meta data can be visualized. For a first setting, we implemented figures and metrics representing the number of distinct accounts, the age of the accounts, such as the number of followers, and the percentage of verified accounts contributing within the specific topic. Further, we show how many an which posts are contained in this cluster at which point in time. This list is not exhaustive and can be complemented and customized. Up to now, we do not utilize additional supervised methods such as Botometer and leave this open for future research.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 4 Case Study and Evaluation \n",
      "\n",
      "In this work we exemplary demonstrate our framework in the context of the Brexit movement. Fur this purpose, we collected Twitter data by utilizing the platform’s Streaming API. Twitter proclaims that the API provides \\(1\\%\\) of the global traffic produced by the platform. Preliminary experiments showed that by filtering specific hashtags (in this case we only filter out tweets containing the term Brexit), we are able to obtain almost a complete conversation history [7]. More precisely, we collected data in late 2019, before the Brexit (between 20th and the 27th of November) and on the actual Brexit day on the first of February. We explicitly removed retweets from our analysis since we want to identify trends only based on original content excluding simply exaggerated trends based on retweet cascades [15]. In total we gathered roughly 1.3 million tweets, which were clustered by our textClust algorithm.\n",
      "\n",
      "As specified in Sect. 3.1, the textClust algorithm requires some parameters that have to be set in advance. Especially \\(\\lambda , r\\) and \\(t_{gap}\\) do highly influence the final clustering result. The \\(\\lambda \\) parameter affects how fast micro-clusters fade out over time and is thus responsible for the overall lifetime of a topic. While a small value ensures that micro-clusters, which are not frequently updated, are not immediately discarded from the set of all micro-clusters, a larger value dismisses them rigorously. Also, \\(t_{gap}\\) influences which clusters are discarded since a larger value leaves more time for potential micro-cluster updates (and cleaning). The distance threshold r affects the granularity of micro-clusters. While a large value merges tfidf vectors which are not necessarily very similar to each other (and therefore may represent different topics), a small value only merges sentences which are almost identical. The choice of suitable parameters does highly depend on the underlying data set. Therefore, we cannot rely on best-practice parameter settings. In context of our data set we systematically tested different parameter combinations. We found that \\(\\lambda \\) also influences the number of identified trends. Since the Brexit day itself was very popular on Twitter with more than one million Tweets only on that day, we set a higher \\(\\lambda \\) in this scenario. Therefore we decided to set \\(\\lambda \\) to 0.001 (November) and 0.002 (Brexit day) respectively. We set \\(t_{gap}\\) to a fixed value of 100 and specified the distance threshold rather generously as 0.6. For all our experiments we used term-fading (fading according to elapsed time and not number of observations) to compensate variances in the stream throughput due to day/night cycles.\n",
      "\n",
      "Large micro-cluster that emerged from promoted Twitter campaign\n",
      "\n",
      "A quantitative evaluation of our approach is almost infeasible due to missing ground-truth data. In this proof-of-concept analysis we show that our framework is actually able to detect trending content within the Twitter stream. When we inspected the filtered micro-clusters from the data gathered between the 20th and the 27th of November, we identified one micro-cluster which exhibits a significantly higher cluster weight than all other ones (see Fig. 3). Consequently, we inspected this micro-cluster more in-depth, utilizing our Dashboard prototype. In total 1900 Tweets are assigned to that specific micro-cluster, with 1850 unique users. This implies that this unusual peak cannot be explained by single spamming accounts. However, we found that the message which was tweeted by all these different accounts is always exactly the same, motivating people to vote for the Conservative party to get the Brexit done (see Fig. 4). It has to be again emphasized that we explicitly excluded retweets from our clustering. Therefore, the observed phenomenon is an unusual distribution pattern. Since we have access to the original Tweet IDs, we inspected the Tweet more in detail. Interestingly, each of the Tweets in question consists of an additional button by which people are able to easily share the same content on their profile (via a new original Tweet) with one click. Further investigation revealed that this so-called call-to-action button is one feature of Twitter intended for businesses to reach their customers. Surprisingly, this feature also seems to be used in political context and has significant impact on the global conversation stream of that topic. Despite the high cluster weight, the trend lasted only a few hours and completely faded out afterwards.\n",
      "\n",
      "Call-to-action button for promoted tweets\n",
      "\n",
      "While our filtering approach during the first phase drastically reduces the number of interesting micro-clusters, it is not guaranteed that all of them do exhibit non-organic trends that should be classified as malicious. In context of the actual Brexit day (first of February 2020), we exemplary show how normal evolving trends can be distinguished from non-organic ones and how the second phase of our framework supports this differentiation. Within Fig. 5, we display three micro-clusters which all represent different topics that were discussed on Twitter that day. The blue trace represents a micro-cluster, containing tweets where users simply wished a happy Brexit day (similar to birthday wishes). As it can be inspected in the Figure, the trend (increase of the micro-cluster weight) started approximately at 8:00 AM with its peak 15 min later. This is not surprising, since it simply reflects that people started posting about the Brexit after they woke up (at nighttime the tweet throughput is significantly smaller than during the day). After the peak of the micro-cluster it slowly fades out until the end of the day, implying that the throughput of newly arriving tweets decreases over time. The green trace corresponds to a micro-cluster that summarized tweets about the first two cases of the corona virus in Britain which coincidentally happened at the same day. Again, the micro-cluster was created and immediately increases in it’s weight. Afterwards, similar to the Happy Brexit micro-cluster, the weight is slowly faded out during the day. The last micro-cluster established at 13PM and captures tweets about Putin which subliminally imply his involvement in the Brexit and that he finally wins. In contrast to the other two clusters, we observe a sharp weight edge with rapid fading after peaking.\n",
      "\n",
      "Organic and non-organic micro-cluster trends at the Brexit day (Color figure online)\n",
      "\n",
      "While the first cluster is an appropriate example for an organic trend that naturally arose due to the topic relevance, the last two both are not easy to interpret, since they contain controversial content that may originate from targeted opinion manipulation. Again, we utilized our Dashboard prototype to inspect those micro-clusters more in-depth. The corona virus cluster in total consisted of about 300 tweets. All tweets were posted by different authors who mainly originate from the UK. Also, the actual content of the tweets differed from each other. Although the term corona virus was always included in the tweet, the wording was always different. However, most tweets embedded an external URL, which linked to a BBC article which was published one day beforeFootnote 2. Using these insights, we conclude that the corona virus trend evolved also in an organic manner and was triggered by the newspaper article. Lastly, we inspect the cluster about Putin. Here, we observe completely different meta-data: First, all of the 320 tweets that were assigned to that cluster only originated from 60 accounts. Further inspection of the different users revealed that 124 tweets (almost \\(40\\%\\) of the cluster tweets) were produced by one single account. The message which was posted by that account was always the same. The only difference was that each tweet mentioned different political individuals. Hence, we deduce that this micro-cluster resulted from a dedicated spamming attack by one single account. For crossvalidation, we used the Botometer service to check whether this specific account can be classified as a bot (automated program). Although the content score is slightly higher than average, Botometer classifies the account as human. However, as we already stated in preliminary work, the Botometer system can be fooled and it is furthermore not of the uttermost importance to identify whether an account is automated or not. The overall goal should be the identification of malicious coordinated campaigns, executed by humans or non-humans [12].\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 5 Discussion and Future Work \n",
      "\n",
      "In this work we proposed a new two-phase framework that is capable of identifying artificially created and organic trends on social media stream data. By utilizing unsupervised stream clustering combined with an additional filtering approach, we can circumvent the problem of missing ground-truth data during the first online phase and simultaneously reduce the amount of unimportant data that has to be inspected manually. Within a second offline phase, we use meta-information that was persisted to secondary memory during clustering to get additional insights into the cluster contents. Within a Dashboard prototype the information is aggregated to valuable KPIs. Our experiments show that our framework is capable of identifying different types of trends. Ranging from simple spammers to coordination via multiple accounts, we revealed organic and non-organic trends that highly affected the overall discussion about the Brexit. We realize that the second offline step is necessary to get reliable insights regarding the type of trend and to verify or reject whether a campaign is malicious or not.\n",
      "\n",
      "While we currently only employ simple aggregation metrics within the second phase of our framework, there is a lot of room for applying additional, more sophisticated analyses such as the identification of user networks. Upcoming research should also focus on optimal parameter configuration. Ideally, parameters should be automatically adjusted during the online phase. The insights from different cluster evolution can also be used to produce ground-truth data within a semi-supervised setting. Via the cluster filtering method, information of suspicious post development and account meta data is gathered. After validation, this data might serve as ground-truth in supervised campaign detection approaches.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel:  Notes \n",
      "\n",
      "A python implementation of textClust and the corresponding dashboard can be downloaded here: https://textclust.com/.\n",
      "\n",
      "The article can be accessed here: https://www.bbc.com/news/health-51325192.\n",
      "\n",
      " \n",
      "\n",
      "----------------------------------------\n",
      "TEXT NR: 3 VON https://link.springer.com/book/10.1007/978-3-642-22531-4\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "TEXT NR: 4 VON https://link.springer.com/chapter/10.1007/978-3-030-06234-7_27\n",
      "----------------------------------------\n",
      "Kapitel:  Abstract \n",
      "\n",
      "Emerging technologies like Artificial Intelligence (AI) show the potential to contribute significantly to the digitalization of supply chains. Nonetheless, the question which approaches from the field of AI are applied within supply chains as well as which supply chain problems or tasks are addressed with AI approaches has not been answered by scientific literature yet. Based on a structured literature review this paper aims at providing an answer to these questions. A special focus is given to the application areas for recognition approaches in supply chain execution, for which this paper provides an overview of those areas research is currently focusing upon.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 1 Introduction \n",
      "\n",
      "The development of new technology has always been a driver of change. Nowadays, higher computing power, more data storage and process capabilities etc. allow for new technology- and data-enabled business models, such as online retailers or mobile app service providers (Emenike, Eyk, & Hoffman, 2016).\n",
      "\n",
      "Emerging technologies such as the Internet of Things (IoT) or big data analytics are also changing the way supply chain management (SCM) is done and have the potential to create a digital supply chain, which can be understood as a “flexibly interconnected, complex, distributed system based on a continuous and autonomous exchange of data and information between human actors and physical, technical objects” (BVL, 2017b). Apart from the already mentioned technologies, especially methods of so-called Artificial Intelligence (AI) are expected to contribute to the digitalization in SCM. In general, the application of AI techniques to not only analyze data or automate decision-making but also to optimize the whole supply chain is considered to be highly relevant and an enabler for a supply chain’s digital transformation (BVL, 2017a). Nonetheless, the question on what exactly AI is and which methods do belong to the set of AI techniques remains and has not been answered by scientific literature yet. Instead, the term AI is viewed and defined from different angles focusing e.g. on “agents that receive percepts from the environment and perform actions” (Russell & Norvig, 2010) or on “computational systems that perform tasks commonly viewed as requiring intelligence” (Poole & Mackworth, 2017). It can be subsumed, that there is no common definition of what AI is. Moreover, the understanding of “intelligent” has been changing over the years, which is described by the AI effect. It describes the circumstance that the notion of AI changes due to advancements in the field as well as the emergence of new technologies. If something a computer can do becomes common enough that a majority of the people are used to it, it is no longer considered as AI (McCorduck, 2004). So while approaches such as genetic algorithms or expert systems are no longer considered to belong to the set of AI techniques anymore, recent progress in the fields of information processing or sensing technology as well as the shift to a data-driven paradigm have led to major advances in the field of AI such as deep learning, reinforcement learning, robotics, computer vision or natural language processing (Stone et al., 2016).\n",
      "\n",
      "Therefore, it is necessary to answer the questions which approaches from the field of AI are applied within the SCM domain as well as which SCM problems or tasks are addressed with AI approaches.\n",
      "\n",
      "A first answer to these two questions has already been given based on the results of a structured literature review being presented at the 9th International Scientific Symposium on Logistics (ISSL).Footnote 1 A summary of the methodology and how it has been applied are described in Sect. 2. The results are summarized in Sects. 3 and 4.\n",
      "\n",
      "While working on these questions, an interesting point has been noticed: Despite problems of object or image recognition are rarely discussed in the investigated scientific literature, they are considered as a suitable AI application possibility especially for supply chain execution. This observation led to the idea to extend the previously mentioned results by specifically searching for literature dealing with this approach/task combination. Hence, this paper aims at answering the following question:\n",
      "\n",
      "What are currently researched application areas for recognition approaches in supply chain execution?\n",
      "\n",
      "This paper aims at providing an overview of which areas within supply chain execution research is most interested in, i.e. which application cases are already existent. This knowledge might then be used as a basis for further research in order to e.g. identify more promising application cases.\n",
      "\n",
      "Section 5 describes the way the search to deepen the initial results of the already existing paper has been done and which application areas and cases could be identified. The paper is closed with a conclusion summarizing the presented work and its most important implications as well as shortly discussing limitations and future research possibilities.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 2 Methodology \n",
      "\n",
      "A structured literature review (SLR) has been utilized to identify (i) which AI approaches are applied within the SCM domain and (ii) which SCM problems or tasks are addressed with these. SLRs aim at creating rigorous research and at making the reasoning process, which has led to results presented later on, more understandable and comprehensible. The SLR presented in this paper has been based on the framework by Thomé et al. (2016) who propose a step-by-step guideline on how to ensure a rigorous literature search.\n",
      "\n",
      "Before conducting the actual SLR, a first initial literature search has been carried out in order to identify which AI approaches are used in the SCM domain, using the very general search term “artificial intelligence” AND (“supply chain management” OR logistics) within the databases of Sciencedirect, Web of Science and Scopus. After the elimination of duplicates two people evaluated the abstract of the 1366 remaining sources independently and if at least one of those regarded a paper as relevant based on this evaluation, it has been included in the following process.\n",
      "\n",
      "After analyzing the remaining 231 publications, five major approach-groups have been identified: (1) metaheuristics, (2) machine learning, (3) multi-agent systems, (4) recognition and (5) natural language processing. The analysis showed a strong bias towards the first group, the application of metaheuristics such as evolutionary algorithms, ant or bee colony optimization or particle swarm optimization. More than 50% of the relevant sources used an approach from this group to address a SCM problem, especially from the area of transport planning. However, the question whether metaheuristics do belong to the set of AI approaches is still discussed in research and there is no definite answer. Moreover, the high number of sources, which mainly stem from the earlier of the considered years, as well as some existing reviews (e.g. Griffis, Bell, & Closs, 2012) show that the application of metaheuristics to the SCM domain is not a new and already well researched field. Therefore the decision to exclude the group of metaheuristic approaches from the further review has been made.\n",
      "\n",
      "The remaining four approach groups have been transformed into new approach-specific search terms in order to conduct the SLR:\n",
      "\n",
      "(“machine learning” OR “self-learning” OR “neural network” OR “support vector machine”) AND “supply chain”\n",
      "\n",
      "“natural language processing” AND “supply chain”\n",
      "\n",
      "(“image recognition” OR “object recognition”) AND “supply chain”\n",
      "\n",
      "((intelligen* OR smart OR knowledge OR reasoning) AND agent) AND “supply chain”.\n",
      "\n",
      "The search and review has been conducted in accordance again with the framework presented by Thomé et al. (2016). Out of 630 hits after removing duplicates, a final set of 153 relevant sources remained after abstract and full-text review. These have been analyzed with regard to the questions which approach they apply and which problem they address with it. A synthesis of the results is presented in the next sections.\n",
      "\n",
      "In order to address the application of recognition approaches specifically for supply chain execution in more detail, a second literature search has been conducted. However, this has not been following a framework for a structured literature review but a more “try-and-error”-focused approach has been used.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 3 Applied AI Approaches \n",
      "\n",
      "In scientific literature numerous different AI approaches are used. The number is even increased, since many researchers adapt known algorithms to their needs and publish this variation with a new name. To provide a better overview the classification scheme based on Poole and Mackworth (2017) and Russell and Norvig (2010) has been used. Table 1 provides an explanation and examples for each class as well as an indication of how many of the sources identified as relevant in the literature search do belong to this problem class. The percentages are not only based on the sources identified in the SLR but also include the ones from the literature search focusing on recognition problems in supply chain execution (for more detail on this search cf. Sect. 5). Hence, the percentages differ from the ones presented in the ISSL paper and a higher proportion of the sources can now be attributed to the recognition problem class.\n",
      "\n",
      "In general, independent from the problem class, variants of neural networks are with 58% the by far most applied AI approach. Such networks consist of one input layer, one output layer and at least one hidden layer between them. The majority of identified sources utilizes so called deep learning for their neural networks, i.e. the networks possess many hidden layers which allows them to process greater amounts of and more complex data in shorter time. This composition of many layers allows neural networks to learn very complex functions (LeCun, Bengio, & Hinton, 2015; Poole & Mackworth, 2017). Moreover, many authors show that neural networks outperform other approaches with regard to e.g. solution quality or convergence speed towards a good solution (e.g. Aengchuan & Phruksaphanrat, 2018; Ma, Wang, & Wang, 2018). Neural networks are mostly used to solve prediction, classification/clustering, optimization, recognition or NLP problems. The second-most used approach, multi-agent systems (MAS), is applied for knowledge representation and reasoning problems. In a MAS, different agents follow their individual goals and strategies. Based on these they perform actions and propose different solution alternatives, which are often presented to a human decision maker who is responsible for the final decision.\n",
      "\n",
      "Considering the different problem classes, it becomes obvious that the majority of sources uses AI approaches to predict something, e.g. customer demand (Watanabe et al., 2016) or supplier performance (Mirkouei & Haapala, 2014). Therefore, a strong suitability of AI approaches to solve prediction tasks can be concluded. The same holds true for classification/clustering as well as knowledge representation and reasoning problems. The amount of sources considering these problem classes is lower than the ones for prediction problems but still a considerable number of sources deals with these categories. An example from the classification class is presented by Ye, Xiao, and Zhu (2015) who classify companies according to which supply chain disruptions they can expect. Knowledge representation and reasoning problems dealt with by scientific literature are e.g. the analysis of the effects that information sharing has on supply chain performance (Ponte, Pino, & La Fuente, 2014).\n",
      "\n",
      "Rather rarely approached problem classes are optimization, recognition and natural language processing (NLP). However, especially the two latter ones should not be considered as unsuitable since recent sources show high potential for applications in the SCM domain e.g. for food quality recognition (Cavallo, Cefola, Pace, Logrieco, & Attolico, 2018), or the analysis of documents to automatically derive information such as failure predictions (Aqlan & Saha, 2015). Also the area of warehouse automation is considered as highly relevant for AI applications. For example, Thamer et al. (2018) examine application possibilities of deep learning in this field and present a way to increase the intelligence of a forklift within a dynamic warehouse environment to make it able to recognize people.\n",
      "\n",
      "Overall, it can be subsumed that variants of neural networks are clearly the most utilized AI approach in the SCM domain. These are used to not only solve regression and classification but also optimization, recognition and NLP problems. The second-most used technology, MAS, is mostly applied to reasoning problems to better understand a system or estimate the effects of certain strategies or actions. While SVMs are also more or less frequently applied, other methods such as decision trees, fuzzy reinforcement learning or named entity recognition are only considered by a minority of the sources.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 4 Addressed SCM Task \n",
      "\n",
      "It is also possible to classify the different sources according to which SCM problem or task they are applying AI approaches to. Fleischmann et al. (2005) provide a good overview of SCM planning tasks in their Supply Chain Planning Matrix and depict them along two dimensions: the planning horizon (long-term, mid-term, short-term) and the type of supply chain process (procurement, production, distribution, sales) (cf. Fig. 1).\n",
      "\n",
      "Supply chain planning matrix (Fleischmann et al., 2005)\n",
      "\n",
      "However, the matrix solely focuses on planning tasks and hence had to be extended to also depict tasks from supply chain execution as well as ones providing support along the supply chain, e.g. performance evaluation. The tasks mentioned in Fig. 1 as examples for each class are quite general and their configuration depends on the specific situation at hand. However, they give a good overview of the various kinds of tasks which are part of SCM.\n",
      "\n",
      "Table 2 gives an overview of the percentage of relevant sources dealing with the tasks of the extended supply chain planning matrix. Again, the sources from the literature search focused on recognition problems in supply chain execution have been considered when calculating the percentages. Therefore, the number of papers dealing with execution has increased when compared to the first investigation.\n",
      "\n",
      "The top three application areas within SCM are—at least according to scientific literature—long-term planning, mid-and short-term sales planning as well as execution. Sources of the category long-term planning typically deal with supply chain or network configurations. Usually variations of neural networks are applied to e.g. predict the capability of a supply chain to fulfill all customer orders (Silva, Ferreira, Silva, Magalhães, & Neto, 2017) or multi-agent systems are used to e.g. examine the influence of different communication and collaboration strategies on SC performance (Medini & Rabénasolo, 2014). Another area is focusing on supplier selection and evaluation, for example in agricultural supply chains (Guo & Lu, 2013) or to estimate a supplier’s resilience capability (Hosseini & Khaled, 2016).\n",
      "\n",
      "Mid- and short-term planning is dealt with by 41% and among the different functions, mid- and short-term sales planning is the most prominent one. All sources from this task category aim at forecasting demand for hard to forecast products such as blood transfusions (Khaldi, El Afia, Chiheb, & Faizi, 2017) or at improving demand forecasts by incorporating external information such as weather data (Watanabe et al., 2016) or social media information (Cui, Gallino, Moreno, & Zhang, 2017).\n",
      "\n",
      "The third task category having received lots of attention from research is supply chain execution. Here, two different tasks show a high occurrence among the identified sources: First, supply chain monitoring e.g. for cold chain transports (Emenike et al. 2016) and second, automated warehousing and production encompassing tasks such as the development of an automated ordering management system (Mortazavi, Arshadi Khamseh, & Azimi, 2015).\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 5 Recognition Approaches for Supply Chain Execution \n",
      "\n",
      "As mentioned before, the number of sources applying AI approaches to recognition problems has been surprisingly low in the SLR presented in Sect. 3. Especially after looking at the tasks AI approaches are applied to both in research and industry the impression of a high suitability for applications in supply chain execution has been strengthened. Many sources apply neural networks and support vector machines to address recognition problems from the area of supply chain execution and report realizable benefits such as high accuracy in recognition (Schlüter, Niebuhr, Lehr, & Krüger, 2018) or the possibility to deal with external factors such as lightning or weather conditions when recognizing objects from camera images (Huang, Li, Chen, Zhang, & Lang, 2017).\n",
      "\n",
      "In order to identify more sources dealing with this apparently promising area, the literature review presented before has been complemented by a further search process. Instead of following another structured approach, publications specifically dealing with the topic of interest have been searched with a few different methods. First, further databases, namely IEEE Xplore and Google Scholar have been queried with the search term (“image recognition” OR “object recognition”) AND “supply chain” which has already been used in the SLR presented before. Having talked to experts from the field of robotics it became imminent that the conducted search focuses on SCM-domain-oriented databases and e.g. neglects ones indexing more technology-focused journals and conferences. Therefore an extension of the set of databases has led to a few more relevant results. Additionally, the set of utilized keywords for the search term has been adapted several times. For example, the term “logistics”, which was dropped as a search term in the first literature review due to it causing many false positive results, has been re-introduced since the overall number of results for this very specific search has been low enough for a manual identification of false positives. Furthermore, once a promising application area such as warehouse automation has been identified this keyword has been utilized to detect more sources from this area and give an indication on whether the perceived relevance can be supported. It has to be noted that the search process has not been extensive and has not been capable to detect all relevant sources. Instead, once an area has been identified as suitable for the application of AI approaches, i.e. a few sources doing so have been found, no further publications have been looked for. Since the purpose of this focus-section is to give an overview on possible and promising application fields and not to identify all possible applications, it has been regarded as sufficient to provide a set of examples for each of the fields. However, due to the non-structured search process this section cannot and does not want to claim to be comprehensible. Since the search was conducted more or less on a “try-and-error” basis and further results were retrieved based on initial ones, it of course is possible that important application areas have been missed. Nonetheless, this way it is possible to get a first impression on where many applications are already existing. And since the search process has mainly been based on sources initially identified in the SLR presented before it is considered as unlikely that major areas have been missed.\n",
      "\n",
      "In the following the identified areas, where applications of AI approaches to address recognition problems in supply chain execution are already existent, are presented and examples for such applications are given. The information as well as the example cases are taken both from research and industry.\n",
      "\n",
      "Warehouse automation is one of the highly researched fields for the application of AI recognition approaches. Not only research but especially industry is interested in using advances in AI as well as robotics to automate typical warehouse operations such as bin picking. Amazon even has organized a “bin picking challenge” to encourage teams from different universities etc. to let their solutions for picking robots compete against each other (for a summary of the first Amazon Picking Challenge and lessons learned from it, compare Correll et al. 2018).\n",
      "\n",
      "The design of picking robots seems to be a highly interesting topic and numerous researchers deal with different aspects of these robots. One of the most important ones is enabling the robot to recognize the objects it is supposed to pick. Usually this is realized by applying a machine learning algorithm trained with and learning from example images. Typical setups of a bin picking robot are stationary and include a robot arm with a gripper that detects objects based on a 3D sensor and plans its motions accordingly (Nieuwenhuisen et al. 2013). To extend this scenario and make the robot more flexible with regard to its operation space Holz et al. (2014) and Nieuwenhuisen et al. (2013) propose a complete system with a mobile robot capable of active object recognition and also grasp planning. Previous to the operation, the robot learns object models that represent objects in graphs depicting compounds of primitive shapes and contours such as cylinders. Having been trained, the robot is able to recognize objects by detecting parts of the graph to be looked for in the captured scene, e.g. detecting a single screw in a transport box filled with several screws or even other objects. The presented approach shows a robust behavior “even in the presence of noise, occlusions, erroneous measurements and missing information” (Holz et al., 2014).\n",
      "\n",
      "Laskey et al. (2016) also propose a picking robot which is capable of picking objects even when access to it is blocked by other object, i.e. grasping in clutter. They iteratively train the robot based on humans demonstrating the picking actions and giving direct feedback to the robot on its current policy. Moreover, a hierarchy of supervisors is used in order to decrease the amount of human demonstrations needed for the robot to learn to pick objects amid clutter. On the first stage, the robot learns from a simple motion planner that ignores the obstacles, i.e. other objects, when grasping the desired object. Then crowd-sourced human workers are used as supervisors on the second stage and finally, an expert from the field of robotics is supervising the robot. With this approach it is possible to achieve a reliability of 90% (Laskey et al., 2016). Another example for the utilization of AI approaches to address recognition problems in a warehouse setting, resp. in the context of picking, is provided by Mo and Lorchirachoonkul (2016) who present a way how to automatically detect which item has been picked and what has been done with it by capturing the worker’s physical interaction and gestures within the picking environment with an array of 3D cameras.\n",
      "\n",
      "However, not only bin packing is addressed with AI approaches. Similar robots resp. approaches to enable them to recognize objects can also be applied to the problem of automatic container unloading (Uriarte, Thamer, Freitag, & Thoben, 2016). For example, Stoyanov et al. (2016) propose a robot to automatically unload coffee sacks. Uriarte et al. (2016) additionally propose the so-called “celluveyor”, a modular conveying system which can be utilized to automate the flow of material in a warehouse.\n",
      "\n",
      "The provided examples show, that especially when combined with advances in robotics and other technologies, AI approaches to solve recognition problems are capable of automating many warehouse processes. This indicates a high potential for the application of AI. However, DHL for example states that only 5% of today’s warehouses are automated (DHL, 2016). This number shows that the available potential still has to be realized.\n",
      "\n",
      "This category subsumes applications supporting people in their every-day operations for example in manufacturing or transport. For example, Sharma et al. (2018) utilize a neural network to automatically parse geographical addresses. This supports the delivery process of mails and parcels which is of high relevance especially due to the increasing amount ordered due to e-commerce etc. The special challenge with regard to addresses is that they exist in various formats and an approach to recognize important parts such as the street name therefore has to be able to deal with this high variety. A neural network is proposed that is capable of extracting individual fields from an address in raw text format and provide a standardized representation (Sharma et al., 2018).\n",
      "\n",
      "Support can also be provided in manufacturing. Longo et al. (2016) develop a system that is equipped with a neural network to process human voice and is able to recognize what the user is currently doing, e.g. which parts are currently handled. Based on this information the system is able to answer questions and give information relevant and suited for the situation and problem at hand. Other applications to support manufacturing operations are e.g. the automatic detection of counterfeited electronic parts to avoid their assembly and possible resulting issues (Frazier, Gilmore, Collins, & Chouika, 2016) or the automatic detection of parts to remanufacture, i.e. to recognize parts which can and which cannot be used further (Schlüter et al., 2018).\n",
      "\n",
      "Another example for how to support actions happening on an everyday basis is provided by Tuszynski et al. (2013). They apply a deep learning neural network to analyze so-called container manifest, documents stating which goods are in a container, and the corresponding container. Radiography images are taken of the container and based on that containers with loads inconsistent from their manifest can be detected.\n",
      "\n",
      "As said before, these are the areas which have been identified as promising application fields of AI recognition approaches in supply chain execution. While the list of classes or examples is certainly not comprehensive, it still is able to give an impression on what has already been developed in this field and provide ideas on where possibly to look at for further applications.\n",
      "\n",
      "Overall, it also needs to be noted that major advances concerning approaches such as deep learning, robotics and computer vision—as already mentioned in the introduction—have just been made and are a requirement for successful applications. Therefore, much more can be expected for these problem classes in the future.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel: 6 Conclusion \n",
      "\n",
      "In summary, the paper aimed at giving a short overview on the most interesting AI approaches and the SCM tasks most often addressed in research. Furthermore, a focus on the application of recognition approaches for tasks from supply chain execution has been set.\n",
      "\n",
      "Looking at results from scientific literature, the main implication that can be derived is that there is a high variety of AI approaches and there are many problems in SCM and logistics to be tackled with AI successfully. Regarding the applied approaches it is obvious, that—while research shows a high variety of them—machine learning in general and neural networks specifically are the by far most applied method. Interestingly, the number of sources dealing with recognition problems is still rather small, but by specifically looking for more examples from this area, it became obvious that there is a great suitability for applying AI to solve issues regarding recognition, especially in supply chain execution.\n",
      "\n",
      "However, research still mainly deals with developing or improving algorithms and not with actually applying them in a real-world setting. There is only a limited set of pilots or specific real application scenarios. Most publications test their approach on a dataset based on e.g. simulations or bench-mark data. Moreover, organizational, process- and human-related issues are rarely discussed. This connects to a more general issue. The identified sources mainly do not report on the process on how to identify good and promising application cases nor on how to choose a suitable approach and implement it. Publications show a focus on applying an AI approach to a given problem but in order to receive a successful solution, it is first necessary to estimate how suitable an application case is. Only this way, the chance of success can at least be increased and the possibility to fail with applying AI can be lowered. Since this aspect has so far not been considered by any of the identified sources, it is a good opportunity for future research.\n",
      "\n",
      "While the paper aimed at basing the results on a structured and understandable way, it cannot claim to be comprehensive. Especially, the chapter focusing on recognition and supply chain execution only can provide an introduction to possible applications. Nonetheless, the goal to give a first idea on suitable application cases and raise awareness on how SCM has so far benefited from is considered to be achieved successfully. Therefore the presented applications classes (warehouse automation and operations support) can be regarded as a starting point for more research on utilizing recognition approaches for supply chain execution. In the future it could be possible to identify more application cases within these classes or examine more supply chain execution problems regarding their suitability for applying AI. Since the technologies enabling the utilization of new and more enhanced AI approaches are developed further, the set of application cases can be expected to also increase and broaden in the future.\n",
      "\n",
      " \n",
      "\n",
      "Kapitel:  Notes \n",
      "\n",
      "https://www.bvl.de/issl.\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for bs, url in zip(springer_soups, springer_links):\n",
    "    print('----------------------------------------')\n",
    "    print(f'TEXT NR: {i} VON {url}')\n",
    "    print('----------------------------------------')\n",
    "    text = get_full_text(bs, url)\n",
    "    if text is not None:\n",
    "        for chapter in text:\n",
    "            chapter_name = chapter['chapter_name']\n",
    "            chapter_text = chapter['chapter_text']\n",
    "            print(f'Kapitel: {chapter_name} \\n')\n",
    "            print(chapter_text)\n",
    "            print('\\n \\n')\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### References\n",
    "Springer often provides Google Scholar links as well"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [],
   "source": [
    "def get_references(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the information of the references of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Returns a list of dictionaries with the reference text and the Google Scholar link (if existing) in th form of\n",
    "    {'text': 'reference text', 'link': 'link to Google Scholar'}\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "\n",
    "    references = []\n",
    "    try:\n",
    "        reference_items = bs.find_all('li', class_='c-article-references__item')\n",
    "    except:\n",
    "        return None  # No references found\n",
    "    for item in reference_items:\n",
    "        reference_text = item.find('p', class_='c-article-references__text').text\n",
    "        try:\n",
    "            gscholar_link = item.find('a', {'data-track-action': 'google scholar reference'}).get('href')\n",
    "        except:\n",
    "            gscholar_link = None\n",
    "        references.append({\n",
    "            'reference_text': reference_text,\n",
    "            'google_scholar_link': gscholar_link\n",
    "        })\n",
    "    return references"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "23\n",
      "None\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    try:\n",
    "        print(len(get_references(soup, url)))\n",
    "    except:\n",
    "        print(None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "# len(journal_soup.find_all('li', class_='c-article-references__item js-c-reading-companion-references-item'))\n",
    "# for i in get_references(conference_chapter_soup, conference_chapter_link):\n",
    "#     if i['google_scholar_link'] is not None:\n",
    "#         print(i['google_scholar_link'])\n",
    "#         print(\"\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Journal Fields\n",
    "### Journal name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_journal_name(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the journal name of the publication\n",
    "    Returns None if publication is not a journal article\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Journal name (String)\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = get_json_data(bs)\n",
    "    if '/article/' in url:\n",
    "        journal_name = json_data.get('isPartOf').get('name')\n",
    "        return journal_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic Markets\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_journal_name(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Journal volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_journal_volume(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the journal volume of the publication\n",
    "    Returns None if publication is not a journal article\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Journal volume (String)\n",
    "    \"\"\"\n",
    "    json_data = get_json_data(bs)\n",
    "    if '/article/' in url:\n",
    "        journal_volume = json_data.get('isPartOf').get('volumeNumber')\n",
    "        return journal_volume\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_journal_volume(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Conference fields\n",
    "### Conference name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_conference_name(bs, url):\n",
    "    if get_publication_type(bs, url) == 'Conference paper':\n",
    "        conference_name = bs.find('p', class_='c-chapter-info-details u-mb-8').find('a', {\n",
    "            'data-track': 'click', 'data-track-action': 'open conference'\n",
    "        }).text\n",
    "        return conference_name\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "International Conference on Human-Computer Interaction\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_conference_name(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Venue -> omitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Conference proceeding/ Book title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_proceedings(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the title of the conference proceedings or book under which the publication was published.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Title of the proceedings/book (String)\n",
    "    \"\"\"\n",
    "    if get_publication_type(bs, url) == 'Conference paper':\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            proceedings = json_data.get('isPartOf').get('name')\n",
    "            return proceedings\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_proceedings(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Book/ volume contributions\n",
    "### Book title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_title(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the title of the book under which the publication was published.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Title of the book (String)\n",
    "    \"\"\"\n",
    "    if get_publication_type(bs, url) == 'Chapter':\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            book_title = json_data.get('isPartOf').get('name')\n",
    "            return book_title\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "The Art of Structuring\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_book_title(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_editors(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the editors of the volume (under which the publication was published)\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: List of Editors : [String]\n",
    "    \"\"\"\n",
    "    if '/chapter/' in url:\n",
    "        try:\n",
    "            editor_div = bs.find('div', {'class': 'c-article-section__content', 'id': 'editor-information-content'})\n",
    "            editors = []\n",
    "            for editor in editor_div.find_all('p', class_='c-article-author-affiliation__authors-list'):\n",
    "                editors.append(editor.text)\n",
    "            # remove titles since we scrape the names\n",
    "            # remove Everything including the point from strings in list\n",
    "            editors = [editor.split('.')[1].strip() for editor in editors]\n",
    "            return editors\n",
    "        except:\n",
    "            return None\n",
    "    # in books the editors are in the json file\n",
    "    if '/book/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            editors = [editor.get('name') for editor in json_data.get('editor')]\n",
    "            return editors\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['Gabriele Meiselwitz']\n",
      "['Herbert Kuchen']\n",
      "['Katrin Bergener', 'Michael Räckers', 'Armin Stein']\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_editors(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Books (in general: proceedings or editor volumes)\n",
    "### Book subtitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_book_subtitle(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the subtitle of the book (proceedings or editor volume).\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Subtitle of the book (String)\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            book_subtitle = json_data.get('alternateName')\n",
    "            return book_subtitle\n",
    "        except:\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "20th International Workshop, WFLP 2011, Odense, Denmark, July 19, 2011, Proceedings\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_book_subtitle(soup, url))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Springer Metrics\n",
    "### Accesses"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [],
   "source": [
    "# Navigating with parent because accesses and citations do not have individual features.\n",
    "\n",
    "def get_accesses(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the number of accesses of the publication according to the Springer metric.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Number of accesses (String) #TODO change to int\n",
    "    \"\"\"\n",
    "    try:\n",
    "        accesses = bs.find('span', text='Accesses').parent.text.strip().split(' ')[0]  # navigating up in the tree\n",
    "        return accesses\n",
    "    except:\n",
    "        print(\"error\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844\n",
      "3894\n",
      "3080\n",
      "2349\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_accesses(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Citations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "# Navigating with parent because accesses and citations do not have individual features.\n",
    "\n",
    "def get_citations(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the number of citations of the publication according to the Springer metric.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Number of citations (String) #TODO change to int\n",
    "    \"\"\"\n",
    "    try:\n",
    "        citations = bs.find('span', text='Citations').parent.text.strip().split(' ')[0]  # navigating up in the tree\n",
    "        return citations\n",
    "    except:\n",
    "        try:\n",
    "            # Citation\n",
    "            citations = bs.find('a', class_='c-article-metrics-bar__label',\n",
    "                                text='Citations').parent.text.split(' ')[0].strip()\n",
    "            return citations\n",
    "        except:\n",
    "            return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "2\n",
      "46\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_citations(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}