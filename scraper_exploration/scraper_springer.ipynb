{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Scraper commands for publications on springer\n",
    "## Examples"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here it is only about the steps, to parse are necessary so that it can be included in the end.\n",
    "\n",
    "There are different website types for publications on springer."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "journal_doi = 'https://doi.org/10.1007/s12525-020-00445-0'\n",
    "journal_full_link = 'https://link.springer.com/article/10.1007/s12525-020-00445-0'\n",
    "\n",
    "conference_chapter_link = 'https://link.springer.com/chapter/10.1007/978-3-030-49570-1_14'\n",
    "conference_book_link = 'https://link.springer.com/book/10.1007/978-3-642-22531-4'\n",
    "\n",
    "volume_contribution_link = 'https://link.springer.com/chapter/10.1007/978-3-030-06234-7_27'\n",
    "#volume_link = 'https://link.springer.com/book/10.1007/978-3-030-06234-7'\n",
    "\n",
    "springer_links = [journal_full_link, conference_chapter_link, conference_book_link, volume_contribution_link]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# identify the type of the link\n",
    "def get_springer_link_type(url):\n",
    "    if '/chapter/' in url:\n",
    "        return 'chapter'\n",
    "    elif '/book/' in url:\n",
    "        return 'book'\n",
    "    elif '/article/' in url:\n",
    "        return 'article'\n",
    "    else:\n",
    "        return 'unknown'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "for link in springer_links:\n",
    "    get_springer_link_type(link)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "def get_bs(url):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.5 Safari/605.1.15'}\n",
    "        r = requests.get(url, headers=headers)\n",
    "        print(r.status_code)\n",
    "        bs = BeautifulSoup(r.text, 'html.parser')\n",
    "    except:\n",
    "        print('Error: ', url)\n",
    "        return None\n",
    "    return bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "journal_soup = get_bs(journal_full_link)\n",
    "conference_chapter_soup = get_bs(conference_chapter_link)\n",
    "conference_book_soup = get_bs(conference_book_link)\n",
    "volume_contribution_soup = get_bs(volume_contribution_link)\n",
    "springer_soups = [journal_soup, conference_chapter_soup, conference_book_soup, volume_contribution_soup]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# get whole data from json and loads to dict\n",
    "# articles need to be prefiltered because they are nested differently\n",
    "def get_json_data(bs):\n",
    "    json_string = bs.find('script', {'type': 'application/ld+json'}).text\n",
    "    json_data = json.loads(json_string)\n",
    "\n",
    "    if '{\"mainEntity\":' in json_string:\n",
    "        return json_data['mainEntity']\n",
    "    else:\n",
    "        return json_data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating json files for the three different types of publications for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "journal_json = get_json_data(journal_soup)\n",
    "conference_chapter_json = get_json_data(conference_chapter_soup)\n",
    "conference_book_json = get_json_data(conference_book_soup)\n",
    "volume_contribution_json = get_json_data(volume_contribution_soup)\n",
    "json_data_list = [journal_json, conference_chapter_json, conference_book_json, volume_contribution_json]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# get names of json fields\n",
    "def get_json_fields(json_data):\n",
    "    return list(json_data.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['headline',\n 'description',\n 'datePublished',\n 'dateModified',\n 'pageStart',\n 'pageEnd',\n 'license',\n 'sameAs',\n 'keywords',\n 'image',\n 'isPartOf',\n 'publisher',\n 'author',\n 'isAccessibleForFree',\n '@type']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_fields(journal_json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main Fields\n",
    "Title #TODO get title also for book (if instruction or with json)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_title(bs):\n",
    "    try:\n",
    "        title = bs.find('h1', {'class': 'c-article-title'}).text\n",
    "        return title\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring customers’ likeliness to use e-service touchpoints in brick and mortar retail\n",
      "A Two-Phase Framework for Detecting Manipulation Campaigns in Social Media\n",
      "None\n",
      "Applications of Artificial Intelligence in Supply Chain Management and Logistics: Focusing Onto Recognition for Supply Chain Execution\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_title(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Authors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_authors(bs):\n",
    "    \"\"\"\n",
    "    Return list of authors in the format:\n",
    "    [{'name': 'Author Name', 'orcid': orcid}, ...]\n",
    "\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list of dicts\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        authors = []\n",
    "        for author in json_data.get('author'):\n",
    "            name = author.get('name')\n",
    "            # split name at comma and reverse\n",
    "            name = name.split(', ')\n",
    "            name = name[1] + ' ' + name[0]\n",
    "            orcid = author.get('url')\n",
    "            authors.append({'name': name,\n",
    "                            'orcid': orcid})\n",
    "        return authors\n",
    "    except:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Benjamin Barann', 'orcid': 'http://orcid.org/0000-0002-1965-2688'}, {'name': 'Jan H. Betzing', 'orcid': None}, {'name': 'Marco Niemann', 'orcid': None}, {'name': 'Benedikt Hoffmeister', 'orcid': None}, {'name': 'Jörg Becker', 'orcid': None}]\n",
      "[{'name': 'Dennis Assenmacher', 'orcid': None}, {'name': 'Lena Clever', 'orcid': None}, {'name': 'Janina Susanne Pohl', 'orcid': None}, {'name': 'Heike Trautmann', 'orcid': None}, {'name': 'Christian Grimme', 'orcid': None}]\n",
      "None\n",
      "[{'name': 'Bernd Hellingrath', 'orcid': None}, {'name': 'Sandra Lechtenberg', 'orcid': None}]\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_authors(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Keywords #TODO may be replaced with BS scraping because weird data structure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def get_keywords(bs):\n",
    "    \"\"\"\n",
    "    Return list of keywords from json data\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    Return list of keywords in the format:\n",
    "    [keyword1, keyword2, ...]\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: list: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        keywords_string = json_data.get('keywords')\n",
    "        keywords = keywords_string.split(',')\n",
    "        return keywords\n",
    "    except:\n",
    "        print(\"Error: no keywords found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['IT in Business', 'e-Commerce/e-business']\n",
      "['Social campaign detection', ' Stream clustering', ' Unsupervised learning']\n",
      "['Java', ' XQuery', ' abstract interpretation', ' higher-order patterns', ' non-deterministic functions']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_keywords(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Abstract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_abstract(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the abstract of the articles, books/preceedings do not have abstracts.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: Received url of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        abstract = json_data.get('description')\n",
    "        return abstract\n",
    "    except:\n",
    "        print(\"Error: no abstract found\")\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-commerce has embraced the digital transformation and innovated with e-service touchpoints to improve customers’ experiences. Now some traditional, less-digitalized brick and mortar (BaM) retailers are starting to counteract the increasing competition by adopting digital touchpoints. However, the academic literature offers little in terms of what determines customers’ behavioral intentions toward e-service touchpoints. Therefore, drawing from the dominant design theory, this article first conceptually adapts selected dominant touchpoints of leading e-commerce solutions to BaM retail. Then 250 shoppers are surveyed regarding the likeliness that they will use the selected touchpoints, followed by an exploratory factor analysis to determine the touchpoints’ characteristics that lead to the shoppers’ assessments. The results suggest that customers prefer touchpoints that support product search and selection, provide information, and increase shopping efficiency. The likeliness that surveyed shoppers will use the touchpoints was affected by the functionality provided, the content conveyed, and the mediating device. The results provide a foundation for further research on customers’ behavioral intentions toward BaM e-service touchpoints and provide useful information for BaM retailers.\n",
      "-------\n",
      "The identification of coordinated campaigns within Social Media is a complex task that is often hindered by missing labels and large amounts of data that have to be processed. We propose a new two-phase framework that uses unsupervised stream clustering for detecting suspicious trends over time in a first step. Afterwards, traditional offline analyses are applied to distinguish between normal trend evolution and malicious manipulation attempts. We demonstrate the applicability of our framework in the context of the final days of the Brexit in 2019/2020.\n",
      "-------\n",
      "None\n",
      "-------\n",
      "Emerging technologies like Artificial Intelligence (AI) show the potential to contribute significantly to the digitalization of supply chains. Nonetheless, the question which approaches from the field of AI are applied within supply chains as well as which supply chain problems or tasks are addressed with AI approaches has not been answered by scientific literature yet. Based on a structured literature review this paper aims at providing an answer to these questions. A special focus is given to the application areas for recognition approaches in supply chain execution, for which this paper provides an overview of those areas research is currently focusing upon.\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_abstract(soup, url))\n",
    "    print(\"-------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pdf #todo #TODO: download"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "def get_pdf(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the pdf link of the publication, if available. Download might require login.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf = None\n",
    "        #todo automate download\n",
    "        # differentiate between article, chapter and book\n",
    "        if '/article/' in url:\n",
    "            pdf = bs.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')\n",
    "\n",
    "        elif '/chapter/' in url:\n",
    "            pdf_box = bs.find('div', {'class': 'c-article-access-provider'})\n",
    "            pdf = pdf_box.find('a', {'data-track-action': 'Pdf download'}).get('href')\n",
    "\n",
    "        elif '/book/' in url:\n",
    "            pdf = bs.find('div', {'data-test': 'download-article-link-wrapper',\n",
    "                                  'class': 'js-context-bar-sticky-point-desktop'}).find('a', {\n",
    "                'data-track-action': 'Book download - pdf'}).get('href')\n",
    "        if pdf is not None:\n",
    "            # append base url if necesary\n",
    "            if 'link.springer.com' in pdf:\n",
    "                return pdf\n",
    "            else:\n",
    "                return f'https://link.springer.com{pdf}'\n",
    "    except:\n",
    "        print(\"Error: no pdf found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: no pdf found\n",
      "Error: no pdf found\n"
     ]
    },
    {
     "data": {
      "text/plain": "['https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf',\n 'https://link.springer.com/content/pdf/10.1007/978-3-030-49570-1_14.pdf',\n None,\n None]"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_links = []\n",
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    test_links.append(get_pdf(soup, url))\n",
    "\n",
    "test_links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'https://link.springer.com/content/pdf/10.1007/s12525-020-00445-0.pdf'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal_soup.find('div', class_='c-pdf-container').find('a', {'data-article-pdf': 'true'}).get('href')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publisher"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_publisher(bs):\n",
    "    \"\"\"\n",
    "    Returns the publisher of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        publisher = json_data.get('publisher').get('name')\n",
    "        return publisher\n",
    "    except:\n",
    "        print(\"Error: no publisher found\")\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n",
      "Springer Berlin Heidelberg\n",
      "Springer International Publishing\n"
     ]
    }
   ],
   "source": [
    "for soup in springer_soups:\n",
    "    print(get_publisher(soup))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Year"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def get_year(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the year of the publication\n",
    "    :param url: URL of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json_data = get_json_data(bs)\n",
    "        if ('/chapter/' in url) or ('/article/' in url):\n",
    "            date = json_data.get('datePublished')\n",
    "            year = date.split('-')[0]  # get year from date (if date is available)\n",
    "            return year\n",
    "        if '/book/' in url:\n",
    "            year = json_data.get('copyrightYear')\n",
    "            return year\n",
    "\n",
    "    except:\n",
    "        print(\"Error: no year found\")\n",
    "        print(bs.name)\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2020\n",
      "2011\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_year(soup, url))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Publication type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def get_publication_type(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the publication type of the publication\n",
    "    :param url: URL of the publication\n",
    "    :param bs: Received bs of the publication\n",
    "    :return: String\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if '/book/' in url:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item'}).text\n",
    "        else:\n",
    "            type = bs.find('li', {'class': 'c-article-identifiers__item', 'data-test': 'article-category'}).text\n",
    "        return type\n",
    "    except:\n",
    "        print(\"Error: no publication type found in bs, deriving by url\")\n",
    "        if '/book/' in url:\n",
    "            return 'Book'\n",
    "        elif '/chapter/' in url:\n",
    "            return 'Chapter'\n",
    "        elif '/article/' in url:\n",
    "            return 'Article'\n",
    "        #return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research Paper\n",
      "Conference paper\n",
      "Conference proceedings\n",
      "Chapter\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_publication_type(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# html_test = requests.get(\"https://link.springer.com/article/10.1007/s11129-017-9188-7\").text\n",
    "# bs_test = BeautifulSoup(html_test, 'html.parser')\n",
    "# get_publication_type(bs_test, 'https://link.springer.com/article/10.1007/s11129-017-9188-7')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Journal Fields\n",
    "### Journal name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_journal_name(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the journal name of the publication\n",
    "    Returns None if publication is not a journal article\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Journal name (String)\n",
    "    \"\"\"\n",
    "\n",
    "    json_data = get_json_data(bs)\n",
    "    if '/article/' in url:\n",
    "        journal_name = json_data.get('isPartOf').get('name')\n",
    "        return journal_name\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic Markets\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_journal_name(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Journal volume"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def get_journal_volume(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the journal volume of the publication\n",
    "    Returns None if publication is not a journal article\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Journal volume (String)\n",
    "    \"\"\"\n",
    "    json_data = get_json_data(bs)\n",
    "    if '/article/' in url:\n",
    "        journal_volume = json_data.get('isPartOf').get('volumeNumber')\n",
    "        return journal_volume\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_journal_volume(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conference fields\n",
    "### Conference name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def get_conference_name(bs, url):\n",
    "    if get_publication_type(bs, url) == 'Conference paper':\n",
    "        conference_name = bs.find('p', class_='c-chapter-info-details u-mb-8').find('a', {\n",
    "            'data-track': 'click', 'data-track-action': 'open conference'\n",
    "        }).text\n",
    "        return conference_name\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "International Conference on Human-Computer Interaction\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_conference_name(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Venue -> omitted"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Conference proceeding/ Book title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def get_proceedings(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the title of the conference proceedings or book under which the publication was published.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Title of the proceedings/book (String)\n",
    "    \"\"\"\n",
    "    if get_publication_type(bs, url) == 'Conference paper':\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            proceedings = json_data.get('isPartOf').get('name')\n",
    "            return proceedings\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_proceedings(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Book/ volume contributions\n",
    "### Book title"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def get_book_title(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the title of the book under which the publication was published.\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Title of the book (String)\n",
    "    \"\"\"\n",
    "    if get_publication_type(bs, url) == 'Chapter':\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            book_title = json_data.get('isPartOf').get('name')\n",
    "            return book_title\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "The Art of Structuring\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_book_title(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [],
   "source": [
    "def get_editors(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the editors of the volume (under which the publication was published)\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: List of Editors : [String]\n",
    "    \"\"\"\n",
    "    if '/chapter/' in url:\n",
    "        try:\n",
    "            editor_div = bs.find('div', {'class': 'c-article-section__content', 'id': 'editor-information-content'})\n",
    "            editors = []\n",
    "            for editor in editor_div.find_all('p', class_='c-article-author-affiliation__authors-list'):\n",
    "                editors.append(editor.text)\n",
    "            # remove titles since we scrape the names\n",
    "            # remove Everything including the point from strings in list\n",
    "            editors = [editor.split('.')[1].strip() for editor in editors]\n",
    "            return editors\n",
    "        except:\n",
    "            return None\n",
    "    # in books the editors are in the json file\n",
    "    if '/book/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            editors = [editor.get('name') for editor in json_data.get('editor')]\n",
    "            return editors\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "['Gabriele Meiselwitz']\n",
      "None\n",
      "['Katrin Bergener', 'Michael Räckers', 'Armin Stein']\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_editors(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Books (in general: proceedings or editor volumes)\n",
    "### Book subtitle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def get_book_subtitle(bs, url):\n",
    "    \"\"\"\n",
    "    Returns the subtitle of the book (proceedings or editor volume).\n",
    "    :param bs: Received bs of the publication\n",
    "    :param url: URL of the publication\n",
    "    :return: Subtitle of the book (String)\n",
    "    \"\"\"\n",
    "    if '/book/' in url:\n",
    "        try:\n",
    "            json_data = get_json_data(bs)\n",
    "            book_subtitle = json_data.get('alternateName')\n",
    "            return book_subtitle\n",
    "        except:\n",
    "            return None\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "20th International Workshop, WFLP 2011, Odense, Denmark, July 19, 2011, Proceedings\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for soup, url in zip(springer_soups, springer_links):\n",
    "    print(get_book_subtitle(soup, url))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "'Bridging the Gap Between Information Systems Research and Practice'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# html_test = requests.get('https://link.springer.com/book/10.1007/978-3-030-06234-7').text\n",
    "# bs_test = BeautifulSoup(html_test, 'html.parser')\n",
    "# get_book_subtitle(bs_test, 'https://link.springer.com/book/10.1007/978-3-030-06234-7')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}